{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O730iQKMPnLn"
      },
      "outputs": [],
      "source": [
        "#Importing required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "bA4Zav-iPv2J"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the dataset\n",
        "df = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wTpvdw-tP2Al",
        "outputId": "249c488d-0902-40a4-daf6-0b281eac4385"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
              "0   540.0                 0.0      0.0  162.0               2.5   \n",
              "1   540.0                 0.0      0.0  162.0               2.5   \n",
              "2   332.5               142.5      0.0  228.0               0.0   \n",
              "3   332.5               142.5      0.0  228.0               0.0   \n",
              "4   198.6               132.4      0.0  192.0               0.0   \n",
              "\n",
              "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
              "0            1040.0           676.0   28     79.99  \n",
              "1            1055.0           676.0   28     61.89  \n",
              "2             932.0           594.0  270     40.27  \n",
              "3             932.0           594.0  365     41.05  \n",
              "4             978.4           825.5  360     44.30  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04f42a0b-813b-4eb4-b551-0583843288ba\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "      <th>Strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>79.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1055.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>61.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>270</td>\n",
              "      <td>40.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>365</td>\n",
              "      <td>41.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198.6</td>\n",
              "      <td>132.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978.4</td>\n",
              "      <td>825.5</td>\n",
              "      <td>360</td>\n",
              "      <td>44.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04f42a0b-813b-4eb4-b551-0583843288ba')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-04f42a0b-813b-4eb4-b551-0583843288ba button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-04f42a0b-813b-4eb4-b551-0583843288ba');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2ca3daac-238b-45d6-9f2f-73d0893d60d4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2ca3daac-238b-45d6-9f2f-73d0893d60d4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2ca3daac-238b-45d6-9f2f-73d0893d60d4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1030,\n  \"fields\": [\n    {\n      \"column\": \"Cement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 104.50636449481543,\n        \"min\": 102.0,\n        \"max\": 540.0,\n        \"num_unique_values\": 278,\n        \"samples\": [\n          337.9,\n          290.2,\n          262.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Blast Furnace Slag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 86.27934174810551,\n        \"min\": 0.0,\n        \"max\": 359.4,\n        \"num_unique_values\": 185,\n        \"samples\": [\n          94.7,\n          119.0,\n          136.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fly Ash\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63.99700415268812,\n        \"min\": 0.0,\n        \"max\": 200.1,\n        \"num_unique_values\": 156,\n        \"samples\": [\n          98.0,\n          142.0,\n          195.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Water\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.354218565032525,\n        \"min\": 121.8,\n        \"max\": 247.0,\n        \"num_unique_values\": 195,\n        \"samples\": [\n          195.4,\n          183.8,\n          127.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Superplasticizer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.973841392485506,\n        \"min\": 0.0,\n        \"max\": 32.2,\n        \"num_unique_values\": 111,\n        \"samples\": [\n          15.0,\n          28.2,\n          16.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Coarse Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 77.75395396672091,\n        \"min\": 801.0,\n        \"max\": 1145.0,\n        \"num_unique_values\": 284,\n        \"samples\": [\n          852.1,\n          913.9,\n          914.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fine Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80.17598014240434,\n        \"min\": 594.0,\n        \"max\": 992.6,\n        \"num_unique_values\": 302,\n        \"samples\": [\n          710.0,\n          695.4,\n          769.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63,\n        \"min\": 1,\n        \"max\": 365,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          91,\n          100,\n          28\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Strength\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.705741961912505,\n        \"min\": 2.33,\n        \"max\": 82.6,\n        \"num_unique_values\": 845,\n        \"samples\": [\n          41.68,\n          39.59,\n          2.33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the library for splitting the data\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Z_DmcoEPP-OP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = df.columns"
      ],
      "metadata": {
        "id": "1J39fpo0Rlam"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = df[column_names[column_names!='Strength']]\n",
        "target = df['Strength']"
      ],
      "metadata": {
        "id": "QWJXyaljRrwb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor_norm = predictor - predictor.mean()/predictor.std()\n",
        "predictor_norm.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dJ1CZugBbF5w",
        "outputId": "278dff7e-233a-4e77-95ca-aa0613c97f05"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Cement  Blast Furnace Slag   Fly Ash       Water  Superplasticizer  \\\n",
              "0  537.309562           -0.856472 -0.846733  153.497358          1.461362   \n",
              "1  537.309562           -0.856472 -0.846733  153.497358          1.461362   \n",
              "2  329.809562          141.643528 -0.846733  219.497358         -1.038638   \n",
              "3  329.809562          141.643528 -0.846733  219.497358         -1.038638   \n",
              "4  195.909562          131.543528 -0.846733  183.497358         -1.038638   \n",
              "\n",
              "   Coarse Aggregate  Fine Aggregate         Age  \n",
              "0        1027.48721      666.351468   27.277154  \n",
              "1        1042.48721      666.351468   27.277154  \n",
              "2         919.48721      584.351468  269.277154  \n",
              "3         919.48721      584.351468  364.277154  \n",
              "4         965.88721      815.851468  359.277154  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c73cf43-51ce-4cb1-af61-41160958061a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>537.309562</td>\n",
              "      <td>-0.856472</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>153.497358</td>\n",
              "      <td>1.461362</td>\n",
              "      <td>1027.48721</td>\n",
              "      <td>666.351468</td>\n",
              "      <td>27.277154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>537.309562</td>\n",
              "      <td>-0.856472</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>153.497358</td>\n",
              "      <td>1.461362</td>\n",
              "      <td>1042.48721</td>\n",
              "      <td>666.351468</td>\n",
              "      <td>27.277154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>329.809562</td>\n",
              "      <td>141.643528</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>219.497358</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>919.48721</td>\n",
              "      <td>584.351468</td>\n",
              "      <td>269.277154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>329.809562</td>\n",
              "      <td>141.643528</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>219.497358</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>919.48721</td>\n",
              "      <td>584.351468</td>\n",
              "      <td>364.277154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>195.909562</td>\n",
              "      <td>131.543528</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>183.497358</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>965.88721</td>\n",
              "      <td>815.851468</td>\n",
              "      <td>359.277154</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c73cf43-51ce-4cb1-af61-41160958061a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3c73cf43-51ce-4cb1-af61-41160958061a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3c73cf43-51ce-4cb1-af61-41160958061a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a70bde50-69d7-4871-9477-1656dfce922d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a70bde50-69d7-4871-9477-1656dfce922d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a70bde50-69d7-4871-9477-1656dfce922d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "predictor_norm",
              "summary": "{\n  \"name\": \"predictor_norm\",\n  \"rows\": 1030,\n  \"fields\": [\n    {\n      \"column\": \"Cement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 104.50636449481549,\n        \"min\": 99.3095622889875,\n        \"max\": 537.3095622889875,\n        \"num_unique_values\": 278,\n        \"samples\": [\n          335.20956228898746,\n          287.50956228898747,\n          259.3095622889875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Blast Furnace Slag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 86.27934174810541,\n        \"min\": -0.8564718244890995,\n        \"max\": 358.54352817551086,\n        \"num_unique_values\": 185,\n        \"samples\": [\n          93.8435281755109,\n          118.1435281755109,\n          135.44352817551092\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fly Ash\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63.997004152687005,\n        \"min\": -0.8467325968146431,\n        \"max\": 199.25326740318536,\n        \"num_unique_values\": 156,\n        \"samples\": [\n          97.15326740318535,\n          141.15326740318537,\n          194.15326740318537\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Water\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.35421856503253,\n        \"min\": 113.29735772346575,\n        \"max\": 238.49735772346574,\n        \"num_unique_values\": 195,\n        \"samples\": [\n          186.89735772346575,\n          175.29735772346575,\n          118.79735772346575\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Superplasticizer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.973841392485511,\n        \"min\": -1.0386382541022263,\n        \"max\": 31.161361745897775,\n        \"num_unique_values\": 111,\n        \"samples\": [\n          13.961361745897774,\n          27.16136174589777,\n          15.461361745897774\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Coarse Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 77.75395396672074,\n        \"min\": 788.4872095577898,\n        \"max\": 1132.4872095577898,\n        \"num_unique_values\": 284,\n        \"samples\": [\n          839.5872095577898,\n          901.3872095577898,\n          901.4872095577898\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fine Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80.17598014240454,\n        \"min\": 584.3514683068058,\n        \"max\": 982.9514683068059,\n        \"num_unique_values\": 302,\n        \"samples\": [\n          700.3514683068058,\n          685.7514683068058,\n          759.6514683068058\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63.16991158103307,\n        \"min\": 0.2771537148068416,\n        \"max\": 364.27715371480684,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          90.27715371480684,\n          99.27715371480684,\n          27.277153714806843\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(predictor_norm, target, test_size=0.3)"
      ],
      "metadata": {
        "id": "ebOSamb-Qb-4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating the model\n",
        "def regression_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(10, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "  model.add(Dense(1))\n",
        "\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "  return model"
      ],
      "metadata": {
        "id": "Rd3VB3JmQ5Tr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Evaluation\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "VwLfN2MXXDqs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_list=[]"
      ],
      "metadata": {
        "id": "IsDm8oCIWH7v"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(50):\n",
        "  model = regression_model()\n",
        "  model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100, verbose=2)\n",
        "\n",
        "  y_pred = model.predict(x_test)\n",
        "  mse = mean_squared_error(y_test, y_pred)\n",
        "  mse_list.append(mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqU3NIJ_YZP8",
        "outputId": "c193724b-449e-49ea-915b-f556cd497afc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "23/23 - 1s - 63ms/step - loss: 10664.8740 - val_loss: 3956.4519\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 3908.9219 - val_loss: 2810.4375\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 3172.1619 - val_loss: 2586.7576\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 5ms/step - loss: 2768.1128 - val_loss: 2339.6650\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 2449.7512 - val_loss: 2134.2119\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 7ms/step - loss: 2173.4836 - val_loss: 1905.7460\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 5ms/step - loss: 1912.2852 - val_loss: 1706.9520\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 5ms/step - loss: 1698.9218 - val_loss: 1607.9504\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1516.0511 - val_loss: 1411.7544\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 5ms/step - loss: 1377.3844 - val_loss: 1283.5941\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1230.7722 - val_loss: 1199.3176\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 8ms/step - loss: 1109.7621 - val_loss: 1152.6689\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 11ms/step - loss: 1002.5876 - val_loss: 984.8214\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 918.1541 - val_loss: 922.6441\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 7ms/step - loss: 822.1382 - val_loss: 832.2236\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 8ms/step - loss: 759.6934 - val_loss: 744.2695\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 11ms/step - loss: 682.9100 - val_loss: 678.1684\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 626.2801 - val_loss: 645.0328\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 9ms/step - loss: 564.5237 - val_loss: 563.4664\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 11ms/step - loss: 518.1046 - val_loss: 521.5047\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 12ms/step - loss: 474.4596 - val_loss: 475.8560\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 7ms/step - loss: 439.2059 - val_loss: 439.9016\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 7ms/step - loss: 402.2851 - val_loss: 395.6141\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 13ms/step - loss: 365.3289 - val_loss: 377.8042\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 8ms/step - loss: 343.1495 - val_loss: 349.1160\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 7ms/step - loss: 318.1820 - val_loss: 317.2088\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 12ms/step - loss: 296.4652 - val_loss: 293.2715\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 7ms/step - loss: 286.2159 - val_loss: 269.1918\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 7ms/step - loss: 262.5322 - val_loss: 252.7399\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 13ms/step - loss: 243.8879 - val_loss: 237.7646\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 12ms/step - loss: 238.0003 - val_loss: 221.3168\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 7ms/step - loss: 223.3002 - val_loss: 210.4491\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 7ms/step - loss: 207.8398 - val_loss: 199.1890\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 12ms/step - loss: 198.7464 - val_loss: 190.4152\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 5ms/step - loss: 190.2508 - val_loss: 185.4382\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 8ms/step - loss: 184.9777 - val_loss: 174.8253\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 11ms/step - loss: 178.3280 - val_loss: 168.6360\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 172.7531 - val_loss: 163.8066\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.8413 - val_loss: 157.3864\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 164.8087 - val_loss: 152.5901\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.0500 - val_loss: 149.1169\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 7ms/step - loss: 153.3426 - val_loss: 144.2302\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 152.0900 - val_loss: 140.8857\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 147.9486 - val_loss: 138.2236\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 145.0107 - val_loss: 136.8723\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 5ms/step - loss: 141.8822 - val_loss: 132.9584\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 140.5942 - val_loss: 130.9916\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 5ms/step - loss: 140.3834 - val_loss: 129.0310\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.4532 - val_loss: 126.7556\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.7760 - val_loss: 127.8074\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 133.2414 - val_loss: 125.5134\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 131.2373 - val_loss: 122.8005\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 7ms/step - loss: 130.6767 - val_loss: 121.7485\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 11ms/step - loss: 129.6421 - val_loss: 121.2652\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 128.6676 - val_loss: 119.8175\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 3ms/step - loss: 128.5007 - val_loss: 119.9177\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 3ms/step - loss: 127.4511 - val_loss: 117.0653\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 125.7409 - val_loss: 116.0032\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 124.5966 - val_loss: 116.8133\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 7ms/step - loss: 126.4097 - val_loss: 116.4883\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 124.5808 - val_loss: 122.1980\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 5ms/step - loss: 123.7815 - val_loss: 113.3164\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 7ms/step - loss: 126.7935 - val_loss: 113.4757\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 124.8502 - val_loss: 116.1890\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.6774 - val_loss: 111.3209\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.1709 - val_loss: 112.6810\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.7069 - val_loss: 113.4843\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.7018 - val_loss: 109.9486\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 5ms/step - loss: 122.9284 - val_loss: 110.5964\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.5180 - val_loss: 120.8350\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.4421 - val_loss: 108.8701\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.1395 - val_loss: 112.5407\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.1511 - val_loss: 113.2505\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.3914 - val_loss: 113.5944\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.1563 - val_loss: 107.7801\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.0184 - val_loss: 107.3833\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.7721 - val_loss: 107.2481\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 7ms/step - loss: 118.0943 - val_loss: 106.6730\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 5ms/step - loss: 115.5945 - val_loss: 109.0667\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.3463 - val_loss: 106.6518\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.5257 - val_loss: 108.4780\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.9733 - val_loss: 106.1380\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.3173 - val_loss: 105.8025\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.6969 - val_loss: 107.0716\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.3047 - val_loss: 106.6253\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.4622 - val_loss: 107.2545\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.4538 - val_loss: 105.3481\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.6189 - val_loss: 105.1517\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.5758 - val_loss: 107.3866\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 7ms/step - loss: 116.1159 - val_loss: 105.1562\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.5973 - val_loss: 110.7054\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.2632 - val_loss: 112.3962\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.7512 - val_loss: 110.8601\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 119.2199 - val_loss: 116.6685\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.0502 - val_loss: 109.9263\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.9998 - val_loss: 105.6282\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.6005 - val_loss: 106.8516\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.3787 - val_loss: 104.0973\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.2119 - val_loss: 105.5920\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.7668 - val_loss: 105.0219\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 68ms/step - loss: 64789.2969 - val_loss: 34187.6523\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 5ms/step - loss: 17935.2168 - val_loss: 7715.3018\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 4744.4287 - val_loss: 2712.0667\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 7ms/step - loss: 3193.1108 - val_loss: 2276.4402\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 12ms/step - loss: 2976.7449 - val_loss: 2134.3640\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 5ms/step - loss: 2747.9868 - val_loss: 1985.9094\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 2534.4028 - val_loss: 1835.6647\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 2318.0442 - val_loss: 1668.5197\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 2113.0403 - val_loss: 1509.9930\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 13ms/step - loss: 1907.2505 - val_loss: 1366.4458\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1695.9003 - val_loss: 1201.9451\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 1492.0806 - val_loss: 1055.6731\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 7ms/step - loss: 1279.8829 - val_loss: 907.2348\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 7ms/step - loss: 1095.3892 - val_loss: 794.0410\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 5ms/step - loss: 936.7051 - val_loss: 673.0499\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 10ms/step - loss: 801.4057 - val_loss: 585.8140\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 7ms/step - loss: 685.2804 - val_loss: 510.1857\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 14ms/step - loss: 592.2233 - val_loss: 452.1201\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 12ms/step - loss: 514.2445 - val_loss: 413.6699\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 15ms/step - loss: 457.8253 - val_loss: 367.4798\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 10ms/step - loss: 408.2648 - val_loss: 346.0160\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 8ms/step - loss: 368.6182 - val_loss: 316.5253\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 335.5421 - val_loss: 301.0348\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 310.6173 - val_loss: 285.6255\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 13ms/step - loss: 289.7291 - val_loss: 270.1868\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 271.8311 - val_loss: 251.1051\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 257.0598 - val_loss: 240.8421\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 13ms/step - loss: 241.9069 - val_loss: 236.5383\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 7ms/step - loss: 229.7525 - val_loss: 220.4939\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 12ms/step - loss: 220.0699 - val_loss: 207.7316\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 209.0298 - val_loss: 204.2848\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 8ms/step - loss: 200.4188 - val_loss: 194.4622\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 12ms/step - loss: 193.2497 - val_loss: 188.1154\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 12ms/step - loss: 185.5166 - val_loss: 178.8635\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.1038 - val_loss: 172.2594\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 9ms/step - loss: 173.6149 - val_loss: 166.9540\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.1617 - val_loss: 159.6262\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 163.7834 - val_loss: 160.4958\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.8483 - val_loss: 152.5434\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.2674 - val_loss: 146.7260\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.7583 - val_loss: 145.5434\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 13ms/step - loss: 151.6407 - val_loss: 140.8137\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 147.3779 - val_loss: 136.7173\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 145.2812 - val_loss: 135.4639\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 144.3228 - val_loss: 132.1519\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 13ms/step - loss: 141.0287 - val_loss: 131.3026\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 12ms/step - loss: 139.5007 - val_loss: 127.7255\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 13ms/step - loss: 139.0414 - val_loss: 129.8357\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.3930 - val_loss: 124.7878\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 136.3960 - val_loss: 124.9767\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 13ms/step - loss: 135.8867 - val_loss: 121.3302\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 12ms/step - loss: 133.9357 - val_loss: 122.4143\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 8ms/step - loss: 132.3739 - val_loss: 120.7438\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 12ms/step - loss: 132.7603 - val_loss: 122.2076\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 12ms/step - loss: 129.9645 - val_loss: 117.0423\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 130.2933 - val_loss: 116.6760\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 128.7641 - val_loss: 118.0283\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 7ms/step - loss: 128.4485 - val_loss: 114.7964\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 12ms/step - loss: 127.7655 - val_loss: 115.6985\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 15ms/step - loss: 126.9356 - val_loss: 115.3991\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 8ms/step - loss: 127.6312 - val_loss: 113.2166\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 10ms/step - loss: 125.7894 - val_loss: 114.8259\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 10ms/step - loss: 126.6550 - val_loss: 112.1818\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 10ms/step - loss: 125.6885 - val_loss: 111.6639\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 125.0892 - val_loss: 111.2939\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 15ms/step - loss: 124.6249 - val_loss: 114.0162\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 12ms/step - loss: 124.5470 - val_loss: 113.1324\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 12ms/step - loss: 126.4464 - val_loss: 111.3641\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 7ms/step - loss: 123.5481 - val_loss: 109.8102\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 13ms/step - loss: 122.9601 - val_loss: 111.0721\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 10ms/step - loss: 123.6821 - val_loss: 110.1397\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 12ms/step - loss: 122.2881 - val_loss: 109.1707\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 12ms/step - loss: 122.3907 - val_loss: 111.6565\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 9ms/step - loss: 123.6210 - val_loss: 111.2740\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 8ms/step - loss: 122.1928 - val_loss: 111.7711\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 16ms/step - loss: 123.9419 - val_loss: 111.1755\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 8ms/step - loss: 121.9269 - val_loss: 108.0117\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.5111 - val_loss: 109.1886\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 7ms/step - loss: 121.9537 - val_loss: 107.6621\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 13ms/step - loss: 125.6831 - val_loss: 109.6772\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.9791 - val_loss: 107.5828\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.1031 - val_loss: 107.2854\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.7334 - val_loss: 108.2199\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.5146 - val_loss: 107.0968\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.0264 - val_loss: 106.8463\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.6439 - val_loss: 106.8703\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.7066 - val_loss: 107.0541\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.1601 - val_loss: 106.6113\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.1268 - val_loss: 106.4535\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.1227 - val_loss: 106.1078\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.7748 - val_loss: 106.5012\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.4778 - val_loss: 106.2221\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.7099 - val_loss: 105.8018\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 7ms/step - loss: 118.4055 - val_loss: 107.9576\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.1697 - val_loss: 106.9809\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.9076 - val_loss: 106.3578\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.8912 - val_loss: 106.0476\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 5ms/step - loss: 119.1265 - val_loss: 105.4465\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 5ms/step - loss: 118.4862 - val_loss: 105.1943\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.1992 - val_loss: 106.4761\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 45ms/step - loss: 512558.7500 - val_loss: 415619.6250\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 5ms/step - loss: 359492.6250 - val_loss: 286400.6875\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 245094.4062 - val_loss: 192617.4375\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 163627.1250 - val_loss: 126034.2500\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 106145.7656 - val_loss: 80210.8125\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 5ms/step - loss: 66459.2891 - val_loss: 48267.2461\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 36709.6250 - val_loss: 23234.2402\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 16397.2715 - val_loss: 10371.2578\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 5ms/step - loss: 7985.6753 - val_loss: 6830.9619\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 5ms/step - loss: 6040.8140 - val_loss: 6358.0356\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 5723.0034 - val_loss: 6121.3408\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 5482.8311 - val_loss: 5870.4639\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 5263.1279 - val_loss: 5624.2041\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 5048.1992 - val_loss: 5411.2432\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 4846.3525 - val_loss: 5199.9854\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 4658.4863 - val_loss: 4973.6689\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 4463.4238 - val_loss: 4782.4800\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 5ms/step - loss: 4287.0986 - val_loss: 4581.7578\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 4105.4238 - val_loss: 4389.0708\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 3937.1582 - val_loss: 4204.9307\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 7ms/step - loss: 3777.8838 - val_loss: 4022.5190\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 3611.2312 - val_loss: 3832.7920\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 5ms/step - loss: 3462.7532 - val_loss: 3668.8098\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 3316.1262 - val_loss: 3487.6343\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 3153.9670 - val_loss: 3355.4653\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 5ms/step - loss: 3019.2749 - val_loss: 3191.1777\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 5ms/step - loss: 2885.6628 - val_loss: 3027.2070\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 2751.4082 - val_loss: 2892.1128\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 2626.6484 - val_loss: 2743.2542\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 5ms/step - loss: 2509.6724 - val_loss: 2613.7649\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 5ms/step - loss: 2392.4756 - val_loss: 2498.5447\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 2286.4263 - val_loss: 2375.0667\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 5ms/step - loss: 2200.2920 - val_loss: 2253.5437\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 2086.4675 - val_loss: 2153.5579\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 1991.9723 - val_loss: 2041.0219\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 5ms/step - loss: 1906.1031 - val_loss: 1941.7544\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 1823.0822 - val_loss: 1848.3510\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 1742.5267 - val_loss: 1762.5138\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 1666.3901 - val_loss: 1683.4996\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 9ms/step - loss: 1593.9069 - val_loss: 1598.5645\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 1527.8064 - val_loss: 1528.3020\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 13ms/step - loss: 1460.8011 - val_loss: 1457.4553\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 7ms/step - loss: 1401.3628 - val_loss: 1391.1725\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 1344.7598 - val_loss: 1330.1143\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 7ms/step - loss: 1290.9424 - val_loss: 1260.4922\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 8ms/step - loss: 1236.7573 - val_loss: 1215.9423\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 5ms/step - loss: 1184.6130 - val_loss: 1155.5688\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 1142.7443 - val_loss: 1103.8630\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 1095.4861 - val_loss: 1064.5229\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 7ms/step - loss: 1049.4913 - val_loss: 1012.9940\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 15ms/step - loss: 1008.0767 - val_loss: 971.9046\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 7ms/step - loss: 967.4156 - val_loss: 929.5357\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 14ms/step - loss: 929.2267 - val_loss: 893.6680\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 15ms/step - loss: 890.6538 - val_loss: 855.4771\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 9ms/step - loss: 856.9631 - val_loss: 819.2616\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 5ms/step - loss: 821.6985 - val_loss: 780.3841\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 788.4979 - val_loss: 748.9237\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 753.9724 - val_loss: 720.5181\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 723.5966 - val_loss: 685.1626\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 693.5694 - val_loss: 659.3899\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 664.9128 - val_loss: 628.0612\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 639.5672 - val_loss: 603.9493\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 7ms/step - loss: 613.1240 - val_loss: 575.4654\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 5ms/step - loss: 586.9445 - val_loss: 551.5438\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 562.0597 - val_loss: 526.7333\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 539.3539 - val_loss: 504.1779\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 514.8512 - val_loss: 484.3291\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 494.7823 - val_loss: 463.9848\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 471.4583 - val_loss: 441.5086\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 7ms/step - loss: 452.7114 - val_loss: 422.9057\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 432.9438 - val_loss: 406.8185\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 416.2106 - val_loss: 391.9992\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 3ms/step - loss: 398.1339 - val_loss: 371.9935\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 380.8176 - val_loss: 354.3333\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 364.4083 - val_loss: 340.0220\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 349.3061 - val_loss: 327.1197\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 335.1778 - val_loss: 310.5517\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 3ms/step - loss: 320.4391 - val_loss: 299.9576\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 308.3838 - val_loss: 286.4836\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 295.2830 - val_loss: 273.7656\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 7ms/step - loss: 283.3314 - val_loss: 264.3223\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 272.1619 - val_loss: 252.4192\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 264.7008 - val_loss: 247.0429\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 253.8518 - val_loss: 233.8146\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 242.9252 - val_loss: 227.0005\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 234.0309 - val_loss: 216.6684\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 225.6968 - val_loss: 212.8155\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 221.5743 - val_loss: 201.8616\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 211.9378 - val_loss: 196.6006\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 206.0048 - val_loss: 191.6794\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 198.8529 - val_loss: 184.8095\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 193.6932 - val_loss: 177.9111\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 187.8569 - val_loss: 172.9259\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 5ms/step - loss: 182.8270 - val_loss: 173.2253\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 177.2875 - val_loss: 162.9177\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 173.1268 - val_loss: 159.2408\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.0086 - val_loss: 155.1616\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 164.6660 - val_loss: 154.3048\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 163.1499 - val_loss: 148.5506\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 157.4925 - val_loss: 145.5481\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 37ms/step - loss: 159924.5938 - val_loss: 121475.2109\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 82648.3438 - val_loss: 57840.7188\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 35886.3672 - val_loss: 22414.0527\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 16653.8809 - val_loss: 12019.1348\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 13038.9297 - val_loss: 10255.6914\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 12100.9072 - val_loss: 9735.3672\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 11414.6689 - val_loss: 9323.0479\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 7ms/step - loss: 10764.1758 - val_loss: 8927.7881\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 10173.4648 - val_loss: 8477.5117\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 7ms/step - loss: 9630.3760 - val_loss: 8114.3535\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 5ms/step - loss: 9138.9688 - val_loss: 7838.0483\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 7ms/step - loss: 8677.4512 - val_loss: 7484.8101\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 3ms/step - loss: 8243.7637 - val_loss: 7167.4990\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 7ms/step - loss: 7844.8662 - val_loss: 6854.3457\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 7471.8052 - val_loss: 6593.8340\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 7133.6299 - val_loss: 6366.0459\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 6799.9702 - val_loss: 6078.4434\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 3ms/step - loss: 6497.9404 - val_loss: 5854.3833\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 6202.4077 - val_loss: 5699.9712\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 5946.0298 - val_loss: 5464.5190\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 5679.4038 - val_loss: 5239.2554\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 7ms/step - loss: 5448.6035 - val_loss: 5011.1592\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 5223.0186 - val_loss: 4888.7642\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 5ms/step - loss: 5012.3286 - val_loss: 4728.8096\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 5ms/step - loss: 4808.0498 - val_loss: 4519.1636\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 4621.6680 - val_loss: 4376.7158\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 4442.0869 - val_loss: 4200.1313\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 5ms/step - loss: 4270.2725 - val_loss: 4068.8237\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 4114.8364 - val_loss: 3947.8528\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 3956.5793 - val_loss: 3824.4790\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 7ms/step - loss: 3815.5818 - val_loss: 3697.5808\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 12ms/step - loss: 3680.7622 - val_loss: 3583.2661\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 3548.2544 - val_loss: 3452.2759\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 5ms/step - loss: 3422.5625 - val_loss: 3345.3049\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 5ms/step - loss: 3306.7251 - val_loss: 3270.9431\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 9ms/step - loss: 3192.1116 - val_loss: 3133.7261\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 11ms/step - loss: 3081.5603 - val_loss: 3031.9067\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 2974.9033 - val_loss: 2971.3425\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 8ms/step - loss: 2882.2251 - val_loss: 2847.9465\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 10ms/step - loss: 2785.7366 - val_loss: 2770.0891\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 5ms/step - loss: 2693.3162 - val_loss: 2685.4287\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 7ms/step - loss: 2606.4978 - val_loss: 2601.9426\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 2521.9878 - val_loss: 2529.0596\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 2445.2551 - val_loss: 2458.3953\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 3ms/step - loss: 2369.6045 - val_loss: 2378.3879\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 2295.6760 - val_loss: 2308.7070\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 3ms/step - loss: 2233.9141 - val_loss: 2227.4001\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 2155.8167 - val_loss: 2188.1711\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 2095.1731 - val_loss: 2128.9404\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 2033.5240 - val_loss: 2046.4705\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 1972.6204 - val_loss: 1998.7220\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 1918.3842 - val_loss: 1941.9462\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 1858.6906 - val_loss: 1890.0791\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 1805.1394 - val_loss: 1838.7152\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 3ms/step - loss: 1755.5360 - val_loss: 1784.3365\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 1705.4830 - val_loss: 1738.4418\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 1656.5292 - val_loss: 1695.4248\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 1609.8915 - val_loss: 1648.1288\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 1567.7183 - val_loss: 1598.9348\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 1531.8937 - val_loss: 1559.9790\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 1482.6274 - val_loss: 1511.3877\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 3ms/step - loss: 1440.4047 - val_loss: 1482.2227\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 1401.8510 - val_loss: 1439.4855\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 1362.5007 - val_loss: 1397.8818\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 7ms/step - loss: 1323.9786 - val_loss: 1366.2065\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 5ms/step - loss: 1288.0685 - val_loss: 1328.7124\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 1252.2728 - val_loss: 1291.5786\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 1220.7307 - val_loss: 1260.9861\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 7ms/step - loss: 1187.1438 - val_loss: 1221.3414\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 1153.5725 - val_loss: 1197.1401\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 1120.9852 - val_loss: 1158.2506\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 1091.5964 - val_loss: 1127.2510\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 1060.5764 - val_loss: 1092.2257\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 1031.1858 - val_loss: 1067.0864\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 1003.0241 - val_loss: 1039.4548\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 973.5673 - val_loss: 1005.8687\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 7ms/step - loss: 946.5384 - val_loss: 980.7371\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 5ms/step - loss: 917.6019 - val_loss: 951.2466\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 891.0305 - val_loss: 927.7937\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 866.4851 - val_loss: 901.1324\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 3ms/step - loss: 841.8030 - val_loss: 880.5360\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 816.3212 - val_loss: 848.9135\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 794.3088 - val_loss: 828.7435\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 773.5093 - val_loss: 807.9426\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 752.5734 - val_loss: 786.3368\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 732.9543 - val_loss: 764.0538\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 712.6629 - val_loss: 748.5793\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 694.4504 - val_loss: 729.3947\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 676.1741 - val_loss: 711.0729\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 3ms/step - loss: 661.9887 - val_loss: 695.3444\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 645.1154 - val_loss: 676.5195\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 627.8531 - val_loss: 661.1522\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 614.0097 - val_loss: 646.8947\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 599.9902 - val_loss: 631.2135\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 7ms/step - loss: 586.7300 - val_loss: 619.7684\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 574.0624 - val_loss: 607.6246\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 561.3599 - val_loss: 594.4533\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 3ms/step - loss: 549.9106 - val_loss: 581.9760\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 538.7070 - val_loss: 571.6401\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 527.8953 - val_loss: 558.5237\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 36ms/step - loss: 3575.8457 - val_loss: 2487.0210\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 2528.8628 - val_loss: 2066.6531\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 2096.6050 - val_loss: 1767.3669\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1790.4530 - val_loss: 1521.7585\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 1527.8500 - val_loss: 1291.7395\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 3ms/step - loss: 1265.5811 - val_loss: 1067.5308\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 7ms/step - loss: 1044.0500 - val_loss: 899.6133\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 851.7376 - val_loss: 740.0223\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 5ms/step - loss: 690.8687 - val_loss: 616.3843\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 579.8848 - val_loss: 535.0880\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 7ms/step - loss: 512.8346 - val_loss: 487.8744\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 5ms/step - loss: 470.4166 - val_loss: 454.9475\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 437.4431 - val_loss: 432.0067\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 411.3703 - val_loss: 408.3699\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 390.7757 - val_loss: 387.0946\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 373.6716 - val_loss: 374.2072\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 357.8597 - val_loss: 359.0349\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 7ms/step - loss: 344.4581 - val_loss: 350.0726\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 12ms/step - loss: 332.9792 - val_loss: 336.6389\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 321.6313 - val_loss: 326.4121\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 312.5619 - val_loss: 318.8276\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 5ms/step - loss: 303.4463 - val_loss: 307.7406\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 296.0608 - val_loss: 300.0325\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 7ms/step - loss: 288.6895 - val_loss: 293.1361\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 12ms/step - loss: 282.1208 - val_loss: 289.0221\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 276.1417 - val_loss: 281.5494\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 5ms/step - loss: 270.3352 - val_loss: 275.6216\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 7ms/step - loss: 265.5919 - val_loss: 271.5237\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 260.1667 - val_loss: 265.3499\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 255.8987 - val_loss: 260.7826\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 251.5772 - val_loss: 256.9484\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 247.7040 - val_loss: 253.6150\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 244.1962 - val_loss: 250.2755\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 7ms/step - loss: 240.8805 - val_loss: 246.6116\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 237.8693 - val_loss: 243.1246\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 234.8711 - val_loss: 240.7630\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 231.8099 - val_loss: 236.5158\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 7ms/step - loss: 228.9648 - val_loss: 235.1841\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 226.2380 - val_loss: 232.2556\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 223.8175 - val_loss: 229.4999\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 221.3914 - val_loss: 228.4019\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 219.7034 - val_loss: 224.5431\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 7ms/step - loss: 216.8344 - val_loss: 223.8378\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 215.0069 - val_loss: 221.6161\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 5ms/step - loss: 212.9267 - val_loss: 219.8616\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 5ms/step - loss: 210.9967 - val_loss: 217.0834\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 209.3327 - val_loss: 215.8176\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 207.5491 - val_loss: 213.9029\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 205.7997 - val_loss: 212.9158\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 204.3140 - val_loss: 209.9322\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 202.3079 - val_loss: 210.0887\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 201.0275 - val_loss: 208.1160\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 199.1213 - val_loss: 205.9149\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 197.4514 - val_loss: 204.9416\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 196.2716 - val_loss: 203.0009\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 194.5759 - val_loss: 201.3981\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 193.0689 - val_loss: 200.7916\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 191.6490 - val_loss: 198.6687\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 5ms/step - loss: 190.2924 - val_loss: 196.9629\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 189.1026 - val_loss: 195.9853\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 187.7287 - val_loss: 194.1828\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 186.6230 - val_loss: 193.2680\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 184.9658 - val_loss: 191.4389\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 184.0948 - val_loss: 190.3214\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 182.4012 - val_loss: 189.6220\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 181.1531 - val_loss: 188.4624\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 180.1263 - val_loss: 186.9045\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.0839 - val_loss: 185.3319\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.9348 - val_loss: 183.9802\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.7167 - val_loss: 182.7165\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 5ms/step - loss: 175.4947 - val_loss: 181.8972\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 3ms/step - loss: 175.0038 - val_loss: 180.2447\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 7ms/step - loss: 173.5034 - val_loss: 179.3598\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 172.2740 - val_loss: 178.0691\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 3ms/step - loss: 171.0570 - val_loss: 177.3065\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 170.3748 - val_loss: 176.8649\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 169.4673 - val_loss: 174.4303\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 7ms/step - loss: 168.3502 - val_loss: 174.3273\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 167.2793 - val_loss: 172.3321\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.9873 - val_loss: 171.7523\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 165.4743 - val_loss: 170.1870\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 164.3452 - val_loss: 169.1959\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 7ms/step - loss: 163.5642 - val_loss: 168.6522\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 162.7688 - val_loss: 166.9902\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.7435 - val_loss: 165.8176\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 161.2108 - val_loss: 165.0058\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.2178 - val_loss: 163.8254\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 7ms/step - loss: 159.2560 - val_loss: 162.9931\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.4170 - val_loss: 162.1253\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 3ms/step - loss: 157.5890 - val_loss: 161.0449\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 7ms/step - loss: 157.1701 - val_loss: 160.0987\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 156.4963 - val_loss: 159.4364\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.2850 - val_loss: 158.0181\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.0234 - val_loss: 157.0676\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.2006 - val_loss: 156.6882\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 153.4959 - val_loss: 155.2016\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.5505 - val_loss: 154.5804\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.2488 - val_loss: 153.5825\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 7ms/step - loss: 151.5064 - val_loss: 152.8484\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 150.9358 - val_loss: 151.9811\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 53ms/step - loss: 7852.4868 - val_loss: 6399.3818\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 5ms/step - loss: 4961.2158 - val_loss: 4550.2358\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 3830.9175 - val_loss: 3626.9722\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 3127.9001 - val_loss: 2887.0383\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 13ms/step - loss: 2542.6772 - val_loss: 2353.6560\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 2078.7866 - val_loss: 1916.4009\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1718.7305 - val_loss: 1626.6299\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 5ms/step - loss: 1456.6515 - val_loss: 1337.7587\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 9ms/step - loss: 1231.4952 - val_loss: 1126.7246\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 10ms/step - loss: 1045.5878 - val_loss: 988.7537\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 5ms/step - loss: 904.6216 - val_loss: 846.0518\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 780.9053 - val_loss: 730.5670\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 681.7747 - val_loss: 628.2851\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 603.5481 - val_loss: 570.0762\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 537.1393 - val_loss: 513.6519\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 483.4890 - val_loss: 468.1491\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 3ms/step - loss: 438.9465 - val_loss: 426.0284\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 11ms/step - loss: 401.3306 - val_loss: 405.1007\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 8ms/step - loss: 372.4696 - val_loss: 368.4263\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 346.4012 - val_loss: 339.6170\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 330.2672 - val_loss: 326.7362\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 7ms/step - loss: 309.6975 - val_loss: 303.4797\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 292.5192 - val_loss: 291.0410\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 279.6082 - val_loss: 285.1190\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 266.3228 - val_loss: 271.4631\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 258.1500 - val_loss: 255.5152\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 246.6830 - val_loss: 247.9760\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 7ms/step - loss: 237.9851 - val_loss: 243.8148\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 232.0372 - val_loss: 233.9014\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 224.1945 - val_loss: 223.8715\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 216.6230 - val_loss: 218.3855\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 210.4261 - val_loss: 209.9665\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 7ms/step - loss: 203.3627 - val_loss: 208.4294\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 197.8413 - val_loss: 197.1286\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 7ms/step - loss: 195.0335 - val_loss: 192.5103\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 187.5091 - val_loss: 187.0878\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 5ms/step - loss: 182.9025 - val_loss: 190.9144\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 5ms/step - loss: 178.4459 - val_loss: 176.3436\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 7ms/step - loss: 174.4746 - val_loss: 170.5555\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 5ms/step - loss: 169.9684 - val_loss: 167.3707\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.8300 - val_loss: 163.8582\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 164.7578 - val_loss: 160.7456\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.0734 - val_loss: 160.0906\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 161.6199 - val_loss: 154.6609\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 3ms/step - loss: 155.3366 - val_loss: 146.7027\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 7ms/step - loss: 150.9909 - val_loss: 143.3463\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 7ms/step - loss: 149.0376 - val_loss: 142.3153\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 147.2251 - val_loss: 138.2938\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 143.2023 - val_loss: 134.6334\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 141.0590 - val_loss: 132.0020\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.8849 - val_loss: 131.8509\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 138.2058 - val_loss: 126.7983\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.5038 - val_loss: 128.8354\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 133.8369 - val_loss: 122.2395\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 131.9700 - val_loss: 120.3928\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 131.4526 - val_loss: 118.9686\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 129.4616 - val_loss: 118.9588\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 129.0947 - val_loss: 115.6824\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 7ms/step - loss: 127.3178 - val_loss: 113.3834\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 125.7815 - val_loss: 112.7524\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 125.8511 - val_loss: 111.8523\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 7ms/step - loss: 127.1531 - val_loss: 113.7270\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 127.4598 - val_loss: 110.4353\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 124.9084 - val_loss: 111.2340\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.6450 - val_loss: 107.7050\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 121.3417 - val_loss: 111.0904\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 121.8942 - val_loss: 106.1258\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 120.2201 - val_loss: 105.9621\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 7ms/step - loss: 120.0453 - val_loss: 108.8631\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.6000 - val_loss: 107.4090\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.5140 - val_loss: 105.8119\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.5095 - val_loss: 109.7280\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.8652 - val_loss: 102.9569\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.5465 - val_loss: 103.0716\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.5143 - val_loss: 103.2659\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.8942 - val_loss: 101.0987\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 3ms/step - loss: 114.8369 - val_loss: 100.8379\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 7ms/step - loss: 115.3333 - val_loss: 102.5216\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.4888 - val_loss: 101.8191\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.0617 - val_loss: 102.3221\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.3167 - val_loss: 104.0734\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 7ms/step - loss: 124.1926 - val_loss: 118.6577\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 15ms/step - loss: 119.8336 - val_loss: 99.3756\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 18ms/step - loss: 113.3174 - val_loss: 101.1896\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.9643 - val_loss: 97.9702\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 16ms/step - loss: 113.0368 - val_loss: 105.5434\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 17ms/step - loss: 116.5799 - val_loss: 98.2076\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 8ms/step - loss: 116.2536 - val_loss: 109.5397\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 11ms/step - loss: 114.1387 - val_loss: 105.2175\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 13ms/step - loss: 112.8310 - val_loss: 118.1160\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 7ms/step - loss: 118.2130 - val_loss: 98.1816\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 13ms/step - loss: 111.0867 - val_loss: 100.6007\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.7315 - val_loss: 97.9929\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 7ms/step - loss: 109.4046 - val_loss: 99.2514\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.7400 - val_loss: 95.3719\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.1760 - val_loss: 96.1746\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.2533 - val_loss: 95.1946\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 108.0263 - val_loss: 96.0561\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 106.5702 - val_loss: 94.7086\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 105.4220 - val_loss: 96.6061\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 37ms/step - loss: 3488.9849 - val_loss: 3009.2395\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 2585.4214 - val_loss: 2389.7039\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 1960.4197 - val_loss: 1752.8646\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 3ms/step - loss: 1404.5869 - val_loss: 1186.8770\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 7ms/step - loss: 997.7582 - val_loss: 847.9673\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 756.4022 - val_loss: 670.5750\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 623.2734 - val_loss: 556.9507\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 7ms/step - loss: 525.8208 - val_loss: 475.1945\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 453.5371 - val_loss: 418.7828\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 397.1521 - val_loss: 372.2717\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 7ms/step - loss: 355.1991 - val_loss: 344.0496\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 323.2147 - val_loss: 315.6265\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 298.2454 - val_loss: 301.8559\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 278.3698 - val_loss: 283.3271\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 261.5434 - val_loss: 270.2515\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 248.4585 - val_loss: 260.2587\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 237.0871 - val_loss: 249.2101\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 227.7528 - val_loss: 238.9911\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 219.1667 - val_loss: 230.7109\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 211.2813 - val_loss: 224.3974\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 204.7036 - val_loss: 217.8712\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 7ms/step - loss: 198.3892 - val_loss: 210.3221\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 5ms/step - loss: 193.6054 - val_loss: 205.2310\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 7ms/step - loss: 188.9075 - val_loss: 199.3867\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 181.9932 - val_loss: 194.1716\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.3034 - val_loss: 191.8518\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 174.3139 - val_loss: 188.0498\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 171.7830 - val_loss: 181.8600\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 7ms/step - loss: 165.6219 - val_loss: 175.5754\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 3ms/step - loss: 165.1755 - val_loss: 172.0010\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 160.5881 - val_loss: 166.9973\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 155.7997 - val_loss: 162.8609\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 3ms/step - loss: 152.5352 - val_loss: 159.0013\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 3ms/step - loss: 148.8275 - val_loss: 155.5692\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 3ms/step - loss: 146.1942 - val_loss: 151.8489\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 7ms/step - loss: 144.0967 - val_loss: 148.4287\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 140.9347 - val_loss: 146.0053\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.9480 - val_loss: 146.0448\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 136.0479 - val_loss: 140.1757\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 7ms/step - loss: 134.3277 - val_loss: 138.6744\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 5ms/step - loss: 132.7295 - val_loss: 137.2505\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 131.7128 - val_loss: 132.9070\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 129.3610 - val_loss: 130.7525\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 3ms/step - loss: 128.4452 - val_loss: 132.2982\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 3ms/step - loss: 125.5387 - val_loss: 126.8249\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.7132 - val_loss: 125.5309\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 122.3366 - val_loss: 123.1825\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.7283 - val_loss: 120.7558\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.8445 - val_loss: 118.5670\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.3438 - val_loss: 118.1663\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.4700 - val_loss: 113.9761\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.6448 - val_loss: 112.5927\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.7354 - val_loss: 117.2912\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.7367 - val_loss: 109.0508\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.2542 - val_loss: 108.5805\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 107.5885 - val_loss: 106.1316\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 106.4779 - val_loss: 104.5608\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 3ms/step - loss: 105.8354 - val_loss: 104.0185\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 104.1921 - val_loss: 103.1988\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 3ms/step - loss: 104.0925 - val_loss: 100.3053\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 3ms/step - loss: 102.4648 - val_loss: 100.2816\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 100.3102 - val_loss: 98.3201\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 3ms/step - loss: 99.9919 - val_loss: 96.0257\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 98.6249 - val_loss: 94.9404\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 97.0461 - val_loss: 94.8233\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 7ms/step - loss: 97.0404 - val_loss: 94.3240\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 95.6934 - val_loss: 92.2439\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 93.6586 - val_loss: 92.6413\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 7ms/step - loss: 94.8558 - val_loss: 89.3443\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 8ms/step - loss: 94.3697 - val_loss: 89.6056\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 11ms/step - loss: 91.2780 - val_loss: 87.0219\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 8ms/step - loss: 91.5311 - val_loss: 85.8137\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 11ms/step - loss: 89.4908 - val_loss: 87.5750\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 88.9072 - val_loss: 83.8096\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 87.6985 - val_loss: 83.0990\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 88.2057 - val_loss: 81.9919\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 5ms/step - loss: 87.4505 - val_loss: 81.0924\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 8ms/step - loss: 88.6393 - val_loss: 81.3059\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 11ms/step - loss: 84.6304 - val_loss: 79.6195\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 7ms/step - loss: 83.6849 - val_loss: 78.5023\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 10ms/step - loss: 83.3256 - val_loss: 78.6111\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.3356 - val_loss: 78.8372\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.3106 - val_loss: 76.6322\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 80.5248 - val_loss: 76.0728\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 80.5792 - val_loss: 75.1984\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.2271 - val_loss: 74.9015\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 78.1756 - val_loss: 73.3535\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.6174 - val_loss: 72.8926\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 76.6188 - val_loss: 74.6060\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.5892 - val_loss: 74.9746\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 79.3037 - val_loss: 75.4287\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.6554 - val_loss: 75.8850\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.5518 - val_loss: 72.2812\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.3291 - val_loss: 70.1255\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.7059 - val_loss: 69.8410\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 3ms/step - loss: 73.7702 - val_loss: 68.8676\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.8003 - val_loss: 68.5806\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 3ms/step - loss: 72.1814 - val_loss: 68.5125\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 7ms/step - loss: 73.8127 - val_loss: 68.0492\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.1579 - val_loss: 66.6644\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 39ms/step - loss: 13331.6543 - val_loss: 5520.4126\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 3712.1252 - val_loss: 2439.3403\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 3105.0249 - val_loss: 2374.2373\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 2887.9175 - val_loss: 2334.5537\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 2677.9258 - val_loss: 2155.6001\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 2489.4221 - val_loss: 2059.6855\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 2315.0564 - val_loss: 1939.3835\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 2140.2432 - val_loss: 1823.8011\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1975.4766 - val_loss: 1707.6976\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1822.3772 - val_loss: 1578.2350\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1672.4391 - val_loss: 1487.0376\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1539.2388 - val_loss: 1371.0332\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 7ms/step - loss: 1415.0701 - val_loss: 1306.3174\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 5ms/step - loss: 1290.5964 - val_loss: 1183.8801\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1180.0698 - val_loss: 1118.9557\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 1074.8848 - val_loss: 1015.9803\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 975.4225 - val_loss: 914.7668\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 884.5901 - val_loss: 850.9720\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 799.6788 - val_loss: 784.8386\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 7ms/step - loss: 724.6011 - val_loss: 709.1700\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 650.8920 - val_loss: 628.2599\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 585.9487 - val_loss: 560.4999\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 7ms/step - loss: 527.5857 - val_loss: 523.5615\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 472.4381 - val_loss: 451.5044\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 7ms/step - loss: 437.2254 - val_loss: 411.6783\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 391.7000 - val_loss: 378.4140\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 343.9277 - val_loss: 335.7779\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 307.2984 - val_loss: 300.4250\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 7ms/step - loss: 278.4366 - val_loss: 263.6482\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 252.2020 - val_loss: 240.1241\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 231.1232 - val_loss: 226.8043\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 211.8781 - val_loss: 199.4860\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 7ms/step - loss: 196.1968 - val_loss: 181.0228\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 5ms/step - loss: 185.2287 - val_loss: 165.0904\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 168.7645 - val_loss: 158.1799\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.0889 - val_loss: 146.2951\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 153.3999 - val_loss: 140.8395\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 147.9560 - val_loss: 131.4500\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 141.2232 - val_loss: 126.2192\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 136.3629 - val_loss: 120.7540\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 133.2628 - val_loss: 117.3377\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 129.6378 - val_loss: 116.9412\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 128.8467 - val_loss: 116.5455\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 5ms/step - loss: 128.2619 - val_loss: 110.2518\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 128.1167 - val_loss: 109.0676\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 7ms/step - loss: 127.0089 - val_loss: 107.7211\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.3920 - val_loss: 107.2569\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.0626 - val_loss: 106.2266\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 7ms/step - loss: 120.2695 - val_loss: 104.4939\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.3037 - val_loss: 105.1377\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 5ms/step - loss: 118.3771 - val_loss: 104.9834\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.8851 - val_loss: 105.5933\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.2181 - val_loss: 102.9149\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 5ms/step - loss: 116.3208 - val_loss: 102.3467\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 5ms/step - loss: 115.4936 - val_loss: 101.7258\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.8020 - val_loss: 101.3198\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.3143 - val_loss: 101.8281\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.8665 - val_loss: 100.8689\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.9419 - val_loss: 100.7596\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 13ms/step - loss: 113.4798 - val_loss: 101.7288\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.2417 - val_loss: 100.1109\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.6788 - val_loss: 100.3557\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 13ms/step - loss: 113.4423 - val_loss: 100.1751\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.6483 - val_loss: 99.3062\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.3550 - val_loss: 98.8592\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.8817 - val_loss: 102.5797\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 7ms/step - loss: 112.0674 - val_loss: 99.6475\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.1305 - val_loss: 97.7512\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 7ms/step - loss: 110.9062 - val_loss: 98.2306\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.0170 - val_loss: 97.1827\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 3ms/step - loss: 111.0844 - val_loss: 97.2924\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.0090 - val_loss: 96.7200\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 7ms/step - loss: 110.6990 - val_loss: 96.9758\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.9857 - val_loss: 96.3757\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.0156 - val_loss: 97.4979\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.0706 - val_loss: 95.8607\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 7ms/step - loss: 109.2802 - val_loss: 98.1083\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 108.3662 - val_loss: 95.5397\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.4486 - val_loss: 104.3741\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 3ms/step - loss: 112.1363 - val_loss: 94.2582\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.4352 - val_loss: 99.8969\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.8092 - val_loss: 92.5230\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 106.1726 - val_loss: 92.3251\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 106.7961 - val_loss: 92.0942\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 106.2109 - val_loss: 92.7974\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 104.9407 - val_loss: 90.3849\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 105.1230 - val_loss: 90.6215\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 105.1349 - val_loss: 90.8598\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 104.7540 - val_loss: 88.9422\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 7ms/step - loss: 102.9013 - val_loss: 90.7403\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 102.7062 - val_loss: 88.3400\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 103.3171 - val_loss: 89.2445\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 106.2170 - val_loss: 92.5424\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 7ms/step - loss: 102.5656 - val_loss: 90.5431\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 103.6120 - val_loss: 86.8917\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 101.4682 - val_loss: 88.1802\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 103.0765 - val_loss: 89.9607\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 102.5806 - val_loss: 86.6522\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 5ms/step - loss: 100.1451 - val_loss: 86.0133\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 100.5626 - val_loss: 84.8089\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 37ms/step - loss: 63283.8984 - val_loss: 23214.4395\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 9111.9854 - val_loss: 1828.7008\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 1118.2378 - val_loss: 1006.0117\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 1019.3552 - val_loss: 935.9126\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 5ms/step - loss: 928.5109 - val_loss: 901.0717\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 3ms/step - loss: 882.9903 - val_loss: 854.5102\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 840.9744 - val_loss: 810.3809\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 801.7832 - val_loss: 767.3737\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 764.4822 - val_loss: 732.6968\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 731.9610 - val_loss: 697.1655\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 699.8315 - val_loss: 666.5849\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 672.4197 - val_loss: 641.6434\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 7ms/step - loss: 647.9888 - val_loss: 614.2409\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 624.5075 - val_loss: 590.0114\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 5ms/step - loss: 604.9347 - val_loss: 571.5792\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 7ms/step - loss: 586.3524 - val_loss: 551.5891\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 569.9990 - val_loss: 535.8095\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 554.0440 - val_loss: 516.9991\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 539.6957 - val_loss: 503.0730\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 525.1102 - val_loss: 490.9164\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 512.6005 - val_loss: 477.0282\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 502.0554 - val_loss: 465.4244\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 488.4532 - val_loss: 452.9962\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 479.1156 - val_loss: 444.4959\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 467.1950 - val_loss: 429.0007\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 454.4177 - val_loss: 422.1270\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 444.6646 - val_loss: 410.2600\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 434.2438 - val_loss: 399.5526\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 425.7064 - val_loss: 391.6777\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 416.3886 - val_loss: 379.3418\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 405.1165 - val_loss: 374.3335\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 396.9200 - val_loss: 362.5825\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 7ms/step - loss: 387.1312 - val_loss: 355.9176\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 378.9487 - val_loss: 345.0835\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 369.3812 - val_loss: 338.7395\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 362.2310 - val_loss: 332.7904\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 352.3261 - val_loss: 321.2760\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 344.1721 - val_loss: 314.3179\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 7ms/step - loss: 337.0772 - val_loss: 305.6367\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 330.5746 - val_loss: 301.3773\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 8ms/step - loss: 320.5847 - val_loss: 292.6819\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 313.5923 - val_loss: 285.7500\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 306.7077 - val_loss: 278.8332\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 300.0895 - val_loss: 272.4475\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 294.1066 - val_loss: 266.7389\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 286.7362 - val_loss: 260.7552\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 7ms/step - loss: 280.1214 - val_loss: 257.5491\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 275.0344 - val_loss: 250.1574\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 268.4115 - val_loss: 244.7152\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 263.2431 - val_loss: 240.1263\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 258.4973 - val_loss: 237.8043\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 13ms/step - loss: 253.0890 - val_loss: 230.7075\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 13ms/step - loss: 247.3508 - val_loss: 224.9178\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 8ms/step - loss: 242.1636 - val_loss: 220.3568\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 10ms/step - loss: 237.7323 - val_loss: 217.4798\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 233.7679 - val_loss: 212.5694\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 230.7796 - val_loss: 210.7936\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 224.3207 - val_loss: 204.4257\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 220.2573 - val_loss: 200.9713\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 218.8192 - val_loss: 204.0117\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 5ms/step - loss: 212.5115 - val_loss: 195.0586\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 210.3890 - val_loss: 191.1385\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 206.5772 - val_loss: 190.1585\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 3ms/step - loss: 204.5460 - val_loss: 185.7534\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 7ms/step - loss: 199.8313 - val_loss: 182.3363\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 196.5428 - val_loss: 180.3822\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 193.6502 - val_loss: 178.3036\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 191.2855 - val_loss: 175.9371\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 3ms/step - loss: 192.1726 - val_loss: 172.9650\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 186.0774 - val_loss: 171.6441\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 5ms/step - loss: 185.1202 - val_loss: 168.3578\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 5ms/step - loss: 180.9734 - val_loss: 166.3658\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 179.4343 - val_loss: 165.2764\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 5ms/step - loss: 177.2209 - val_loss: 163.0730\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 174.6491 - val_loss: 160.7120\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 172.8311 - val_loss: 159.0384\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.4398 - val_loss: 159.1705\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 169.3605 - val_loss: 157.0891\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 167.3586 - val_loss: 155.9286\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 167.4293 - val_loss: 154.9265\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 165.8279 - val_loss: 151.1405\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.5602 - val_loss: 152.5670\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 5ms/step - loss: 161.6886 - val_loss: 149.3565\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.8334 - val_loss: 148.1252\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.8815 - val_loss: 146.4418\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.1778 - val_loss: 148.0525\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 3ms/step - loss: 158.1190 - val_loss: 143.6723\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 7ms/step - loss: 155.5376 - val_loss: 143.0464\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.2505 - val_loss: 144.2199\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 7ms/step - loss: 153.5145 - val_loss: 141.6447\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 5ms/step - loss: 152.1555 - val_loss: 141.2034\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 153.8477 - val_loss: 139.6991\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.2619 - val_loss: 138.6205\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.4313 - val_loss: 138.0994\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 7ms/step - loss: 149.7200 - val_loss: 142.8406\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 153.2376 - val_loss: 142.5826\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 148.8122 - val_loss: 135.9796\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 5ms/step - loss: 145.4921 - val_loss: 136.8502\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 145.6691 - val_loss: 134.3000\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 143.8986 - val_loss: 134.2580\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 38ms/step - loss: 114364.8594 - val_loss: 79400.6172\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 61295.2344 - val_loss: 41324.1992\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 3ms/step - loss: 29295.9922 - val_loss: 16828.9082\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 10291.2646 - val_loss: 5210.3247\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 3978.8293 - val_loss: 3567.0769\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 5ms/step - loss: 3401.5164 - val_loss: 3253.9309\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 5ms/step - loss: 3091.9861 - val_loss: 3005.9473\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 2870.9839 - val_loss: 2777.4966\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 2666.9749 - val_loss: 2568.8113\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 2485.2395 - val_loss: 2391.7451\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 2322.2717 - val_loss: 2227.0408\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 2162.0496 - val_loss: 2080.8535\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 2024.3485 - val_loss: 1945.2601\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1897.7924 - val_loss: 1822.5773\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1783.3396 - val_loss: 1705.1373\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 1671.6422 - val_loss: 1602.6790\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 1577.9794 - val_loss: 1506.7762\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1484.3816 - val_loss: 1419.0930\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1402.8617 - val_loss: 1335.7750\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1325.7985 - val_loss: 1261.4041\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 1254.4355 - val_loss: 1194.0045\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 1191.3024 - val_loss: 1128.3552\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 1128.4064 - val_loss: 1070.6776\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 1071.6163 - val_loss: 1015.1403\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 1017.6027 - val_loss: 965.7041\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 8ms/step - loss: 969.9771 - val_loss: 917.5265\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 923.7728 - val_loss: 872.7657\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 879.0970 - val_loss: 832.5012\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 13ms/step - loss: 840.9576 - val_loss: 793.0923\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 7ms/step - loss: 802.4243 - val_loss: 756.5488\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 762.8414 - val_loss: 720.5547\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 730.3303 - val_loss: 689.0145\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 7ms/step - loss: 698.4048 - val_loss: 658.6606\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 669.2864 - val_loss: 629.5031\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 641.1600 - val_loss: 604.0074\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 614.2847 - val_loss: 578.5734\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 589.4491 - val_loss: 556.0608\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 5ms/step - loss: 567.0603 - val_loss: 534.5022\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 544.3301 - val_loss: 513.4078\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 5ms/step - loss: 523.4370 - val_loss: 493.9615\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 7ms/step - loss: 504.2073 - val_loss: 475.7552\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 11ms/step - loss: 485.6155 - val_loss: 457.9545\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 467.5811 - val_loss: 441.8708\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 5ms/step - loss: 451.2358 - val_loss: 425.7328\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 434.3434 - val_loss: 410.3548\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 418.8523 - val_loss: 395.7925\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 404.2658 - val_loss: 382.4920\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 3ms/step - loss: 390.8969 - val_loss: 369.7410\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 377.5753 - val_loss: 357.7022\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 7ms/step - loss: 365.7904 - val_loss: 346.4960\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 5ms/step - loss: 354.7560 - val_loss: 335.7717\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 5ms/step - loss: 343.7055 - val_loss: 325.3298\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 332.9526 - val_loss: 315.5920\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 323.2036 - val_loss: 306.0836\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 312.8485 - val_loss: 297.0137\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 7ms/step - loss: 303.9234 - val_loss: 288.7458\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 295.1163 - val_loss: 280.6432\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 286.4732 - val_loss: 273.0254\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 7ms/step - loss: 278.9520 - val_loss: 265.7517\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 271.2636 - val_loss: 258.5230\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 263.5869 - val_loss: 252.4552\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 257.2469 - val_loss: 245.4239\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 250.7103 - val_loss: 239.3407\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 7ms/step - loss: 244.2063 - val_loss: 233.3747\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 237.5648 - val_loss: 228.2515\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 232.2874 - val_loss: 222.7396\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 7ms/step - loss: 227.1401 - val_loss: 217.9436\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 221.2628 - val_loss: 212.5604\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 216.4448 - val_loss: 208.1718\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 211.6260 - val_loss: 203.9837\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 206.9503 - val_loss: 199.4157\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 203.0738 - val_loss: 195.3312\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 198.5788 - val_loss: 191.6657\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 3ms/step - loss: 194.8624 - val_loss: 187.8835\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 3ms/step - loss: 191.0658 - val_loss: 184.4235\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 187.3296 - val_loss: 181.6112\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.9989 - val_loss: 177.8600\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 3ms/step - loss: 180.6429 - val_loss: 174.6906\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 7ms/step - loss: 177.6074 - val_loss: 171.8163\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 174.5719 - val_loss: 169.0725\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 171.6904 - val_loss: 165.9901\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.2768 - val_loss: 163.5236\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.4041 - val_loss: 160.8636\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 163.3526 - val_loss: 159.1780\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 161.2785 - val_loss: 156.2964\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.1011 - val_loss: 154.6013\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.8777 - val_loss: 152.0921\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 7ms/step - loss: 154.7663 - val_loss: 150.0392\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 152.1917 - val_loss: 148.1138\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 150.5705 - val_loss: 146.3401\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 148.8474 - val_loss: 144.4224\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 3ms/step - loss: 147.8214 - val_loss: 142.9948\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 146.1465 - val_loss: 141.2332\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 145.0985 - val_loss: 140.4656\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 142.4765 - val_loss: 138.1233\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 140.8929 - val_loss: 136.7681\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 139.9388 - val_loss: 135.3710\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 3ms/step - loss: 138.1082 - val_loss: 134.1191\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.1331 - val_loss: 133.7686\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 135.6731 - val_loss: 131.8807\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 39ms/step - loss: 229348.6094 - val_loss: 155777.6250\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 112341.4141 - val_loss: 67958.8125\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 46223.5742 - val_loss: 24984.0664\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 15991.7188 - val_loss: 7662.0591\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 4697.5806 - val_loss: 2091.5493\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1355.1366 - val_loss: 791.3961\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 7ms/step - loss: 629.0850 - val_loss: 596.0841\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 522.5213 - val_loss: 581.9958\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 502.9652 - val_loss: 576.8541\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 494.2085 - val_loss: 568.6815\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 485.6905 - val_loss: 560.8307\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 8ms/step - loss: 477.0189 - val_loss: 551.1660\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 468.5157 - val_loss: 542.6748\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 460.2955 - val_loss: 533.8851\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 13ms/step - loss: 452.0076 - val_loss: 526.0764\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 443.7921 - val_loss: 517.0097\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 13ms/step - loss: 435.7892 - val_loss: 509.1500\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 428.2298 - val_loss: 502.4487\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 420.7831 - val_loss: 493.8898\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 8ms/step - loss: 413.8194 - val_loss: 488.9225\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 12ms/step - loss: 406.7535 - val_loss: 479.0870\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 12ms/step - loss: 399.4362 - val_loss: 472.8394\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 7ms/step - loss: 393.1675 - val_loss: 465.8737\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 11ms/step - loss: 387.3707 - val_loss: 458.9582\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 5ms/step - loss: 381.1880 - val_loss: 453.4492\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 7ms/step - loss: 375.0911 - val_loss: 445.9586\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 5ms/step - loss: 369.3984 - val_loss: 440.1970\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 364.3232 - val_loss: 433.4766\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 358.2561 - val_loss: 427.3734\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 353.8807 - val_loss: 422.6228\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 3ms/step - loss: 347.8941 - val_loss: 416.0655\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 7ms/step - loss: 343.7500 - val_loss: 410.2057\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 5ms/step - loss: 338.2367 - val_loss: 405.3429\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 7ms/step - loss: 333.9969 - val_loss: 399.8852\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 329.6212 - val_loss: 395.0521\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 325.0025 - val_loss: 389.4914\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 321.2692 - val_loss: 384.6214\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 317.1167 - val_loss: 379.9027\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 313.5033 - val_loss: 375.0517\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 310.9499 - val_loss: 371.6942\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 305.3169 - val_loss: 365.7139\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 301.8030 - val_loss: 361.6413\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 7ms/step - loss: 298.4862 - val_loss: 357.3570\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 5ms/step - loss: 295.2764 - val_loss: 352.9193\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 291.8268 - val_loss: 348.7861\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 288.5254 - val_loss: 344.8702\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 7ms/step - loss: 286.5424 - val_loss: 341.1004\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 7ms/step - loss: 282.2455 - val_loss: 337.0787\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 5ms/step - loss: 279.7366 - val_loss: 333.1597\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 276.5599 - val_loss: 329.4849\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 273.7553 - val_loss: 325.9963\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 271.2528 - val_loss: 322.6202\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 268.7780 - val_loss: 319.3941\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 266.0274 - val_loss: 315.7494\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 264.1787 - val_loss: 312.6053\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 262.3221 - val_loss: 309.3261\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 259.4190 - val_loss: 306.3242\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 3ms/step - loss: 257.0206 - val_loss: 303.1762\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 254.7827 - val_loss: 300.1230\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 7ms/step - loss: 252.8357 - val_loss: 297.2399\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 250.4619 - val_loss: 294.4162\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 7ms/step - loss: 248.9321 - val_loss: 291.4907\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 246.6589 - val_loss: 288.7103\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 244.8940 - val_loss: 286.1471\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 243.2070 - val_loss: 283.3817\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 241.6393 - val_loss: 281.0233\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 239.2258 - val_loss: 278.4849\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 237.9414 - val_loss: 276.1096\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 236.4821 - val_loss: 273.4007\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 234.5721 - val_loss: 270.8647\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 7ms/step - loss: 233.1703 - val_loss: 268.6849\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 231.3693 - val_loss: 266.5562\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 5ms/step - loss: 230.1603 - val_loss: 265.0995\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 7ms/step - loss: 229.3602 - val_loss: 262.1248\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 226.9263 - val_loss: 260.1341\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 225.5481 - val_loss: 257.9419\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 224.7578 - val_loss: 256.0007\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 5ms/step - loss: 223.4549 - val_loss: 254.0014\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 5ms/step - loss: 221.8566 - val_loss: 252.0176\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 220.7551 - val_loss: 250.3117\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 219.8306 - val_loss: 248.9471\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 217.8591 - val_loss: 246.6128\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 216.9935 - val_loss: 245.4046\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 216.1166 - val_loss: 243.1132\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 214.6076 - val_loss: 242.6174\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 215.0185 - val_loss: 239.9996\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 7ms/step - loss: 214.4187 - val_loss: 238.6845\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 211.4339 - val_loss: 237.0670\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 5ms/step - loss: 210.4097 - val_loss: 235.6719\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 209.0706 - val_loss: 234.1692\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 208.4239 - val_loss: 232.0938\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 207.7530 - val_loss: 230.8713\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 206.3007 - val_loss: 230.1954\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 205.2525 - val_loss: 227.9237\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 204.4675 - val_loss: 226.3253\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 203.9847 - val_loss: 224.9678\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 202.8185 - val_loss: 224.2353\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 201.5691 - val_loss: 222.0266\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 200.3027 - val_loss: 220.8996\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 199.7019 - val_loss: 221.2841\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 50ms/step - loss: 228924.6250 - val_loss: 175169.7188\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 6ms/step - loss: 143805.1875 - val_loss: 108459.2500\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 7ms/step - loss: 86665.6953 - val_loss: 62169.7617\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 47067.5898 - val_loss: 29022.1660\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 19104.0605 - val_loss: 9624.3418\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 13ms/step - loss: 7341.3037 - val_loss: 5093.5132\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 14ms/step - loss: 5172.1050 - val_loss: 4525.1338\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 10ms/step - loss: 4757.5103 - val_loss: 4188.5640\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 7ms/step - loss: 4419.7183 - val_loss: 3872.0640\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 4111.8291 - val_loss: 3593.7637\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 3837.1240 - val_loss: 3341.6484\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 3585.7539 - val_loss: 3117.9927\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 3348.3430 - val_loss: 2909.8391\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 3130.4268 - val_loss: 2714.3535\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 2927.1807 - val_loss: 2520.6289\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 2701.6331 - val_loss: 2274.3113\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 7ms/step - loss: 2350.1511 - val_loss: 1744.1290\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1768.7140 - val_loss: 1311.6980\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1434.3514 - val_loss: 1061.8754\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 1213.9493 - val_loss: 935.3489\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 1077.3383 - val_loss: 833.5071\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 7ms/step - loss: 964.4161 - val_loss: 764.6747\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 5ms/step - loss: 874.5955 - val_loss: 714.9400\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 807.5585 - val_loss: 667.2404\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 747.5270 - val_loss: 637.1372\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 707.5346 - val_loss: 595.0679\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 654.8727 - val_loss: 560.8720\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 622.5200 - val_loss: 531.2124\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 573.2643 - val_loss: 502.2639\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 541.3712 - val_loss: 474.1349\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 507.7849 - val_loss: 446.2820\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 476.8943 - val_loss: 428.0122\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 448.0536 - val_loss: 396.4368\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 421.5569 - val_loss: 377.9461\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 402.0908 - val_loss: 362.8054\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 7ms/step - loss: 377.0670 - val_loss: 333.9448\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 352.6526 - val_loss: 315.0181\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 5ms/step - loss: 332.9047 - val_loss: 308.2506\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 5ms/step - loss: 316.6055 - val_loss: 281.1403\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 296.3342 - val_loss: 264.4605\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 5ms/step - loss: 283.1809 - val_loss: 252.1735\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 267.0484 - val_loss: 237.2593\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 250.9759 - val_loss: 225.4067\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 240.1064 - val_loss: 213.8309\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 227.6631 - val_loss: 203.0098\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 216.6220 - val_loss: 194.0008\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 7ms/step - loss: 209.1130 - val_loss: 185.8503\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 200.5975 - val_loss: 178.5417\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 7ms/step - loss: 190.0392 - val_loss: 169.1442\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 182.3592 - val_loss: 167.0143\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.9526 - val_loss: 157.8649\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 172.7916 - val_loss: 155.8035\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 3ms/step - loss: 167.0837 - val_loss: 149.9437\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 160.5787 - val_loss: 142.7268\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 158.5489 - val_loss: 138.8459\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.7696 - val_loss: 136.9638\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.6617 - val_loss: 132.5098\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 148.5827 - val_loss: 130.7468\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 145.4264 - val_loss: 128.7557\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 141.1374 - val_loss: 125.4061\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.7124 - val_loss: 124.0416\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 7ms/step - loss: 136.3282 - val_loss: 127.3078\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.4893 - val_loss: 129.6835\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.0393 - val_loss: 124.4319\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 132.0602 - val_loss: 118.8596\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 130.9345 - val_loss: 118.5324\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 131.5101 - val_loss: 117.2384\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 128.9034 - val_loss: 115.9615\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 128.6369 - val_loss: 129.1259\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 3ms/step - loss: 131.3592 - val_loss: 121.4031\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 131.9523 - val_loss: 115.7359\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 3ms/step - loss: 126.3447 - val_loss: 113.4968\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 125.2562 - val_loss: 113.4023\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 127.8276 - val_loss: 118.7608\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 7ms/step - loss: 128.4117 - val_loss: 115.9288\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 129.1793 - val_loss: 113.7560\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 125.4417 - val_loss: 111.6048\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.5145 - val_loss: 111.6501\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.0775 - val_loss: 111.8992\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.9132 - val_loss: 111.4470\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.3848 - val_loss: 113.3110\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 7ms/step - loss: 123.2312 - val_loss: 111.0874\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 5ms/step - loss: 122.8321 - val_loss: 110.6653\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.0388 - val_loss: 111.0034\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 7ms/step - loss: 122.8148 - val_loss: 111.2810\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 7ms/step - loss: 124.2575 - val_loss: 110.6253\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 5ms/step - loss: 121.6069 - val_loss: 110.0614\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.5553 - val_loss: 110.6412\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.9341 - val_loss: 109.1518\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.6329 - val_loss: 113.6909\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.9800 - val_loss: 111.1857\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 7ms/step - loss: 121.0166 - val_loss: 108.6922\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 5ms/step - loss: 120.4697 - val_loss: 108.6838\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.2190 - val_loss: 110.2159\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.1411 - val_loss: 120.5860\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 129.0615 - val_loss: 108.3870\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.3748 - val_loss: 109.6302\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.1749 - val_loss: 107.9592\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 7ms/step - loss: 119.2601 - val_loss: 108.7657\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 12ms/step - loss: 118.8994 - val_loss: 110.2703\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 67ms/step - loss: 164080.5156 - val_loss: 125687.3750\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 100049.7344 - val_loss: 70167.7188\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 52303.6602 - val_loss: 32770.3633\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 23534.7734 - val_loss: 14002.7197\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 10244.4346 - val_loss: 6092.3008\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 5074.6108 - val_loss: 3430.6829\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 7ms/step - loss: 3375.7988 - val_loss: 2746.8887\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 5ms/step - loss: 2970.3201 - val_loss: 2569.0669\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 2844.3081 - val_loss: 2508.1736\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 2780.1360 - val_loss: 2456.4539\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 7ms/step - loss: 2719.1277 - val_loss: 2406.2261\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 2661.4041 - val_loss: 2352.3696\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 2598.9731 - val_loss: 2302.0222\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 2540.5793 - val_loss: 2249.9294\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 2479.1912 - val_loss: 2199.5225\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 2420.1470 - val_loss: 2148.0344\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 7ms/step - loss: 2359.7437 - val_loss: 2099.0222\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 2304.1826 - val_loss: 2047.7238\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 5ms/step - loss: 2244.5127 - val_loss: 2000.6902\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 2189.5183 - val_loss: 1949.5135\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 2132.1665 - val_loss: 1902.4055\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 7ms/step - loss: 2078.3782 - val_loss: 1857.5293\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 5ms/step - loss: 2025.9913 - val_loss: 1810.5449\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 1974.0474 - val_loss: 1765.6863\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 1923.2330 - val_loss: 1722.8740\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 1872.5950 - val_loss: 1680.6365\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 1824.7170 - val_loss: 1638.5449\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 1776.6033 - val_loss: 1598.7491\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 1733.7393 - val_loss: 1559.8323\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 1686.0632 - val_loss: 1521.3917\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 1642.7385 - val_loss: 1483.7435\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 1599.7076 - val_loss: 1447.2740\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 1560.8506 - val_loss: 1413.3126\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 1519.7686 - val_loss: 1378.2720\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 1481.7157 - val_loss: 1345.6046\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 1444.3961 - val_loss: 1312.7285\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 1408.0411 - val_loss: 1282.1719\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 1373.7008 - val_loss: 1251.9819\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 5ms/step - loss: 1339.6031 - val_loss: 1222.3204\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 5ms/step - loss: 1305.6149 - val_loss: 1193.7731\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 1275.0280 - val_loss: 1165.5099\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 1242.6881 - val_loss: 1139.1783\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 1212.7100 - val_loss: 1111.8777\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 1183.5522 - val_loss: 1087.2335\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 1153.4158 - val_loss: 1062.1597\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 1127.1034 - val_loss: 1037.9741\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 1100.5784 - val_loss: 1014.0648\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 1074.9736 - val_loss: 991.1187\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 5ms/step - loss: 1048.3345 - val_loss: 969.6590\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 1025.4916 - val_loss: 948.2700\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 998.6858 - val_loss: 926.5522\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 976.4321 - val_loss: 906.1711\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 953.4189 - val_loss: 886.7542\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 932.7079 - val_loss: 867.1268\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 7ms/step - loss: 910.6494 - val_loss: 848.3868\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 889.5947 - val_loss: 829.9302\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 870.1807 - val_loss: 812.0084\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 848.6595 - val_loss: 794.9982\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 830.1335 - val_loss: 777.6284\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 7ms/step - loss: 812.3466 - val_loss: 761.1034\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 792.5043 - val_loss: 745.3395\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 775.2739 - val_loss: 729.6260\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 7ms/step - loss: 758.3967 - val_loss: 714.2101\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 741.9554 - val_loss: 699.9370\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 7ms/step - loss: 725.7534 - val_loss: 684.9601\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 709.7836 - val_loss: 671.1685\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 695.3208 - val_loss: 656.9969\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 678.6853 - val_loss: 643.9421\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 666.1223 - val_loss: 631.0880\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 650.7420 - val_loss: 617.7501\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 7ms/step - loss: 636.3181 - val_loss: 605.2681\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 622.7582 - val_loss: 593.4495\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 5ms/step - loss: 610.1429 - val_loss: 581.7923\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 597.4558 - val_loss: 570.1900\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 587.5953 - val_loss: 559.0885\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 576.5360 - val_loss: 548.4284\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 5ms/step - loss: 560.8123 - val_loss: 537.8032\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 9ms/step - loss: 549.8735 - val_loss: 527.2307\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 11ms/step - loss: 539.0115 - val_loss: 516.8351\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 527.7141 - val_loss: 507.2935\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 518.1406 - val_loss: 497.6981\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 8ms/step - loss: 506.6165 - val_loss: 488.2493\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 12ms/step - loss: 498.5797 - val_loss: 479.3363\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 5ms/step - loss: 489.3028 - val_loss: 469.9781\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 478.9304 - val_loss: 462.4016\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 469.5306 - val_loss: 453.2160\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 5ms/step - loss: 459.3037 - val_loss: 445.2631\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 450.6920 - val_loss: 437.0758\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 442.7372 - val_loss: 429.0788\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 434.2523 - val_loss: 421.4962\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 7ms/step - loss: 425.6781 - val_loss: 414.7407\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 418.6189 - val_loss: 406.6860\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 411.9920 - val_loss: 399.5792\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 403.3364 - val_loss: 392.9678\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 396.0818 - val_loss: 385.8573\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 389.4356 - val_loss: 379.0863\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 383.7346 - val_loss: 373.3392\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 376.5323 - val_loss: 366.8386\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 369.1335 - val_loss: 361.4564\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 8ms/step - loss: 363.0945 - val_loss: 354.5478\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 37ms/step - loss: 14155.0166 - val_loss: 7688.9546\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 3602.2019 - val_loss: 2127.9622\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 3ms/step - loss: 2103.7905 - val_loss: 1782.9196\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1820.3746 - val_loss: 1683.4985\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1564.0582 - val_loss: 1517.4863\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 7ms/step - loss: 1375.6731 - val_loss: 1354.6373\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1206.7421 - val_loss: 1213.9792\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 1054.2567 - val_loss: 1088.8993\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 5ms/step - loss: 931.6172 - val_loss: 987.9131\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 5ms/step - loss: 813.9966 - val_loss: 854.9183\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 717.4666 - val_loss: 773.4130\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 641.3109 - val_loss: 681.5392\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 572.6062 - val_loss: 610.9907\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 513.2045 - val_loss: 553.3978\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 464.9583 - val_loss: 519.0302\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 420.9297 - val_loss: 457.6491\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 382.0465 - val_loss: 410.2551\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 350.2284 - val_loss: 378.4538\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 7ms/step - loss: 323.9011 - val_loss: 346.3176\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 5ms/step - loss: 300.8872 - val_loss: 337.8843\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 283.3723 - val_loss: 299.4740\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 264.8981 - val_loss: 288.7520\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 253.5736 - val_loss: 264.7003\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 7ms/step - loss: 239.0017 - val_loss: 254.5060\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 230.3838 - val_loss: 236.6681\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 218.5404 - val_loss: 233.2351\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 212.1312 - val_loss: 218.2134\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 204.5118 - val_loss: 207.0058\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 7ms/step - loss: 195.8484 - val_loss: 200.9315\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 195.6419 - val_loss: 193.9681\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 184.6904 - val_loss: 187.1203\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 182.1978 - val_loss: 182.0422\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.2755 - val_loss: 176.9883\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 171.7757 - val_loss: 172.2890\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 170.6375 - val_loss: 169.4660\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 165.2713 - val_loss: 172.7739\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 166.3836 - val_loss: 170.5448\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.5190 - val_loss: 157.7102\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 160.3816 - val_loss: 156.7802\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 5ms/step - loss: 157.0969 - val_loss: 157.4526\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 5ms/step - loss: 153.9105 - val_loss: 150.6582\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.9163 - val_loss: 146.5112\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 148.4534 - val_loss: 144.6497\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 146.1111 - val_loss: 141.8036\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 143.7429 - val_loss: 139.5317\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 141.2979 - val_loss: 138.9922\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 7ms/step - loss: 140.5219 - val_loss: 136.7713\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 139.9717 - val_loss: 134.6583\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 137.1320 - val_loss: 133.8703\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 136.1503 - val_loss: 131.0133\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 135.7608 - val_loss: 130.2759\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 133.2805 - val_loss: 130.7875\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 132.3203 - val_loss: 127.8985\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 130.7690 - val_loss: 130.0653\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 130.6822 - val_loss: 125.6974\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 129.6533 - val_loss: 124.6978\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 12ms/step - loss: 128.5592 - val_loss: 128.3520\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 128.8283 - val_loss: 122.7580\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 127.3431 - val_loss: 121.6697\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 5ms/step - loss: 125.3031 - val_loss: 121.8068\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 127.6612 - val_loss: 131.2516\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 7ms/step - loss: 126.1899 - val_loss: 120.0867\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 11ms/step - loss: 124.2852 - val_loss: 118.3155\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 5ms/step - loss: 122.4193 - val_loss: 118.6501\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.3994 - val_loss: 118.6523\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 5ms/step - loss: 122.8386 - val_loss: 118.9626\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.2053 - val_loss: 117.4040\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 13ms/step - loss: 122.2103 - val_loss: 118.0213\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 13ms/step - loss: 119.8398 - val_loss: 115.9900\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.7419 - val_loss: 115.3599\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.8832 - val_loss: 118.0323\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 119.2409 - val_loss: 113.7355\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.4001 - val_loss: 123.7156\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.3175 - val_loss: 114.9107\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.8734 - val_loss: 117.6972\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 5ms/step - loss: 119.7554 - val_loss: 118.6061\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.9426 - val_loss: 118.6420\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.9839 - val_loss: 113.6554\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.8491 - val_loss: 115.3289\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 7ms/step - loss: 115.8711 - val_loss: 111.7248\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 5ms/step - loss: 116.0149 - val_loss: 111.6874\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.4019 - val_loss: 110.4218\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.7449 - val_loss: 111.7881\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.7056 - val_loss: 111.6768\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.2575 - val_loss: 110.8138\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.6067 - val_loss: 111.5483\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.5983 - val_loss: 110.2337\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.0995 - val_loss: 109.4359\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.9611 - val_loss: 109.9689\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 114.6357 - val_loss: 109.6119\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.0209 - val_loss: 111.5249\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.6703 - val_loss: 113.5052\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.8561 - val_loss: 110.8325\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.7268 - val_loss: 108.9052\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.2941 - val_loss: 108.5807\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.9422 - val_loss: 113.4936\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.8200 - val_loss: 110.9595\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.0969 - val_loss: 108.1900\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.5381 - val_loss: 112.6143\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.6428 - val_loss: 107.9856\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 256016.2812 - val_loss: 189388.8750\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 141651.7500 - val_loss: 97189.7500\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 68294.7266 - val_loss: 42972.9805\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 28236.4355 - val_loss: 15337.4131\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 9586.3291 - val_loss: 4635.7505\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 7ms/step - loss: 3291.1169 - val_loss: 2026.1619\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 2056.2559 - val_loss: 1609.3749\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 1829.2339 - val_loss: 1484.1703\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1698.6069 - val_loss: 1371.0924\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 1573.8486 - val_loss: 1270.3123\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 1458.8960 - val_loss: 1170.9188\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 5ms/step - loss: 1351.7395 - val_loss: 1082.4412\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 1250.4567 - val_loss: 999.7386\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1157.7804 - val_loss: 924.4476\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1072.7029 - val_loss: 856.8824\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 7ms/step - loss: 992.7498 - val_loss: 792.6607\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 5ms/step - loss: 919.8135 - val_loss: 736.8090\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 852.7413 - val_loss: 683.2901\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 789.6552 - val_loss: 635.9760\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 733.6615 - val_loss: 596.7133\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 682.9440 - val_loss: 557.3665\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 637.8480 - val_loss: 523.2336\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 596.2908 - val_loss: 493.0285\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 558.7818 - val_loss: 464.4970\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 524.4872 - val_loss: 440.0264\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 495.1223 - val_loss: 416.7238\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 465.8983 - val_loss: 396.8683\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 441.3001 - val_loss: 376.8497\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 418.1686 - val_loss: 359.9879\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 397.0299 - val_loss: 343.8186\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 377.8781 - val_loss: 329.0911\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 7ms/step - loss: 359.8041 - val_loss: 317.1709\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 343.9525 - val_loss: 302.6664\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 328.8782 - val_loss: 291.2222\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 7ms/step - loss: 313.5151 - val_loss: 278.9485\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 299.9872 - val_loss: 268.1878\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 287.5114 - val_loss: 257.9766\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 274.9224 - val_loss: 249.9367\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 263.9557 - val_loss: 239.4066\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 253.6464 - val_loss: 231.8929\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 7ms/step - loss: 246.4606 - val_loss: 224.1445\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 7ms/step - loss: 234.8416 - val_loss: 215.8005\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 7ms/step - loss: 225.4389 - val_loss: 208.6764\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 217.7139 - val_loss: 202.5506\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 209.7922 - val_loss: 195.5802\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 202.8110 - val_loss: 188.4732\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 13ms/step - loss: 196.3476 - val_loss: 182.6898\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 189.1507 - val_loss: 176.4210\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 5ms/step - loss: 183.5042 - val_loss: 171.1083\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.3822 - val_loss: 166.2212\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.2530 - val_loss: 162.5447\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.8396 - val_loss: 157.0835\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.8016 - val_loss: 153.0064\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 13ms/step - loss: 158.3114 - val_loss: 149.7615\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 8ms/step - loss: 154.5321 - val_loss: 145.9154\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 7ms/step - loss: 150.2963 - val_loss: 142.9388\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 11ms/step - loss: 147.1436 - val_loss: 140.3370\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 143.3050 - val_loss: 137.6276\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 141.0210 - val_loss: 135.4999\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 7ms/step - loss: 138.7909 - val_loss: 133.4720\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 5ms/step - loss: 135.9455 - val_loss: 131.5969\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 133.9907 - val_loss: 130.2775\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 132.2065 - val_loss: 128.1550\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 130.6381 - val_loss: 126.7746\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 128.5416 - val_loss: 125.1918\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 7ms/step - loss: 127.7558 - val_loss: 123.9369\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 126.3227 - val_loss: 122.7689\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 124.8434 - val_loss: 121.6092\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.8010 - val_loss: 120.4116\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 5ms/step - loss: 123.1936 - val_loss: 119.6258\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 122.2107 - val_loss: 118.5306\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 7ms/step - loss: 120.9419 - val_loss: 117.9425\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.1219 - val_loss: 117.0024\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.9760 - val_loss: 116.3050\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.5953 - val_loss: 115.4268\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.8416 - val_loss: 114.8154\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.3921 - val_loss: 115.3686\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 7ms/step - loss: 117.8345 - val_loss: 113.7113\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.5799 - val_loss: 113.1460\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.9940 - val_loss: 112.5185\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.5420 - val_loss: 111.9838\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 5ms/step - loss: 115.2203 - val_loss: 112.1842\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.3910 - val_loss: 111.2853\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.6334 - val_loss: 111.0168\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.9961 - val_loss: 110.2737\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.4349 - val_loss: 109.8463\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.9098 - val_loss: 109.5727\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 7ms/step - loss: 112.9878 - val_loss: 109.3411\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.0626 - val_loss: 109.7207\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.4388 - val_loss: 108.4811\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.8102 - val_loss: 108.0709\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.6100 - val_loss: 107.8673\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.1668 - val_loss: 107.3982\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 5ms/step - loss: 111.4441 - val_loss: 107.7529\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.5354 - val_loss: 107.5049\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.1598 - val_loss: 107.3574\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.7523 - val_loss: 106.9885\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.3594 - val_loss: 106.7322\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 5ms/step - loss: 109.4916 - val_loss: 106.1018\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.4347 - val_loss: 105.8447\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 38ms/step - loss: 274842.0938 - val_loss: 206376.5781\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 3ms/step - loss: 156856.5625 - val_loss: 113796.1172\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 7ms/step - loss: 82826.0781 - val_loss: 57358.8359\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 39671.1797 - val_loss: 25873.7773\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 7ms/step - loss: 17016.1504 - val_loss: 10555.3232\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 6871.1909 - val_loss: 4216.2876\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 3080.8398 - val_loss: 2056.8179\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1939.5260 - val_loss: 1421.9640\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1647.7336 - val_loss: 1231.1676\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1549.8478 - val_loss: 1165.6488\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 1491.1992 - val_loss: 1114.5953\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1436.8811 - val_loss: 1070.3768\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 1385.6630 - val_loss: 1028.9202\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 7ms/step - loss: 1333.4885 - val_loss: 989.1121\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 5ms/step - loss: 1280.0060 - val_loss: 949.8569\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 1228.8257 - val_loss: 907.8533\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 5ms/step - loss: 1179.2582 - val_loss: 868.4121\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1128.0309 - val_loss: 830.8319\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 3ms/step - loss: 1078.9565 - val_loss: 796.1800\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1031.4589 - val_loss: 757.6725\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 986.8748 - val_loss: 723.1921\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 939.9196 - val_loss: 687.2929\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 897.6785 - val_loss: 656.6705\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 855.2187 - val_loss: 621.1361\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 816.2346 - val_loss: 590.9020\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 775.1736 - val_loss: 561.3107\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 738.0342 - val_loss: 534.8242\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 13ms/step - loss: 702.0187 - val_loss: 508.4800\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 669.1864 - val_loss: 483.4438\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 7ms/step - loss: 635.0463 - val_loss: 456.9150\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 603.4061 - val_loss: 432.0281\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 572.8510 - val_loss: 411.0022\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 7ms/step - loss: 543.8862 - val_loss: 390.6574\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 516.7369 - val_loss: 371.9378\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 493.3075 - val_loss: 351.8990\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 13ms/step - loss: 465.9580 - val_loss: 332.2046\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 443.5336 - val_loss: 316.8481\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 419.6140 - val_loss: 300.9547\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 13ms/step - loss: 399.3954 - val_loss: 284.9898\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 379.3671 - val_loss: 270.9965\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 8ms/step - loss: 361.2661 - val_loss: 258.1789\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 9ms/step - loss: 345.1482 - val_loss: 246.4934\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 328.2612 - val_loss: 235.4833\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 314.6051 - val_loss: 225.8401\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 299.8253 - val_loss: 216.4046\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 7ms/step - loss: 287.1693 - val_loss: 207.4333\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 275.0571 - val_loss: 199.0385\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 263.7568 - val_loss: 192.7696\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 253.3241 - val_loss: 185.5195\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 244.0055 - val_loss: 179.1240\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 3ms/step - loss: 235.5413 - val_loss: 173.7995\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 3ms/step - loss: 227.6648 - val_loss: 167.7489\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 219.2923 - val_loss: 163.4078\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 212.7869 - val_loss: 159.2552\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 206.5539 - val_loss: 156.3331\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 200.9318 - val_loss: 152.0235\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 195.2034 - val_loss: 149.0432\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 190.9009 - val_loss: 146.0605\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 186.1043 - val_loss: 143.6619\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 181.7009 - val_loss: 141.5492\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 178.0029 - val_loss: 139.0730\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 174.5674 - val_loss: 137.3734\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 7ms/step - loss: 171.7833 - val_loss: 135.7825\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 168.7613 - val_loss: 134.1111\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 165.9314 - val_loss: 132.8455\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 163.4173 - val_loss: 131.8426\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 161.6959 - val_loss: 130.5777\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.0861 - val_loss: 129.7178\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 157.4390 - val_loss: 128.6014\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 155.2137 - val_loss: 127.8351\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 153.3485 - val_loss: 127.0252\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 151.8275 - val_loss: 126.4774\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 150.3923 - val_loss: 125.9482\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 148.9765 - val_loss: 125.2064\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 148.2742 - val_loss: 124.6852\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 146.4836 - val_loss: 124.6008\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 145.2400 - val_loss: 123.8309\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 144.0511 - val_loss: 123.5167\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 5ms/step - loss: 143.1121 - val_loss: 123.1356\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 5ms/step - loss: 142.5199 - val_loss: 122.7415\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 5ms/step - loss: 141.4584 - val_loss: 122.4551\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 5ms/step - loss: 140.5953 - val_loss: 122.1628\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 139.8335 - val_loss: 121.9023\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.7523 - val_loss: 121.6431\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 138.3962 - val_loss: 121.3749\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 7ms/step - loss: 137.3736 - val_loss: 121.0287\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 7ms/step - loss: 136.7463 - val_loss: 120.6922\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 135.9863 - val_loss: 120.4748\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 135.4555 - val_loss: 120.1502\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 134.7958 - val_loss: 119.8621\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.2323 - val_loss: 119.7167\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 133.7184 - val_loss: 119.1974\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 133.4458 - val_loss: 119.1593\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 132.9664 - val_loss: 118.6650\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 7ms/step - loss: 131.9699 - val_loss: 118.3971\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 131.6149 - val_loss: 118.0564\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 130.9691 - val_loss: 117.6433\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 130.4686 - val_loss: 117.4867\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 129.9242 - val_loss: 117.1230\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 129.8340 - val_loss: 116.8075\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 36ms/step - loss: 2262.4465 - val_loss: 1586.8600\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 1551.2842 - val_loss: 1210.7977\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 7ms/step - loss: 1226.5232 - val_loss: 959.3690\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 992.7321 - val_loss: 737.3831\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 805.0198 - val_loss: 587.6225\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 5ms/step - loss: 658.8607 - val_loss: 475.1310\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 531.7973 - val_loss: 399.5466\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 443.9827 - val_loss: 361.5215\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 399.3676 - val_loss: 342.9083\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 7ms/step - loss: 371.2330 - val_loss: 330.4316\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 348.7509 - val_loss: 328.5745\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 328.4803 - val_loss: 304.2664\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 309.0168 - val_loss: 291.2104\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 294.4128 - val_loss: 280.9159\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 282.8533 - val_loss: 268.2025\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 267.1700 - val_loss: 259.3350\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 7ms/step - loss: 254.9713 - val_loss: 255.5533\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 244.8570 - val_loss: 245.6089\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 237.4460 - val_loss: 237.1385\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 230.0303 - val_loss: 230.2578\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 7ms/step - loss: 220.4061 - val_loss: 222.7452\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 213.4221 - val_loss: 215.5595\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 5ms/step - loss: 205.1620 - val_loss: 209.7244\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 7ms/step - loss: 199.2498 - val_loss: 202.3309\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 12ms/step - loss: 192.7123 - val_loss: 194.5487\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 7ms/step - loss: 186.8460 - val_loss: 190.3913\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 13ms/step - loss: 181.9526 - val_loss: 180.4012\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 177.4512 - val_loss: 174.1356\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 7ms/step - loss: 173.2106 - val_loss: 168.3862\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 3ms/step - loss: 169.6846 - val_loss: 164.5320\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.3587 - val_loss: 160.0741\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 8ms/step - loss: 159.6219 - val_loss: 155.5752\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.7868 - val_loss: 150.1730\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 154.5510 - val_loss: 150.2979\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.8468 - val_loss: 147.1000\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 151.2233 - val_loss: 142.4899\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 143.6978 - val_loss: 139.9299\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 142.7011 - val_loss: 136.8391\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 139.6012 - val_loss: 132.8046\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 137.1765 - val_loss: 132.6698\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.1131 - val_loss: 128.0186\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.0730 - val_loss: 126.9026\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 7ms/step - loss: 137.3812 - val_loss: 127.7607\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 135.6185 - val_loss: 126.1895\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 128.2280 - val_loss: 121.8946\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 128.0065 - val_loss: 121.6321\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 129.9358 - val_loss: 119.7727\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 125.4124 - val_loss: 117.5393\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 3ms/step - loss: 125.0815 - val_loss: 118.0485\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 123.8122 - val_loss: 120.5195\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 127.2926 - val_loss: 114.9964\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 7ms/step - loss: 122.4571 - val_loss: 114.7799\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 5ms/step - loss: 121.1748 - val_loss: 113.8574\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 120.5738 - val_loss: 120.5202\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 120.0260 - val_loss: 114.4809\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.5727 - val_loss: 111.8921\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 7ms/step - loss: 118.0784 - val_loss: 115.6703\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.4973 - val_loss: 111.2262\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 5ms/step - loss: 117.7133 - val_loss: 111.2648\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 7ms/step - loss: 116.6370 - val_loss: 109.5098\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.6898 - val_loss: 113.1548\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.2357 - val_loss: 108.5470\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.5627 - val_loss: 108.6051\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 7ms/step - loss: 115.2720 - val_loss: 108.3737\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.6815 - val_loss: 107.1350\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.9544 - val_loss: 111.4431\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.9168 - val_loss: 107.4041\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 7ms/step - loss: 115.7531 - val_loss: 106.4417\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 5ms/step - loss: 115.8412 - val_loss: 107.1524\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.1209 - val_loss: 107.2560\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.0913 - val_loss: 109.9402\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.7624 - val_loss: 105.6330\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.2609 - val_loss: 124.3589\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 5ms/step - loss: 117.4228 - val_loss: 116.8461\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.6601 - val_loss: 105.4861\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.3167 - val_loss: 104.9636\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 7ms/step - loss: 113.1234 - val_loss: 105.7320\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.2815 - val_loss: 107.4895\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 7ms/step - loss: 114.6888 - val_loss: 104.8278\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 5ms/step - loss: 118.7163 - val_loss: 119.9730\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.3139 - val_loss: 104.3859\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.0509 - val_loss: 110.9594\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.6755 - val_loss: 106.7327\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.2699 - val_loss: 106.2808\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.7394 - val_loss: 104.8771\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.3589 - val_loss: 103.8381\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 5ms/step - loss: 112.0701 - val_loss: 104.1515\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.2729 - val_loss: 105.1801\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.1534 - val_loss: 107.1913\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 113.0800 - val_loss: 105.1581\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 3ms/step - loss: 114.2716 - val_loss: 103.3250\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 3ms/step - loss: 114.7656 - val_loss: 107.3446\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 5ms/step - loss: 111.2073 - val_loss: 107.4446\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 5ms/step - loss: 112.0474 - val_loss: 105.2006\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 5ms/step - loss: 113.2060 - val_loss: 103.6147\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.0973 - val_loss: 104.3112\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.5731 - val_loss: 105.3072\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.1227 - val_loss: 103.3781\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.0174 - val_loss: 111.4177\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 7ms/step - loss: 112.6758 - val_loss: 103.0704\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 47ms/step - loss: 212332.2969 - val_loss: 163835.1250\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 19ms/step - loss: 133317.1875 - val_loss: 92393.6406\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 63149.8867 - val_loss: 32324.0195\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 16463.7656 - val_loss: 7473.5923\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 7ms/step - loss: 6382.7856 - val_loss: 6453.8828\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 13ms/step - loss: 5811.7974 - val_loss: 5953.7300\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 5386.7456 - val_loss: 5601.0176\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 7ms/step - loss: 5050.6284 - val_loss: 5236.2915\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 12ms/step - loss: 4732.7915 - val_loss: 4936.8018\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 7ms/step - loss: 4441.6455 - val_loss: 4627.0933\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 4172.9082 - val_loss: 4364.2637\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 5ms/step - loss: 3933.8335 - val_loss: 4105.4287\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 3712.6606 - val_loss: 3873.4749\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 7ms/step - loss: 3509.7000 - val_loss: 3669.7095\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 5ms/step - loss: 3325.2952 - val_loss: 3491.8738\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 3158.1499 - val_loss: 3304.9832\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 3008.9771 - val_loss: 3139.7988\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 2868.1924 - val_loss: 2994.8108\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 2722.2664 - val_loss: 2842.5051\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 2603.2761 - val_loss: 2715.5596\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 2488.6104 - val_loss: 2580.6904\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 2386.2168 - val_loss: 2492.1399\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 7ms/step - loss: 2276.4600 - val_loss: 2360.6855\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 2180.1807 - val_loss: 2260.7083\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 2093.5044 - val_loss: 2170.8740\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 2010.0696 - val_loss: 2076.5515\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 1933.9246 - val_loss: 1986.1151\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 1860.1155 - val_loss: 1916.8467\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 1793.9006 - val_loss: 1834.4673\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 1734.4619 - val_loss: 1767.2025\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 1673.8652 - val_loss: 1706.5079\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 1616.3522 - val_loss: 1633.7461\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 1560.0399 - val_loss: 1572.5940\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 1506.2747 - val_loss: 1518.2452\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 1462.4274 - val_loss: 1460.7501\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 1412.5760 - val_loss: 1412.3860\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 1369.4628 - val_loss: 1366.9259\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 1326.5427 - val_loss: 1318.4189\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 7ms/step - loss: 1287.4630 - val_loss: 1283.6786\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 5ms/step - loss: 1249.5414 - val_loss: 1231.2699\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 1216.1481 - val_loss: 1193.7308\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 1177.5879 - val_loss: 1154.5247\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 1145.3085 - val_loss: 1121.5516\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 1115.3342 - val_loss: 1091.1454\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 1080.4110 - val_loss: 1053.4231\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 1049.9152 - val_loss: 1019.0196\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 1023.6426 - val_loss: 996.5811\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 995.7562 - val_loss: 961.3345\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 968.2615 - val_loss: 931.1007\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 944.6288 - val_loss: 908.8905\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 923.9017 - val_loss: 878.3715\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 902.6403 - val_loss: 853.4144\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 873.7476 - val_loss: 829.1411\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 850.1624 - val_loss: 804.2144\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 7ms/step - loss: 829.1935 - val_loss: 791.3594\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 810.9987 - val_loss: 760.1495\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 798.6823 - val_loss: 749.7649\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 5ms/step - loss: 770.4532 - val_loss: 726.1384\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 7ms/step - loss: 751.2396 - val_loss: 701.8514\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 733.5138 - val_loss: 689.4749\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 3ms/step - loss: 716.0878 - val_loss: 669.4307\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 699.6601 - val_loss: 652.6357\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 7ms/step - loss: 682.2453 - val_loss: 635.1770\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 668.0460 - val_loss: 626.8058\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 658.0864 - val_loss: 601.5088\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 640.7828 - val_loss: 595.1317\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 622.7330 - val_loss: 579.3964\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 609.3463 - val_loss: 562.4152\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 596.5247 - val_loss: 549.2372\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 586.5171 - val_loss: 542.0954\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 569.3042 - val_loss: 524.3185\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 558.7743 - val_loss: 518.5322\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 556.2178 - val_loss: 498.3990\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 541.0259 - val_loss: 487.6267\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 525.1823 - val_loss: 482.5218\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 5ms/step - loss: 511.9725 - val_loss: 467.7629\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 7ms/step - loss: 502.4483 - val_loss: 463.8527\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 494.8228 - val_loss: 452.5800\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 7ms/step - loss: 482.7923 - val_loss: 438.4413\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 473.9903 - val_loss: 430.7020\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 463.9908 - val_loss: 420.2418\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 456.4279 - val_loss: 421.5750\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 446.2025 - val_loss: 403.0937\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 438.7978 - val_loss: 396.1649\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 7ms/step - loss: 429.7410 - val_loss: 392.6026\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 420.4007 - val_loss: 381.3766\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 415.7453 - val_loss: 381.5416\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 405.8323 - val_loss: 366.5592\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 397.9405 - val_loss: 361.6409\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 392.7622 - val_loss: 356.4040\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 3ms/step - loss: 383.6826 - val_loss: 347.5267\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 377.2748 - val_loss: 340.9867\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 370.5414 - val_loss: 337.2565\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 364.5697 - val_loss: 328.7108\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 358.0230 - val_loss: 327.6599\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 12ms/step - loss: 352.3723 - val_loss: 317.5724\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 5ms/step - loss: 347.4178 - val_loss: 319.2827\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 345.9249 - val_loss: 310.7089\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 5ms/step - loss: 337.5522 - val_loss: 303.0693\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 329.3981 - val_loss: 297.1396\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 56ms/step - loss: 7095.7759 - val_loss: 3413.0752\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 16ms/step - loss: 1668.2217 - val_loss: 980.9510\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 902.1662 - val_loss: 728.0850\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 699.1010 - val_loss: 623.5059\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 582.2993 - val_loss: 546.4865\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 5ms/step - loss: 502.5911 - val_loss: 474.2677\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 5ms/step - loss: 444.5676 - val_loss: 426.2920\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 396.8878 - val_loss: 385.4629\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 358.6909 - val_loss: 354.5364\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 327.9513 - val_loss: 323.6502\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 301.4551 - val_loss: 302.7948\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 279.7612 - val_loss: 281.4737\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 3ms/step - loss: 261.7397 - val_loss: 266.7992\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 247.3602 - val_loss: 253.2664\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 5ms/step - loss: 235.2760 - val_loss: 240.9051\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 224.2671 - val_loss: 232.1286\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 216.1520 - val_loss: 224.4438\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 207.0737 - val_loss: 215.7633\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 3ms/step - loss: 200.2211 - val_loss: 208.1216\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 194.7163 - val_loss: 203.2916\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 5ms/step - loss: 188.9123 - val_loss: 197.8128\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 5ms/step - loss: 184.5119 - val_loss: 193.6562\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.9932 - val_loss: 188.8881\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 175.9893 - val_loss: 184.1641\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 173.4583 - val_loss: 179.7704\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 168.6124 - val_loss: 175.2603\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 165.7846 - val_loss: 171.8564\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 5ms/step - loss: 162.6899 - val_loss: 169.5937\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.2706 - val_loss: 165.3050\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 157.4647 - val_loss: 163.5211\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 3ms/step - loss: 154.4985 - val_loss: 160.1944\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 152.1370 - val_loss: 158.7977\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 5ms/step - loss: 150.2316 - val_loss: 154.7109\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 147.9439 - val_loss: 151.5901\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 147.1985 - val_loss: 149.4336\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 145.5647 - val_loss: 148.8039\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 7ms/step - loss: 142.8880 - val_loss: 144.8064\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 140.4271 - val_loss: 143.9824\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 7ms/step - loss: 138.7549 - val_loss: 140.9030\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 137.5224 - val_loss: 138.7424\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 136.1617 - val_loss: 138.5887\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.5473 - val_loss: 135.5137\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 133.0661 - val_loss: 134.5464\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 132.0303 - val_loss: 132.4322\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 5ms/step - loss: 130.7628 - val_loss: 130.9468\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 5ms/step - loss: 130.1685 - val_loss: 131.3313\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 128.6894 - val_loss: 127.7629\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 128.0148 - val_loss: 126.6478\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 127.1522 - val_loss: 126.5131\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 126.0581 - val_loss: 124.0662\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 125.1469 - val_loss: 126.7267\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 125.9876 - val_loss: 121.9395\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 5ms/step - loss: 123.2548 - val_loss: 122.8588\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 5ms/step - loss: 123.8971 - val_loss: 120.4063\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 124.3836 - val_loss: 119.1359\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 121.5261 - val_loss: 120.0203\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 121.6603 - val_loss: 117.5576\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.1644 - val_loss: 116.8815\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.1246 - val_loss: 116.8670\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.2625 - val_loss: 115.3632\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 119.0135 - val_loss: 117.1394\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.7658 - val_loss: 114.8993\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.9119 - val_loss: 113.9666\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.9571 - val_loss: 113.0737\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.1993 - val_loss: 114.1880\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.8709 - val_loss: 112.1320\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.0404 - val_loss: 116.1509\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 7ms/step - loss: 118.2073 - val_loss: 111.9550\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 5ms/step - loss: 116.9279 - val_loss: 111.2727\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.4884 - val_loss: 110.4938\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.0969 - val_loss: 110.2843\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.7260 - val_loss: 109.7284\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.5406 - val_loss: 109.3162\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 7ms/step - loss: 115.2208 - val_loss: 109.3255\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.4297 - val_loss: 108.6108\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.8564 - val_loss: 108.3534\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.3148 - val_loss: 107.8870\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.3016 - val_loss: 107.4059\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.3213 - val_loss: 107.3043\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 5ms/step - loss: 112.8679 - val_loss: 106.9859\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.4664 - val_loss: 107.3796\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 8ms/step - loss: 113.2026 - val_loss: 106.5687\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 11ms/step - loss: 112.5348 - val_loss: 106.4429\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.3194 - val_loss: 105.8011\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 5ms/step - loss: 116.6952 - val_loss: 106.4571\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 7ms/step - loss: 112.5396 - val_loss: 105.6660\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 5ms/step - loss: 111.5456 - val_loss: 105.5099\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.1880 - val_loss: 104.9113\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.3828 - val_loss: 105.2074\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 13ms/step - loss: 111.5128 - val_loss: 104.9942\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 15ms/step - loss: 111.7133 - val_loss: 105.8624\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.7597 - val_loss: 107.5520\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 7ms/step - loss: 112.1410 - val_loss: 104.4558\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 12ms/step - loss: 111.5278 - val_loss: 104.4443\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.0573 - val_loss: 104.2680\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.4277 - val_loss: 104.4951\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 110.3192 - val_loss: 110.0908\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.5532 - val_loss: 104.2788\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.9546 - val_loss: 104.7352\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.4570 - val_loss: 103.6324\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 36ms/step - loss: 386933.1250 - val_loss: 279327.0625\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 197152.6719 - val_loss: 132314.5625\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 87006.1953 - val_loss: 55349.4180\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 34474.1953 - val_loss: 22284.0371\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 14186.5977 - val_loss: 10914.2617\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 8095.8213 - val_loss: 7843.1973\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 6748.8462 - val_loss: 7076.0210\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 6470.4258 - val_loss: 6814.2476\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 6346.2705 - val_loss: 6643.4341\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 6209.6089 - val_loss: 6503.7617\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 6080.3882 - val_loss: 6353.5073\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 5942.8452 - val_loss: 6215.6611\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 5809.5103 - val_loss: 6050.6738\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 5676.0054 - val_loss: 5894.3384\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 5543.2593 - val_loss: 5758.5479\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 3ms/step - loss: 5408.5288 - val_loss: 5588.7207\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 3ms/step - loss: 5278.1865 - val_loss: 5450.1650\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 5143.3608 - val_loss: 5305.9131\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 5011.9136 - val_loss: 5143.7935\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 4880.7651 - val_loss: 5019.5356\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 4760.4072 - val_loss: 4888.6938\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 4631.0107 - val_loss: 4720.8823\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 4506.6313 - val_loss: 4612.2324\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 4386.7095 - val_loss: 4486.5571\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 4268.6504 - val_loss: 4332.3970\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 4151.7310 - val_loss: 4213.5850\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 4039.6133 - val_loss: 4094.4070\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 3927.7690 - val_loss: 3982.9636\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 3821.1692 - val_loss: 3864.9697\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 7ms/step - loss: 3713.0364 - val_loss: 3736.8450\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 3608.6658 - val_loss: 3623.6089\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 3517.0752 - val_loss: 3535.8523\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 3409.4910 - val_loss: 3419.0808\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 3316.6272 - val_loss: 3312.2102\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 3222.9084 - val_loss: 3220.0864\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 3131.5022 - val_loss: 3122.5024\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 3044.0825 - val_loss: 3037.2371\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 2956.3335 - val_loss: 2942.7302\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 5ms/step - loss: 2873.9888 - val_loss: 2847.1863\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 2788.5232 - val_loss: 2770.5901\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 2709.6841 - val_loss: 2685.5454\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 2635.4426 - val_loss: 2593.8206\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 2558.0562 - val_loss: 2524.3508\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 2473.3010 - val_loss: 2424.7600\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 2343.0378 - val_loss: 2188.6655\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 2072.6240 - val_loss: 1904.8695\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 7ms/step - loss: 1805.8151 - val_loss: 1638.8165\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 1551.6637 - val_loss: 1428.4429\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 1329.2582 - val_loss: 1193.4938\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 1115.9543 - val_loss: 1007.3810\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 935.1660 - val_loss: 849.5824\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 7ms/step - loss: 788.3226 - val_loss: 716.5098\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 666.7090 - val_loss: 604.4486\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 7ms/step - loss: 567.8136 - val_loss: 518.8462\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 495.6681 - val_loss: 452.9292\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 5ms/step - loss: 433.3044 - val_loss: 400.1551\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 384.7469 - val_loss: 371.4466\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 351.6872 - val_loss: 330.8216\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 322.8601 - val_loss: 301.4592\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 3ms/step - loss: 301.4883 - val_loss: 271.8126\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 279.7896 - val_loss: 254.7826\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 262.3473 - val_loss: 240.5027\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 249.9512 - val_loss: 233.3390\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 240.8437 - val_loss: 216.8120\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 228.2721 - val_loss: 204.1059\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 3ms/step - loss: 218.1444 - val_loss: 195.0789\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 8ms/step - loss: 208.3991 - val_loss: 185.0673\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 203.7925 - val_loss: 182.3172\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 198.5810 - val_loss: 173.5463\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 15ms/step - loss: 193.1394 - val_loss: 168.7560\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 186.1398 - val_loss: 165.6589\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 184.1823 - val_loss: 163.3472\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.8869 - val_loss: 161.2548\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.9030 - val_loss: 157.3872\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 173.4517 - val_loss: 155.2834\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 172.3895 - val_loss: 152.9516\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 7ms/step - loss: 168.6966 - val_loss: 152.5527\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 5ms/step - loss: 168.2437 - val_loss: 151.3176\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.9476 - val_loss: 149.0704\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 164.5822 - val_loss: 148.0732\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 13ms/step - loss: 162.4665 - val_loss: 146.6322\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.2892 - val_loss: 146.2311\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 7ms/step - loss: 160.0854 - val_loss: 146.6962\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 11ms/step - loss: 160.0091 - val_loss: 145.0343\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 158.4655 - val_loss: 145.5293\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.5394 - val_loss: 143.1936\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.1888 - val_loss: 142.3577\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 157.0502 - val_loss: 143.6174\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.9830 - val_loss: 141.4597\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 155.5657 - val_loss: 141.6991\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 153.7449 - val_loss: 140.4554\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 153.1268 - val_loss: 140.4492\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.2361 - val_loss: 142.3826\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.0525 - val_loss: 145.9131\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.5359 - val_loss: 140.1903\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.5556 - val_loss: 139.4855\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 150.1107 - val_loss: 137.7370\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 150.9747 - val_loss: 138.4875\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 5ms/step - loss: 149.5118 - val_loss: 139.9208\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 5ms/step - loss: 151.5964 - val_loss: 136.8708\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 36ms/step - loss: 5684.7368 - val_loss: 3272.2966\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 9ms/step - loss: 3802.0435 - val_loss: 2662.3113\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 3021.6619 - val_loss: 2161.7722\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 2537.0757 - val_loss: 1829.2747\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 2176.5967 - val_loss: 1618.5055\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 5ms/step - loss: 1892.2979 - val_loss: 1381.0608\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 1650.1176 - val_loss: 1259.3281\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1442.2070 - val_loss: 1097.7877\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 1277.1150 - val_loss: 990.0565\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1129.8204 - val_loss: 887.0594\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1006.7737 - val_loss: 798.7960\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 898.4600 - val_loss: 729.9855\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 805.2100 - val_loss: 672.4421\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 3ms/step - loss: 730.5237 - val_loss: 605.2960\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 659.8827 - val_loss: 563.6605\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 601.4514 - val_loss: 523.5456\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 553.8631 - val_loss: 486.3674\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 507.6747 - val_loss: 454.1577\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 472.5694 - val_loss: 437.0799\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 436.3039 - val_loss: 394.5984\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 5ms/step - loss: 407.7331 - val_loss: 382.3968\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 5ms/step - loss: 379.0266 - val_loss: 357.0425\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 356.7821 - val_loss: 335.0886\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 335.2580 - val_loss: 317.3308\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 315.3358 - val_loss: 313.6681\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 5ms/step - loss: 298.9880 - val_loss: 288.0244\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 3ms/step - loss: 281.6967 - val_loss: 278.2921\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 3ms/step - loss: 267.8474 - val_loss: 268.5302\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 254.6960 - val_loss: 251.9386\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 242.3806 - val_loss: 241.3290\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 233.6737 - val_loss: 245.2490\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 3ms/step - loss: 222.0176 - val_loss: 219.6159\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 211.6455 - val_loss: 215.0396\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 3ms/step - loss: 204.8624 - val_loss: 202.7980\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 194.5888 - val_loss: 192.3168\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 185.9991 - val_loss: 190.2180\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.3821 - val_loss: 176.4017\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 172.2418 - val_loss: 172.4389\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 7ms/step - loss: 165.2387 - val_loss: 168.1309\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 159.3934 - val_loss: 158.7439\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 151.9510 - val_loss: 151.5180\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 5ms/step - loss: 146.5180 - val_loss: 145.6053\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 5ms/step - loss: 142.1547 - val_loss: 141.1251\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 142.1014 - val_loss: 134.6360\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 3ms/step - loss: 132.8821 - val_loss: 129.9661\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 128.3261 - val_loss: 125.7259\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 124.7544 - val_loss: 121.7553\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 7ms/step - loss: 121.1537 - val_loss: 121.5323\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.4580 - val_loss: 114.1347\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.4015 - val_loss: 110.1468\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.3493 - val_loss: 110.0676\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.1294 - val_loss: 105.3986\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.3660 - val_loss: 101.0690\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 103.9901 - val_loss: 99.5645\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 103.2825 - val_loss: 97.2284\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 102.1916 - val_loss: 96.4743\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 5ms/step - loss: 99.9821 - val_loss: 91.7942\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 7ms/step - loss: 98.3924 - val_loss: 92.8335\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 95.6357 - val_loss: 88.3922\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 94.1089 - val_loss: 90.5181\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 94.5902 - val_loss: 84.7584\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 90.8150 - val_loss: 83.1423\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 89.6104 - val_loss: 81.9412\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 88.5193 - val_loss: 81.0035\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 5ms/step - loss: 88.5029 - val_loss: 79.8213\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 86.1090 - val_loss: 80.2671\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.7543 - val_loss: 78.7961\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 86.3734 - val_loss: 79.8986\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 86.0386 - val_loss: 76.2395\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 7ms/step - loss: 84.4766 - val_loss: 79.9652\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 13ms/step - loss: 85.0491 - val_loss: 74.3760\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.8046 - val_loss: 73.5145\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 13ms/step - loss: 81.4433 - val_loss: 72.9095\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 7ms/step - loss: 81.5326 - val_loss: 72.2357\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 11ms/step - loss: 81.2123 - val_loss: 71.4328\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 80.3898 - val_loss: 70.7076\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 81.4975 - val_loss: 70.1548\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 80.2919 - val_loss: 70.4005\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.9047 - val_loss: 72.8200\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 79.4549 - val_loss: 73.9148\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 80.6383 - val_loss: 69.4369\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 78.8975 - val_loss: 67.7776\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.1233 - val_loss: 67.5821\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 77.0802 - val_loss: 66.9538\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.5313 - val_loss: 69.8322\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.4186 - val_loss: 66.1538\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 75.9521 - val_loss: 66.0130\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.9977 - val_loss: 72.2995\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.7812 - val_loss: 65.1611\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 7ms/step - loss: 75.2842 - val_loss: 65.9637\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 5ms/step - loss: 75.9999 - val_loss: 64.5268\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 75.6256 - val_loss: 64.5855\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 3ms/step - loss: 75.3506 - val_loss: 65.6348\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.5632 - val_loss: 63.9475\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.0559 - val_loss: 64.8550\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 3ms/step - loss: 74.8714 - val_loss: 66.5679\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 73.9960 - val_loss: 63.9340\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.2543 - val_loss: 63.0938\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.8767 - val_loss: 63.9660\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 3ms/step - loss: 74.2328 - val_loss: 62.6045\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 39ms/step - loss: 61396.0664 - val_loss: 39258.5625\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 27354.5801 - val_loss: 16169.1484\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 10569.1006 - val_loss: 5763.8315\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 3246.9580 - val_loss: 1581.9911\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1393.7288 - val_loss: 1205.9897\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 1236.0498 - val_loss: 1113.1505\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1111.8832 - val_loss: 1024.2231\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1018.9943 - val_loss: 944.1087\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 937.8007 - val_loss: 876.8500\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 865.5567 - val_loss: 817.5580\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 805.3760 - val_loss: 765.4204\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 751.8162 - val_loss: 719.4187\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 702.6246 - val_loss: 674.2260\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 660.2244 - val_loss: 640.8616\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 621.7327 - val_loss: 606.3315\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 585.6815 - val_loss: 570.7366\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 553.8519 - val_loss: 543.6913\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 526.2494 - val_loss: 519.9457\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 499.9059 - val_loss: 491.3211\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 475.4948 - val_loss: 470.2623\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 7ms/step - loss: 454.5742 - val_loss: 450.0042\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 435.3893 - val_loss: 428.9259\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 5ms/step - loss: 415.0071 - val_loss: 410.8814\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 5ms/step - loss: 399.2177 - val_loss: 395.5514\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 382.3022 - val_loss: 379.6565\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 368.7111 - val_loss: 366.3294\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 355.1334 - val_loss: 352.9488\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 343.8194 - val_loss: 340.5745\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 7ms/step - loss: 332.7375 - val_loss: 328.3482\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 322.6348 - val_loss: 317.8369\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 313.8936 - val_loss: 309.1413\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 305.8264 - val_loss: 301.5862\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 7ms/step - loss: 298.1196 - val_loss: 292.5342\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 5ms/step - loss: 291.5789 - val_loss: 286.2585\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 284.9711 - val_loss: 279.2209\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 279.7605 - val_loss: 272.6948\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 274.4455 - val_loss: 268.2452\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 7ms/step - loss: 269.0601 - val_loss: 261.8898\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 264.7885 - val_loss: 257.7121\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 260.6027 - val_loss: 252.7299\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 3ms/step - loss: 256.0215 - val_loss: 248.1404\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 7ms/step - loss: 252.5946 - val_loss: 243.8086\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 3ms/step - loss: 248.8057 - val_loss: 240.3727\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 245.2995 - val_loss: 236.6260\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 244.1002 - val_loss: 234.8868\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 242.3404 - val_loss: 230.2317\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 236.6908 - val_loss: 227.1442\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 7ms/step - loss: 234.4450 - val_loss: 224.5384\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 231.2133 - val_loss: 221.7560\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 228.2131 - val_loss: 219.0347\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 226.6260 - val_loss: 217.6540\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 225.0759 - val_loss: 214.0310\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 222.7934 - val_loss: 211.4758\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 219.3056 - val_loss: 208.9687\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 5ms/step - loss: 218.3582 - val_loss: 206.7681\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 215.2018 - val_loss: 205.6996\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 212.8121 - val_loss: 202.3294\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 210.5417 - val_loss: 200.0597\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 210.2201 - val_loss: 200.8868\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 208.9379 - val_loss: 196.7003\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 13ms/step - loss: 204.8675 - val_loss: 194.0705\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 14ms/step - loss: 202.8343 - val_loss: 193.4822\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 11ms/step - loss: 202.1596 - val_loss: 190.7566\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 199.4717 - val_loss: 188.7077\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 196.8978 - val_loss: 187.2335\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 195.9045 - val_loss: 185.0805\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 194.4017 - val_loss: 185.3075\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 194.1134 - val_loss: 183.0725\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 3ms/step - loss: 191.3478 - val_loss: 179.9466\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 7ms/step - loss: 188.5760 - val_loss: 178.8242\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 187.8787 - val_loss: 176.8746\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 7ms/step - loss: 185.6510 - val_loss: 175.0552\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 184.3459 - val_loss: 173.6123\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 182.3311 - val_loss: 172.1682\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 181.5011 - val_loss: 170.4918\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 180.6019 - val_loss: 170.4802\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 7ms/step - loss: 177.2106 - val_loss: 172.2269\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 178.6746 - val_loss: 166.6563\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 3ms/step - loss: 177.2812 - val_loss: 164.9212\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 7ms/step - loss: 175.5816 - val_loss: 163.6235\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 173.1115 - val_loss: 162.8933\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 171.5204 - val_loss: 161.3435\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 170.1450 - val_loss: 159.5622\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.9200 - val_loss: 159.3054\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.1460 - val_loss: 157.1371\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 166.2508 - val_loss: 156.6447\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 166.4964 - val_loss: 154.9181\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 7ms/step - loss: 164.9676 - val_loss: 155.1565\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 5ms/step - loss: 162.8141 - val_loss: 152.1000\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 161.2395 - val_loss: 152.3232\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 161.3606 - val_loss: 151.0399\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.2032 - val_loss: 149.2117\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 157.9203 - val_loss: 147.5991\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 3ms/step - loss: 157.1202 - val_loss: 147.0266\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.9701 - val_loss: 145.5437\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 154.6922 - val_loss: 144.8765\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.0180 - val_loss: 143.6484\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.7684 - val_loss: 144.9189\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 153.2963 - val_loss: 141.3661\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 150.7327 - val_loss: 140.8821\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 37ms/step - loss: 64025.6641 - val_loss: 40737.1172\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 24914.6465 - val_loss: 14641.2783\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 7ms/step - loss: 8573.7383 - val_loss: 5442.2207\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 3638.5344 - val_loss: 3135.1250\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 2716.9204 - val_loss: 2639.7014\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 2491.5159 - val_loss: 2509.6523\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 2390.7769 - val_loss: 2415.0874\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 2292.7939 - val_loss: 2314.5969\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 2196.0986 - val_loss: 2207.2832\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 2098.7410 - val_loss: 2120.8726\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 2001.8082 - val_loss: 2019.8042\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 7ms/step - loss: 1908.5615 - val_loss: 1930.0392\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 1820.2783 - val_loss: 1829.8870\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 1729.8240 - val_loss: 1747.3234\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 1646.6469 - val_loss: 1665.5651\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 1561.8481 - val_loss: 1580.2367\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 3ms/step - loss: 1491.7900 - val_loss: 1508.3077\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1413.2980 - val_loss: 1421.5084\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 3ms/step - loss: 1338.7062 - val_loss: 1360.4602\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1273.8794 - val_loss: 1286.8608\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 1207.1174 - val_loss: 1222.2256\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 1148.4835 - val_loss: 1157.8365\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 1088.8472 - val_loss: 1103.5457\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 7ms/step - loss: 1035.7572 - val_loss: 1054.1254\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 985.4130 - val_loss: 997.7095\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 5ms/step - loss: 937.0784 - val_loss: 945.2343\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 893.7866 - val_loss: 904.5128\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 848.6867 - val_loss: 856.9976\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 811.1211 - val_loss: 822.2672\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 771.8424 - val_loss: 778.3542\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 5ms/step - loss: 738.7558 - val_loss: 744.8427\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 705.5665 - val_loss: 713.4677\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 677.8667 - val_loss: 678.7658\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 648.4444 - val_loss: 658.2213\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 622.0223 - val_loss: 623.2269\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 599.8245 - val_loss: 597.6443\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 574.6737 - val_loss: 577.6635\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 554.9671 - val_loss: 552.5451\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 8ms/step - loss: 534.9188 - val_loss: 533.7487\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 516.4650 - val_loss: 513.7927\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 13ms/step - loss: 500.2734 - val_loss: 498.0590\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 483.4733 - val_loss: 476.8955\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 469.7797 - val_loss: 461.9550\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 455.3044 - val_loss: 448.0213\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 7ms/step - loss: 442.6935 - val_loss: 434.3316\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 431.2648 - val_loss: 422.3577\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 419.5241 - val_loss: 409.3351\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 410.0843 - val_loss: 399.9428\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 13ms/step - loss: 399.4040 - val_loss: 389.8867\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 390.5500 - val_loss: 376.5229\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 15ms/step - loss: 382.1333 - val_loss: 368.3201\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 11ms/step - loss: 373.4635 - val_loss: 359.3583\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 365.9613 - val_loss: 352.5552\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 359.6439 - val_loss: 344.8066\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 351.9921 - val_loss: 335.9059\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 5ms/step - loss: 345.0888 - val_loss: 329.8766\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 339.3101 - val_loss: 323.5350\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 333.3588 - val_loss: 315.6500\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 327.1389 - val_loss: 310.8020\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 322.6013 - val_loss: 304.7990\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 5ms/step - loss: 317.5279 - val_loss: 297.4124\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 311.6418 - val_loss: 294.8587\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 7ms/step - loss: 306.8735 - val_loss: 287.3355\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 7ms/step - loss: 304.1842 - val_loss: 283.3914\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 5ms/step - loss: 298.0050 - val_loss: 279.4599\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 7ms/step - loss: 293.7589 - val_loss: 273.5853\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 289.2977 - val_loss: 268.8094\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 285.3222 - val_loss: 264.8947\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 281.6802 - val_loss: 260.5218\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 278.3978 - val_loss: 256.7651\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 7ms/step - loss: 274.4479 - val_loss: 252.4686\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 269.9082 - val_loss: 249.2769\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 266.8036 - val_loss: 246.1484\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 3ms/step - loss: 262.7969 - val_loss: 242.4405\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 259.6735 - val_loss: 238.1799\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 255.6628 - val_loss: 235.1749\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 252.4339 - val_loss: 230.7413\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 249.2473 - val_loss: 228.2339\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 245.9906 - val_loss: 224.9455\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 243.2501 - val_loss: 222.0144\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 240.1687 - val_loss: 219.1090\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 236.6715 - val_loss: 216.1594\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 234.2336 - val_loss: 212.7642\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 230.8372 - val_loss: 210.0888\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 228.3272 - val_loss: 207.6116\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 226.2409 - val_loss: 203.9237\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 7ms/step - loss: 223.5386 - val_loss: 201.7551\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 220.2950 - val_loss: 199.3706\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 7ms/step - loss: 218.0260 - val_loss: 196.3992\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 215.4123 - val_loss: 194.5052\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 211.9200 - val_loss: 191.7450\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 3ms/step - loss: 209.5075 - val_loss: 189.0583\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 7ms/step - loss: 207.1907 - val_loss: 186.8703\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 205.0771 - val_loss: 185.6916\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 202.6834 - val_loss: 182.5947\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 200.1440 - val_loss: 180.4530\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 198.2283 - val_loss: 179.1962\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 197.3711 - val_loss: 176.0239\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 194.6645 - val_loss: 174.1809\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 192.1959 - val_loss: 172.5038\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 37ms/step - loss: 8472.7197 - val_loss: 7303.5347\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 6940.0298 - val_loss: 5739.7490\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 5878.4780 - val_loss: 5155.4219\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 4920.1680 - val_loss: 4238.5537\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 4051.7229 - val_loss: 3556.1331\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 7ms/step - loss: 3339.5732 - val_loss: 2931.2791\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 2744.4521 - val_loss: 2346.2480\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 2222.4785 - val_loss: 1899.1133\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 1812.6234 - val_loss: 1515.7277\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 1455.2445 - val_loss: 1250.2715\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 1205.3329 - val_loss: 1085.5742\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1032.7330 - val_loss: 948.3421\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 920.8765 - val_loss: 884.4541\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 5ms/step - loss: 849.2353 - val_loss: 817.3921\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 790.5305 - val_loss: 767.0778\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 7ms/step - loss: 737.3159 - val_loss: 722.2776\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 3ms/step - loss: 687.3192 - val_loss: 680.1505\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 7ms/step - loss: 637.4991 - val_loss: 640.1017\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 5ms/step - loss: 603.5302 - val_loss: 628.6877\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 568.4223 - val_loss: 578.9412\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 5ms/step - loss: 538.2628 - val_loss: 553.5301\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 509.5957 - val_loss: 523.4412\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 485.9260 - val_loss: 503.8210\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 462.2156 - val_loss: 476.6841\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 441.7073 - val_loss: 472.2296\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 424.6044 - val_loss: 430.3769\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 13ms/step - loss: 404.8142 - val_loss: 425.9704\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 13ms/step - loss: 386.6954 - val_loss: 405.6869\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 371.1239 - val_loss: 389.8453\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 353.7848 - val_loss: 367.1924\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 339.2650 - val_loss: 356.1553\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 326.7713 - val_loss: 346.7928\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 313.7611 - val_loss: 326.9813\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 301.4445 - val_loss: 309.0257\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 289.8395 - val_loss: 307.2627\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 12ms/step - loss: 279.4875 - val_loss: 283.4451\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 267.9754 - val_loss: 281.5674\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 257.9281 - val_loss: 262.8217\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 13ms/step - loss: 247.3999 - val_loss: 258.7728\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 238.8074 - val_loss: 250.2243\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 231.8271 - val_loss: 233.0623\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 221.7332 - val_loss: 232.2257\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 7ms/step - loss: 213.8136 - val_loss: 218.7422\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 207.6761 - val_loss: 214.9412\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 201.2870 - val_loss: 203.0199\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 193.6513 - val_loss: 199.1301\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 188.6311 - val_loss: 188.8728\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 185.7527 - val_loss: 182.5367\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 7ms/step - loss: 178.6467 - val_loss: 180.5950\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 172.9599 - val_loss: 174.3600\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 167.9479 - val_loss: 169.2010\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 162.8811 - val_loss: 161.9698\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 3ms/step - loss: 161.7216 - val_loss: 160.4906\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 7ms/step - loss: 156.3215 - val_loss: 153.3154\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 152.5997 - val_loss: 151.6194\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 3ms/step - loss: 149.6325 - val_loss: 146.7851\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 146.9786 - val_loss: 145.1260\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 143.6392 - val_loss: 139.5694\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 141.4721 - val_loss: 137.8071\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 138.6703 - val_loss: 134.2814\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 136.9298 - val_loss: 132.4016\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.8634 - val_loss: 129.7943\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 132.9421 - val_loss: 127.6592\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 132.0029 - val_loss: 130.6336\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 130.3513 - val_loss: 125.3011\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 129.1539 - val_loss: 122.3709\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 126.9744 - val_loss: 121.2704\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 126.2025 - val_loss: 120.6195\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 124.7268 - val_loss: 119.0522\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 7ms/step - loss: 124.7621 - val_loss: 117.3343\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 123.4157 - val_loss: 116.3511\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 5ms/step - loss: 123.9464 - val_loss: 115.1507\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 121.2318 - val_loss: 115.0272\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.7350 - val_loss: 115.8454\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.7318 - val_loss: 112.6472\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.7418 - val_loss: 112.7075\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.3958 - val_loss: 112.1396\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.7979 - val_loss: 111.8771\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.4115 - val_loss: 110.8678\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 7ms/step - loss: 118.8121 - val_loss: 111.8256\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 5ms/step - loss: 118.9109 - val_loss: 110.2441\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.5256 - val_loss: 109.4852\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.0038 - val_loss: 109.6924\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.3996 - val_loss: 108.9288\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.2230 - val_loss: 108.3391\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 7ms/step - loss: 116.6291 - val_loss: 108.2122\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 7ms/step - loss: 116.3899 - val_loss: 107.8834\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 3ms/step - loss: 116.4366 - val_loss: 107.4301\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.9396 - val_loss: 107.7217\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.7934 - val_loss: 107.2251\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 7ms/step - loss: 116.8319 - val_loss: 107.8907\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.0059 - val_loss: 106.9220\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.5330 - val_loss: 106.9515\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.3636 - val_loss: 106.7649\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 5ms/step - loss: 115.2853 - val_loss: 111.6060\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 5ms/step - loss: 116.4581 - val_loss: 106.3816\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.6785 - val_loss: 107.1343\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.2571 - val_loss: 106.0500\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.6579 - val_loss: 107.2678\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.3376 - val_loss: 105.7716\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 38ms/step - loss: 494658.7188 - val_loss: 367032.9688\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 281804.9688 - val_loss: 193365.3750\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 3ms/step - loss: 139012.9062 - val_loss: 87237.2344\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 57523.1914 - val_loss: 31360.3105\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 17473.7324 - val_loss: 6926.1973\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 3158.2371 - val_loss: 1087.2452\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 826.6479 - val_loss: 671.4431\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 725.3640 - val_loss: 646.2601\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 688.3080 - val_loss: 623.4220\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 657.7628 - val_loss: 602.1776\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 626.6827 - val_loss: 576.9833\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 7ms/step - loss: 599.2931 - val_loss: 552.6222\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 570.3358 - val_loss: 532.1217\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 543.0565 - val_loss: 509.8590\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 518.5781 - val_loss: 491.3301\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 496.2493 - val_loss: 473.0032\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 5ms/step - loss: 472.4190 - val_loss: 453.2793\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 5ms/step - loss: 451.9327 - val_loss: 439.6401\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 432.5556 - val_loss: 423.2995\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 414.7932 - val_loss: 410.2609\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 13ms/step - loss: 398.5544 - val_loss: 398.1482\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 383.8050 - val_loss: 384.7982\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 370.1176 - val_loss: 373.9574\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 13ms/step - loss: 357.1383 - val_loss: 367.5195\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 345.3396 - val_loss: 354.7405\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 335.7453 - val_loss: 345.4933\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 324.9071 - val_loss: 337.7933\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 316.0138 - val_loss: 329.5675\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 307.5563 - val_loss: 322.5837\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 300.4525 - val_loss: 315.8304\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 7ms/step - loss: 293.3401 - val_loss: 308.0967\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 7ms/step - loss: 285.8655 - val_loss: 302.8406\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 12ms/step - loss: 279.8027 - val_loss: 295.1937\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 273.5894 - val_loss: 289.7770\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 267.7613 - val_loss: 283.7586\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 262.8313 - val_loss: 279.0930\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 257.4376 - val_loss: 272.7142\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 5ms/step - loss: 253.1683 - val_loss: 267.7672\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 248.0013 - val_loss: 263.9779\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 7ms/step - loss: 243.8522 - val_loss: 259.0367\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 5ms/step - loss: 239.7159 - val_loss: 253.0629\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 236.0983 - val_loss: 249.5309\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 231.9029 - val_loss: 244.4499\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 228.4585 - val_loss: 239.9681\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 5ms/step - loss: 225.0203 - val_loss: 236.2356\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 5ms/step - loss: 222.8943 - val_loss: 232.9532\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 220.7285 - val_loss: 228.4749\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 215.8808 - val_loss: 225.6445\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 3ms/step - loss: 212.6855 - val_loss: 222.1201\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 3ms/step - loss: 210.2039 - val_loss: 218.7398\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 3ms/step - loss: 207.2314 - val_loss: 215.0974\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 204.2580 - val_loss: 212.2027\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 201.9089 - val_loss: 208.9050\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 199.5002 - val_loss: 206.1327\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 5ms/step - loss: 197.4664 - val_loss: 203.5063\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 196.0529 - val_loss: 202.1585\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 193.7365 - val_loss: 198.2289\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 190.7435 - val_loss: 195.4386\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 189.2946 - val_loss: 193.2316\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 187.4710 - val_loss: 191.2055\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 185.4715 - val_loss: 188.5624\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 183.3959 - val_loss: 186.2556\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 7ms/step - loss: 181.8546 - val_loss: 184.4862\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 180.3956 - val_loss: 182.0701\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 5ms/step - loss: 178.4054 - val_loss: 180.0941\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 7ms/step - loss: 177.2689 - val_loss: 178.3162\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.0042 - val_loss: 176.5159\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 174.2189 - val_loss: 174.3391\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 174.4308 - val_loss: 174.4442\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 3ms/step - loss: 171.8082 - val_loss: 171.9566\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 7ms/step - loss: 169.9902 - val_loss: 169.3611\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 168.2279 - val_loss: 168.5558\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 168.0374 - val_loss: 166.1776\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 167.0546 - val_loss: 165.3692\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 5ms/step - loss: 165.0511 - val_loss: 163.4075\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 164.6970 - val_loss: 163.7890\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.8589 - val_loss: 160.1049\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.9325 - val_loss: 158.9177\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 7ms/step - loss: 159.9028 - val_loss: 157.4709\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 5ms/step - loss: 158.6342 - val_loss: 156.3283\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.5711 - val_loss: 155.3863\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.6654 - val_loss: 153.8403\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 155.3408 - val_loss: 152.4727\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.7606 - val_loss: 153.4177\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 154.2437 - val_loss: 152.5803\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.0593 - val_loss: 148.9969\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 151.2681 - val_loss: 148.3067\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 151.1096 - val_loss: 146.4985\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.0053 - val_loss: 145.6726\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 148.6581 - val_loss: 144.3298\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 147.2455 - val_loss: 143.5827\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 146.4164 - val_loss: 142.6887\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 146.3807 - val_loss: 142.6485\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 5ms/step - loss: 147.1216 - val_loss: 140.5618\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 5ms/step - loss: 144.1534 - val_loss: 139.1690\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 7ms/step - loss: 143.5909 - val_loss: 139.1199\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 142.2098 - val_loss: 137.4236\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 141.5535 - val_loss: 136.5849\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 141.0187 - val_loss: 135.6361\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 140.4218 - val_loss: 134.5511\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 70ms/step - loss: 6098.7183 - val_loss: 3735.8005\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 18ms/step - loss: 4149.0728 - val_loss: 3049.3591\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 13ms/step - loss: 3125.4260 - val_loss: 2482.7917\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 13ms/step - loss: 2565.6370 - val_loss: 2157.6489\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 14ms/step - loss: 2226.1550 - val_loss: 1898.6294\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 12ms/step - loss: 1934.3970 - val_loss: 1662.1805\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 13ms/step - loss: 1671.7839 - val_loss: 1483.1359\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 5ms/step - loss: 1484.6711 - val_loss: 1354.0275\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 1313.7013 - val_loss: 1184.5492\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1185.3336 - val_loss: 1061.1852\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1067.5718 - val_loss: 956.6943\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 5ms/step - loss: 938.2632 - val_loss: 841.0018\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 835.8400 - val_loss: 761.1599\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 7ms/step - loss: 769.4695 - val_loss: 684.3984\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 5ms/step - loss: 674.8314 - val_loss: 608.9064\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 603.3082 - val_loss: 545.8050\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 542.7827 - val_loss: 489.9112\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 488.8674 - val_loss: 465.9618\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 442.8620 - val_loss: 402.5466\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 5ms/step - loss: 411.1214 - val_loss: 359.8242\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 366.7385 - val_loss: 332.6182\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 7ms/step - loss: 328.3639 - val_loss: 298.5113\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 298.4275 - val_loss: 270.5513\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 5ms/step - loss: 273.2764 - val_loss: 248.7225\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 7ms/step - loss: 251.6374 - val_loss: 237.2525\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 5ms/step - loss: 233.5855 - val_loss: 214.7018\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 216.9347 - val_loss: 196.5435\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 7ms/step - loss: 201.2804 - val_loss: 191.0087\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 5ms/step - loss: 192.3415 - val_loss: 185.6508\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 178.7386 - val_loss: 161.5373\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 5ms/step - loss: 167.6404 - val_loss: 153.3311\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 5ms/step - loss: 160.5272 - val_loss: 155.9112\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 155.0255 - val_loss: 146.3917\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 146.6220 - val_loss: 135.3931\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 7ms/step - loss: 141.7061 - val_loss: 130.1752\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 5ms/step - loss: 137.2403 - val_loss: 126.3972\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.0597 - val_loss: 126.8345\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 5ms/step - loss: 132.5745 - val_loss: 120.4582\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 130.2859 - val_loss: 122.2547\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 5ms/step - loss: 127.7694 - val_loss: 116.2863\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 124.3487 - val_loss: 115.0308\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.0456 - val_loss: 113.7420\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.6014 - val_loss: 112.3320\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.2301 - val_loss: 117.7085\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 5ms/step - loss: 120.8375 - val_loss: 110.9801\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.1837 - val_loss: 110.1923\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 5ms/step - loss: 119.9074 - val_loss: 109.5139\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.0741 - val_loss: 109.1973\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.0148 - val_loss: 110.4143\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 5ms/step - loss: 116.7454 - val_loss: 109.5548\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.1541 - val_loss: 108.5947\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.3128 - val_loss: 115.4394\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 7ms/step - loss: 124.5529 - val_loss: 121.8801\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 119.4813 - val_loss: 109.8279\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.5732 - val_loss: 107.5484\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.1500 - val_loss: 108.3687\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.3650 - val_loss: 110.7897\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.2134 - val_loss: 111.6281\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.2250 - val_loss: 106.6929\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 7ms/step - loss: 115.8849 - val_loss: 107.2765\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.1962 - val_loss: 105.9421\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 5ms/step - loss: 116.2163 - val_loss: 105.8661\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.3841 - val_loss: 107.7593\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.3020 - val_loss: 107.6296\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 119.9806 - val_loss: 107.0283\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.0099 - val_loss: 105.2233\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.5310 - val_loss: 104.9807\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 5ms/step - loss: 116.0491 - val_loss: 105.0222\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 7ms/step - loss: 117.7294 - val_loss: 111.8513\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 5ms/step - loss: 114.9220 - val_loss: 105.2254\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.9815 - val_loss: 112.4971\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.1707 - val_loss: 114.3553\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.4446 - val_loss: 107.3039\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.5018 - val_loss: 104.3469\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.4241 - val_loss: 107.0097\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.8250 - val_loss: 103.8684\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.1350 - val_loss: 104.3215\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 5ms/step - loss: 114.1580 - val_loss: 108.9775\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.5999 - val_loss: 104.0940\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.5206 - val_loss: 105.6681\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.2684 - val_loss: 109.6940\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 7ms/step - loss: 121.2901 - val_loss: 104.2599\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.5177 - val_loss: 103.7778\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.7412 - val_loss: 106.1645\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 8ms/step - loss: 115.3219 - val_loss: 109.7470\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 7ms/step - loss: 116.9055 - val_loss: 113.0340\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 7ms/step - loss: 118.6003 - val_loss: 112.3280\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 12ms/step - loss: 117.9119 - val_loss: 103.9459\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.7274 - val_loss: 103.1675\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.6896 - val_loss: 105.6513\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 7ms/step - loss: 115.6250 - val_loss: 112.4086\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.8416 - val_loss: 104.5972\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 7ms/step - loss: 115.4564 - val_loss: 102.9644\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 13ms/step - loss: 116.9491 - val_loss: 112.8615\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 13ms/step - loss: 117.7631 - val_loss: 103.2953\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 13ms/step - loss: 116.0411 - val_loss: 104.8711\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 12ms/step - loss: 119.0549 - val_loss: 115.3882\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.7919 - val_loss: 106.6025\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 5ms/step - loss: 117.7265 - val_loss: 103.7968\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 7ms/step - loss: 116.3956 - val_loss: 119.3619\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 1109837.2500 - val_loss: 900257.0625\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 728352.1250 - val_loss: 568163.4375\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 442697.3750 - val_loss: 330431.2812\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 247850.5000 - val_loss: 176093.1250\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 127955.3359 - val_loss: 87984.7109\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 62092.8984 - val_loss: 41623.4141\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 29203.3418 - val_loss: 20141.9668\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 14838.5244 - val_loss: 11183.4482\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 9217.4170 - val_loss: 7963.6216\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 7319.6069 - val_loss: 6886.0811\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 6714.8271 - val_loss: 6529.3638\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 6506.9868 - val_loss: 6382.8296\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 7ms/step - loss: 6407.3115 - val_loss: 6290.0610\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 6325.6606 - val_loss: 6211.8999\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 6249.4902 - val_loss: 6135.3228\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 6169.9956 - val_loss: 6060.2671\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 6093.3345 - val_loss: 5981.4248\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 6017.6865 - val_loss: 5902.4521\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 5937.7358 - val_loss: 5817.5146\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 5857.9390 - val_loss: 5736.5161\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 5775.5845 - val_loss: 5649.5317\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 5ms/step - loss: 5691.7476 - val_loss: 5562.3867\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 5ms/step - loss: 5606.8564 - val_loss: 5473.2754\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 5ms/step - loss: 5523.0244 - val_loss: 5382.0688\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 5434.0518 - val_loss: 5286.9595\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 5343.3838 - val_loss: 5197.8970\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 5256.7866 - val_loss: 5097.3687\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 5161.9155 - val_loss: 5010.2358\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 5072.1440 - val_loss: 4915.0410\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 4987.1118 - val_loss: 4819.4785\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 4894.4897 - val_loss: 4724.8462\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 5ms/step - loss: 4805.4048 - val_loss: 4636.3457\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 4719.7437 - val_loss: 4544.5996\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 4630.6011 - val_loss: 4457.4224\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 4546.0352 - val_loss: 4372.7983\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 4465.2485 - val_loss: 4297.0093\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 4385.2539 - val_loss: 4211.0107\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 7ms/step - loss: 4310.5054 - val_loss: 4131.2749\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 5ms/step - loss: 4231.9233 - val_loss: 4051.6350\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 7ms/step - loss: 4154.1309 - val_loss: 3981.4839\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 5ms/step - loss: 4085.1104 - val_loss: 3910.2175\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 4018.4563 - val_loss: 3847.6577\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 3956.2642 - val_loss: 3770.9058\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 3889.8401 - val_loss: 3717.8555\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 3814.2788 - val_loss: 3642.3035\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 7ms/step - loss: 3752.0027 - val_loss: 3580.8665\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 3687.7456 - val_loss: 3524.9841\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 3629.8506 - val_loss: 3468.5327\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 3571.9307 - val_loss: 3407.3467\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 3515.8647 - val_loss: 3352.7520\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 3458.2119 - val_loss: 3296.8811\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 3405.5493 - val_loss: 3241.3538\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 3354.9670 - val_loss: 3196.3730\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 5ms/step - loss: 3299.3738 - val_loss: 3139.7227\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 3248.4771 - val_loss: 3088.5332\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 7ms/step - loss: 3196.1724 - val_loss: 3040.3142\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 3147.5703 - val_loss: 2992.7449\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 3096.9109 - val_loss: 2943.2979\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 3050.5732 - val_loss: 2896.2354\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 2997.7754 - val_loss: 2856.5645\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 7ms/step - loss: 2953.6265 - val_loss: 2808.1951\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 5ms/step - loss: 2908.1299 - val_loss: 2755.7502\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 2861.4446 - val_loss: 2719.9727\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 2813.9771 - val_loss: 2674.3604\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 5ms/step - loss: 2769.9392 - val_loss: 2624.2812\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 2722.1738 - val_loss: 2583.9971\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 8ms/step - loss: 2682.1653 - val_loss: 2544.1658\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 12ms/step - loss: 2632.3154 - val_loss: 2499.9216\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 2589.7749 - val_loss: 2458.2693\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 2545.4873 - val_loss: 2413.7529\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 5ms/step - loss: 2505.8333 - val_loss: 2376.1768\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 2461.1438 - val_loss: 2336.0396\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 2418.9639 - val_loss: 2301.6941\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 2377.5750 - val_loss: 2257.6006\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 2337.6108 - val_loss: 2218.6367\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 13ms/step - loss: 2296.8481 - val_loss: 2180.6270\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 2260.0642 - val_loss: 2141.9673\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 14ms/step - loss: 2218.2185 - val_loss: 2110.2849\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 13ms/step - loss: 2178.9299 - val_loss: 2068.6938\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 12ms/step - loss: 2143.1265 - val_loss: 2034.5067\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 5ms/step - loss: 2105.9033 - val_loss: 1999.3488\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 2064.4346 - val_loss: 1966.6814\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 2028.3901 - val_loss: 1929.6505\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 1991.1451 - val_loss: 1894.6093\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 1953.4448 - val_loss: 1860.6702\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 1918.8647 - val_loss: 1826.2253\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 1891.1721 - val_loss: 1798.3833\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 1859.3713 - val_loss: 1758.2119\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 1814.9104 - val_loss: 1734.4434\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 7ms/step - loss: 1783.0319 - val_loss: 1703.1565\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 1751.7079 - val_loss: 1667.0427\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 7ms/step - loss: 1715.6290 - val_loss: 1636.2676\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 1681.7806 - val_loss: 1611.3882\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 1654.7314 - val_loss: 1573.5354\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 1621.5330 - val_loss: 1550.4884\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 1590.4116 - val_loss: 1514.8270\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 1555.9506 - val_loss: 1490.2792\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 1526.7161 - val_loss: 1461.2208\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 1496.0665 - val_loss: 1427.6603\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 1467.6587 - val_loss: 1408.3448\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 7656.6035 - val_loss: 4875.6729\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 3926.1699 - val_loss: 3390.5725\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 2974.2227 - val_loss: 2666.0950\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 7ms/step - loss: 2294.2156 - val_loss: 2099.5254\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 1751.4229 - val_loss: 1590.0740\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 1302.5168 - val_loss: 1196.3523\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 961.6611 - val_loss: 857.7508\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 700.8997 - val_loss: 631.8513\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 514.5122 - val_loss: 467.9981\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 385.6951 - val_loss: 360.6885\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 5ms/step - loss: 301.3967 - val_loss: 284.0740\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 244.4735 - val_loss: 235.1309\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 207.5487 - val_loss: 202.5797\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 8ms/step - loss: 184.5101 - val_loss: 177.5880\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 11ms/step - loss: 162.8889 - val_loss: 162.2008\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 153.3495 - val_loss: 154.2163\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 142.4476 - val_loss: 146.8236\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 135.1070 - val_loss: 143.2741\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.7675 - val_loss: 134.1309\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 7ms/step - loss: 129.4521 - val_loss: 133.3961\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 7ms/step - loss: 128.6991 - val_loss: 129.2259\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 5ms/step - loss: 125.6267 - val_loss: 127.3888\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 7ms/step - loss: 122.4147 - val_loss: 124.3854\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 122.6129 - val_loss: 123.1902\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 121.6147 - val_loss: 120.7973\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 120.5686 - val_loss: 121.7157\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.9845 - val_loss: 118.8634\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.3523 - val_loss: 118.5077\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.1844 - val_loss: 117.0565\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.8472 - val_loss: 116.1654\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.2638 - val_loss: 116.0803\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.6090 - val_loss: 115.1614\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.8239 - val_loss: 114.4728\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.2862 - val_loss: 114.8984\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.3796 - val_loss: 114.0668\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.1567 - val_loss: 114.3304\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.7634 - val_loss: 113.5455\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 7ms/step - loss: 118.7130 - val_loss: 112.4657\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.2579 - val_loss: 112.9049\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.4741 - val_loss: 113.0984\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.0734 - val_loss: 111.5993\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.7042 - val_loss: 112.3628\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.3659 - val_loss: 116.3352\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.3122 - val_loss: 115.0265\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.2471 - val_loss: 110.6563\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.2593 - val_loss: 109.9935\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 5ms/step - loss: 116.4327 - val_loss: 109.6219\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.2784 - val_loss: 110.0322\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.0534 - val_loss: 111.6089\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 8ms/step - loss: 115.0137 - val_loss: 108.6248\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.3739 - val_loss: 111.1801\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 7ms/step - loss: 114.7413 - val_loss: 109.0823\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 13ms/step - loss: 113.6088 - val_loss: 128.8327\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 12ms/step - loss: 128.6886 - val_loss: 108.8986\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.3141 - val_loss: 108.6938\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 5ms/step - loss: 116.8171 - val_loss: 108.8720\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 7ms/step - loss: 116.5981 - val_loss: 108.5375\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.1903 - val_loss: 114.0897\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.6740 - val_loss: 107.3354\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.1520 - val_loss: 107.2219\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 8ms/step - loss: 116.4354 - val_loss: 107.1343\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 14ms/step - loss: 117.0857 - val_loss: 106.6928\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 11ms/step - loss: 113.8582 - val_loss: 108.0470\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 5ms/step - loss: 113.0427 - val_loss: 108.5272\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.5245 - val_loss: 106.0638\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.0062 - val_loss: 109.1947\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.1038 - val_loss: 110.9561\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 131.5044 - val_loss: 118.1301\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 125.4445 - val_loss: 105.9735\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.5090 - val_loss: 106.0430\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.9136 - val_loss: 106.6857\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 7ms/step - loss: 116.1328 - val_loss: 115.8456\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.3011 - val_loss: 107.3723\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.8537 - val_loss: 105.9928\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.8268 - val_loss: 114.6747\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.3957 - val_loss: 117.5034\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.9428 - val_loss: 105.0715\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.4191 - val_loss: 110.0033\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.6381 - val_loss: 105.7080\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 5ms/step - loss: 118.6832 - val_loss: 116.2499\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.4866 - val_loss: 104.0760\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 7ms/step - loss: 111.4181 - val_loss: 110.1280\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.1971 - val_loss: 104.1350\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.2500 - val_loss: 103.9236\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.0731 - val_loss: 106.8905\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 7ms/step - loss: 112.9722 - val_loss: 116.0251\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.4176 - val_loss: 104.2427\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 7ms/step - loss: 110.6279 - val_loss: 106.6758\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 5ms/step - loss: 112.4342 - val_loss: 111.9455\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.3291 - val_loss: 103.9524\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.9513 - val_loss: 102.8267\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.9337 - val_loss: 103.6561\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 5ms/step - loss: 115.0421 - val_loss: 103.6229\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.4075 - val_loss: 103.6127\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.1051 - val_loss: 112.6959\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 7ms/step - loss: 114.2834 - val_loss: 102.9285\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 5ms/step - loss: 114.9741 - val_loss: 108.6270\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.4212 - val_loss: 102.4688\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.8810 - val_loss: 139.4111\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.7117 - val_loss: 109.6273\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 9188.3047 - val_loss: 3791.4927\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 2925.3391 - val_loss: 2870.8887\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 2660.0989 - val_loss: 2743.1340\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 2430.0071 - val_loss: 2576.2400\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 2243.3010 - val_loss: 2341.2368\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 2053.5417 - val_loss: 2150.5466\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1881.0989 - val_loss: 1960.9446\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1706.3610 - val_loss: 1782.8297\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1544.6509 - val_loss: 1608.6094\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 7ms/step - loss: 1383.5840 - val_loss: 1458.2134\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1233.4487 - val_loss: 1294.2692\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 1085.8928 - val_loss: 1143.4266\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 955.1157 - val_loss: 1004.1054\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 838.9286 - val_loss: 890.4495\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 7ms/step - loss: 748.2173 - val_loss: 794.6743\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 676.4836 - val_loss: 715.1440\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 615.0777 - val_loss: 646.4065\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 565.8021 - val_loss: 588.4628\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 521.6704 - val_loss: 541.7755\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 480.2287 - val_loss: 497.6317\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 447.4631 - val_loss: 456.7535\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 415.2372 - val_loss: 425.1008\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 5ms/step - loss: 388.2395 - val_loss: 391.3398\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 361.1991 - val_loss: 361.0110\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 338.2439 - val_loss: 332.6083\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 317.1678 - val_loss: 311.5039\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 297.2192 - val_loss: 287.1820\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 279.2276 - val_loss: 269.9837\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 7ms/step - loss: 263.0595 - val_loss: 252.8549\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 251.4185 - val_loss: 235.4767\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 5ms/step - loss: 237.7684 - val_loss: 221.3747\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 226.0403 - val_loss: 221.9393\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 214.2585 - val_loss: 198.8195\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 204.9807 - val_loss: 189.4521\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 7ms/step - loss: 196.4745 - val_loss: 183.0276\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 14ms/step - loss: 189.1138 - val_loss: 173.0663\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 12ms/step - loss: 185.5644 - val_loss: 170.7011\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.7319 - val_loss: 163.3115\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.3584 - val_loss: 154.4158\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 7ms/step - loss: 168.1487 - val_loss: 149.6620\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 13ms/step - loss: 162.1914 - val_loss: 146.9198\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.7142 - val_loss: 141.0776\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.0863 - val_loss: 136.8822\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 150.1958 - val_loss: 134.0983\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 13ms/step - loss: 146.6142 - val_loss: 130.0650\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 8ms/step - loss: 143.4922 - val_loss: 129.9955\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 11ms/step - loss: 140.3308 - val_loss: 124.0003\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 137.2909 - val_loss: 120.8823\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 134.9035 - val_loss: 119.0475\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 132.7377 - val_loss: 117.2661\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 130.0440 - val_loss: 117.0170\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 131.1390 - val_loss: 111.2491\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 7ms/step - loss: 128.3304 - val_loss: 109.5091\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.7332 - val_loss: 109.3477\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.4373 - val_loss: 108.4060\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 7ms/step - loss: 119.2590 - val_loss: 103.6374\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 5ms/step - loss: 118.5363 - val_loss: 102.1220\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.3369 - val_loss: 100.7751\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.8880 - val_loss: 98.7331\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.0377 - val_loss: 97.0053\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.6565 - val_loss: 95.8849\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.6905 - val_loss: 94.5971\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.6849 - val_loss: 93.1792\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 106.2902 - val_loss: 92.2138\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 105.7078 - val_loss: 92.0853\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 103.7526 - val_loss: 91.0361\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 103.8542 - val_loss: 89.9257\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 101.7107 - val_loss: 89.7261\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 8ms/step - loss: 99.5698 - val_loss: 86.3825\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 99.5054 - val_loss: 85.5907\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 97.7874 - val_loss: 84.9775\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 96.9180 - val_loss: 83.6773\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 98.2633 - val_loss: 82.7821\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 94.6337 - val_loss: 81.9868\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 94.6535 - val_loss: 81.3184\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 93.0793 - val_loss: 80.7818\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 93.4297 - val_loss: 80.0716\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 92.2363 - val_loss: 79.8496\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 91.4632 - val_loss: 80.0240\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 90.3333 - val_loss: 78.2481\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 89.8590 - val_loss: 78.7906\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 90.1948 - val_loss: 82.3881\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 90.4338 - val_loss: 79.9863\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 89.4918 - val_loss: 78.0704\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 88.4012 - val_loss: 75.7174\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 7ms/step - loss: 87.2163 - val_loss: 73.6246\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.1319 - val_loss: 74.5300\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 5ms/step - loss: 84.5890 - val_loss: 72.8290\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.0826 - val_loss: 75.3812\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 84.5625 - val_loss: 72.6835\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 83.8142 - val_loss: 72.3637\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 5ms/step - loss: 83.7306 - val_loss: 71.6863\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 83.2148 - val_loss: 70.1721\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.0542 - val_loss: 72.5120\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 82.6200 - val_loss: 69.7055\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.3700 - val_loss: 72.5466\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 80.5077 - val_loss: 69.1694\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 80.6960 - val_loss: 68.5514\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.3950 - val_loss: 68.6612\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.2758 - val_loss: 71.5984\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 1834.3193 - val_loss: 1036.9357\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 930.1927 - val_loss: 516.9913\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 7ms/step - loss: 476.8430 - val_loss: 368.9199\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 5ms/step - loss: 330.4455 - val_loss: 339.0093\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 279.5930 - val_loss: 291.8393\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 7ms/step - loss: 245.2581 - val_loss: 238.0035\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 205.7796 - val_loss: 201.4146\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 180.3091 - val_loss: 171.2464\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 164.8850 - val_loss: 162.9649\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 148.9602 - val_loss: 147.3096\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 138.2192 - val_loss: 138.8896\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.6006 - val_loss: 131.2003\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 128.5257 - val_loss: 131.4256\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 7ms/step - loss: 127.4467 - val_loss: 123.4982\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.2473 - val_loss: 121.4966\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.0248 - val_loss: 120.9728\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.3521 - val_loss: 116.6892\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 7ms/step - loss: 116.4207 - val_loss: 114.1721\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.6205 - val_loss: 113.8708\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 5ms/step - loss: 115.9423 - val_loss: 117.3882\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 7ms/step - loss: 116.4979 - val_loss: 116.4398\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.4853 - val_loss: 109.6019\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 7ms/step - loss: 112.6524 - val_loss: 109.0071\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 12ms/step - loss: 114.8058 - val_loss: 109.7454\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.4109 - val_loss: 116.4616\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.5169 - val_loss: 107.5389\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 7ms/step - loss: 113.5675 - val_loss: 105.5165\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 5ms/step - loss: 111.2541 - val_loss: 105.4220\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.7990 - val_loss: 105.4394\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 5ms/step - loss: 113.2899 - val_loss: 104.4980\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.1937 - val_loss: 106.2739\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.8562 - val_loss: 106.4545\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.5078 - val_loss: 103.2879\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.5937 - val_loss: 107.4799\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 7ms/step - loss: 110.5604 - val_loss: 108.1477\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 13ms/step - loss: 110.0164 - val_loss: 102.1606\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.8090 - val_loss: 101.0374\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 7ms/step - loss: 107.4137 - val_loss: 100.9324\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 11ms/step - loss: 108.7173 - val_loss: 103.9559\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 5ms/step - loss: 108.5263 - val_loss: 100.5598\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 5ms/step - loss: 107.9035 - val_loss: 100.4321\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 108.8427 - val_loss: 100.9820\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 107.8389 - val_loss: 99.7072\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 106.9541 - val_loss: 110.6480\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.5910 - val_loss: 113.2263\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.6709 - val_loss: 102.0790\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 107.7191 - val_loss: 119.9021\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 7ms/step - loss: 115.9924 - val_loss: 99.5100\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.2238 - val_loss: 99.8263\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 5ms/step - loss: 109.6770 - val_loss: 99.6202\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 106.5994 - val_loss: 98.6191\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.4867 - val_loss: 104.4877\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 7ms/step - loss: 106.3891 - val_loss: 98.5709\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 105.9629 - val_loss: 101.2790\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 108.4393 - val_loss: 115.4815\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.2907 - val_loss: 98.4958\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 7ms/step - loss: 108.4658 - val_loss: 100.3439\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.9119 - val_loss: 98.3548\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 108.3332 - val_loss: 100.5675\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 106.7591 - val_loss: 99.4710\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 105.6499 - val_loss: 98.6226\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 7ms/step - loss: 109.2982 - val_loss: 110.8830\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.9183 - val_loss: 99.4513\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 105.9479 - val_loss: 103.6066\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 7ms/step - loss: 106.2462 - val_loss: 97.9241\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 5ms/step - loss: 106.7001 - val_loss: 105.8876\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 7ms/step - loss: 107.7150 - val_loss: 103.7112\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.0670 - val_loss: 97.9346\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.2725 - val_loss: 106.6827\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 105.9820 - val_loss: 98.2605\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 106.5473 - val_loss: 97.6757\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 7ms/step - loss: 106.9887 - val_loss: 98.7267\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 7ms/step - loss: 105.2423 - val_loss: 100.0964\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.4053 - val_loss: 116.8484\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.6873 - val_loss: 102.2839\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 5ms/step - loss: 108.9420 - val_loss: 102.5279\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.9981 - val_loss: 101.1486\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 108.7254 - val_loss: 97.9080\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 108.6664 - val_loss: 108.7989\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.4967 - val_loss: 100.3601\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 5ms/step - loss: 112.9559 - val_loss: 98.0704\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 108.1867 - val_loss: 99.5880\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 108.4811 - val_loss: 103.4088\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.9193 - val_loss: 97.9791\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 106.4979 - val_loss: 97.3171\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 105.6799 - val_loss: 97.9208\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 106.6871 - val_loss: 117.2644\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 7ms/step - loss: 113.3177 - val_loss: 97.4530\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 5ms/step - loss: 107.5772 - val_loss: 99.0367\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 105.6333 - val_loss: 97.1337\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 105.6603 - val_loss: 98.1741\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 105.5796 - val_loss: 98.2873\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 105.5843 - val_loss: 97.3357\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.5737 - val_loss: 97.2768\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 7ms/step - loss: 106.5227 - val_loss: 100.6250\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 105.8644 - val_loss: 98.8298\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 105.3804 - val_loss: 108.0801\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 105.5339 - val_loss: 97.5948\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 107.2261 - val_loss: 100.4725\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 107.9044 - val_loss: 102.4000\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 4502.7998 - val_loss: 2737.9309\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 3540.7798 - val_loss: 2325.7109\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 2738.4041 - val_loss: 1772.1105\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 7ms/step - loss: 2159.7585 - val_loss: 1541.6648\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 1744.3823 - val_loss: 1375.5275\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 5ms/step - loss: 1458.3726 - val_loss: 1108.6604\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 1154.5912 - val_loss: 929.4033\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 933.9955 - val_loss: 790.4011\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 757.5510 - val_loss: 618.9009\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 601.2747 - val_loss: 531.0764\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 7ms/step - loss: 491.8500 - val_loss: 429.6353\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 13ms/step - loss: 409.8627 - val_loss: 359.6213\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 333.7453 - val_loss: 302.3330\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 283.6680 - val_loss: 262.5049\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 5ms/step - loss: 240.5274 - val_loss: 217.2273\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 208.3832 - val_loss: 195.1878\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 8ms/step - loss: 182.9268 - val_loss: 167.9223\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 14ms/step - loss: 164.9516 - val_loss: 151.2663\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 11ms/step - loss: 149.5473 - val_loss: 138.2985\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 13ms/step - loss: 140.0809 - val_loss: 126.5770\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 13ms/step - loss: 130.8527 - val_loss: 120.8818\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 12ms/step - loss: 125.5895 - val_loss: 115.2432\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.0645 - val_loss: 116.4487\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.1260 - val_loss: 114.5222\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.4252 - val_loss: 110.3257\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 5ms/step - loss: 120.0828 - val_loss: 113.6670\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.0014 - val_loss: 108.9850\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.5659 - val_loss: 105.9669\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.1132 - val_loss: 105.4975\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.3392 - val_loss: 106.2892\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.5532 - val_loss: 116.9126\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.3761 - val_loss: 105.5116\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.4477 - val_loss: 104.0606\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 7ms/step - loss: 115.2006 - val_loss: 109.0280\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 5ms/step - loss: 114.8068 - val_loss: 104.9798\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.6632 - val_loss: 104.9582\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 5ms/step - loss: 113.5172 - val_loss: 107.2965\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 5ms/step - loss: 112.6390 - val_loss: 104.9369\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.8666 - val_loss: 104.6453\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.9029 - val_loss: 105.6511\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.6324 - val_loss: 104.5367\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 7ms/step - loss: 112.3187 - val_loss: 103.7449\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.5195 - val_loss: 116.0210\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.8990 - val_loss: 103.0402\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.0116 - val_loss: 103.2904\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.1669 - val_loss: 108.6521\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 7ms/step - loss: 112.6133 - val_loss: 103.3984\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.2363 - val_loss: 105.2012\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.2364 - val_loss: 110.4109\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.6263 - val_loss: 103.3585\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.5207 - val_loss: 102.6995\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.9185 - val_loss: 113.5114\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.1420 - val_loss: 107.1091\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.8056 - val_loss: 106.4794\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.2556 - val_loss: 103.0233\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.0500 - val_loss: 102.7066\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.0419 - val_loss: 103.5219\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.0803 - val_loss: 102.3566\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.2530 - val_loss: 106.9446\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.6219 - val_loss: 134.5838\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 7ms/step - loss: 127.1098 - val_loss: 103.5571\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.4461 - val_loss: 102.0364\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.5729 - val_loss: 104.5990\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.8955 - val_loss: 106.5353\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.1178 - val_loss: 103.9801\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.7284 - val_loss: 103.8550\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 5ms/step - loss: 113.1902 - val_loss: 130.7771\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 123.2825 - val_loss: 103.2641\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.4890 - val_loss: 104.0993\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.8247 - val_loss: 101.8249\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.4352 - val_loss: 102.5888\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.5931 - val_loss: 102.0553\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.8755 - val_loss: 106.4731\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.7306 - val_loss: 104.4308\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.0972 - val_loss: 106.0902\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.4722 - val_loss: 107.5265\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.3376 - val_loss: 112.4207\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.9675 - val_loss: 103.3141\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.7552 - val_loss: 107.5563\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.7213 - val_loss: 111.9877\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.8388 - val_loss: 104.6642\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.8311 - val_loss: 104.1664\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 5ms/step - loss: 113.1821 - val_loss: 102.3556\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 5ms/step - loss: 113.7482 - val_loss: 103.3424\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 5ms/step - loss: 118.0141 - val_loss: 108.4089\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 124.0717 - val_loss: 105.7289\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 123.0457 - val_loss: 102.3269\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.0121 - val_loss: 101.7475\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.6629 - val_loss: 106.1287\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.0852 - val_loss: 104.7966\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.0254 - val_loss: 102.6119\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.3746 - val_loss: 102.5501\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.8073 - val_loss: 114.7663\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.7304 - val_loss: 124.1604\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.4340 - val_loss: 102.2139\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.7691 - val_loss: 106.7303\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.0787 - val_loss: 108.7159\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.5248 - val_loss: 105.3693\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.4140 - val_loss: 113.4728\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.1352 - val_loss: 103.3738\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 54ms/step - loss: 1083.7866 - val_loss: 615.8268\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 19ms/step - loss: 635.7335 - val_loss: 484.1505\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 541.1617 - val_loss: 433.1363\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 479.7869 - val_loss: 387.3992\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 427.4890 - val_loss: 345.5189\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 7ms/step - loss: 374.2023 - val_loss: 303.8615\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 7ms/step - loss: 330.2497 - val_loss: 276.1482\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 292.7975 - val_loss: 248.0234\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 259.4548 - val_loss: 229.5455\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 239.1797 - val_loss: 214.3155\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 13ms/step - loss: 220.1365 - val_loss: 202.6096\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 5ms/step - loss: 204.8305 - val_loss: 192.8274\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 192.6909 - val_loss: 182.4123\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 182.8587 - val_loss: 173.5375\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.0938 - val_loss: 167.7043\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 169.0190 - val_loss: 160.4807\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 163.6687 - val_loss: 155.7085\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 7ms/step - loss: 157.9313 - val_loss: 147.9392\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.5423 - val_loss: 143.3526\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 148.3260 - val_loss: 139.1135\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 142.6570 - val_loss: 134.5996\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 5ms/step - loss: 139.5301 - val_loss: 130.5244\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 7ms/step - loss: 134.1926 - val_loss: 127.7233\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 5ms/step - loss: 127.3489 - val_loss: 129.1830\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 125.2266 - val_loss: 123.8815\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 122.4175 - val_loss: 122.0971\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.4919 - val_loss: 117.8148\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.7854 - val_loss: 118.6625\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.4083 - val_loss: 116.1108\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 5ms/step - loss: 116.7265 - val_loss: 113.0641\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.3306 - val_loss: 112.3172\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 7ms/step - loss: 114.8554 - val_loss: 117.2442\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.9812 - val_loss: 112.3702\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.8721 - val_loss: 109.8599\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.9549 - val_loss: 108.5452\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 108.0664 - val_loss: 107.2801\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 108.4927 - val_loss: 106.5534\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.7599 - val_loss: 107.2097\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 105.3872 - val_loss: 105.3966\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 5ms/step - loss: 104.7584 - val_loss: 104.2143\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 7ms/step - loss: 104.1316 - val_loss: 104.6126\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 103.0942 - val_loss: 102.3983\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 103.2268 - val_loss: 101.6208\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 102.1589 - val_loss: 100.8263\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 100.5499 - val_loss: 99.8748\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 100.6427 - val_loss: 99.5364\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 7ms/step - loss: 98.7383 - val_loss: 99.0655\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 98.8936 - val_loss: 97.3183\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 5ms/step - loss: 97.9278 - val_loss: 96.6785\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 97.1371 - val_loss: 95.9385\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 96.2618 - val_loss: 97.1672\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 7ms/step - loss: 97.4661 - val_loss: 95.2304\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 98.2848 - val_loss: 104.0830\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 96.9202 - val_loss: 92.8986\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 93.6155 - val_loss: 90.7623\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 5ms/step - loss: 91.8406 - val_loss: 94.5307\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 91.5066 - val_loss: 88.2292\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 92.5395 - val_loss: 87.1047\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 7ms/step - loss: 92.4456 - val_loss: 89.6922\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 91.9951 - val_loss: 86.5496\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 86.8999 - val_loss: 84.4482\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 87.0224 - val_loss: 85.3964\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 86.4641 - val_loss: 84.7603\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.0449 - val_loss: 82.6599\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 84.0480 - val_loss: 82.3137\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 83.5966 - val_loss: 80.7627\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 83.7759 - val_loss: 85.2080\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.0406 - val_loss: 79.2951\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 81.8408 - val_loss: 78.8070\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.0376 - val_loss: 78.6710\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 5ms/step - loss: 79.5128 - val_loss: 77.7164\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.3575 - val_loss: 77.1769\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 78.6130 - val_loss: 78.7623\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 78.7563 - val_loss: 75.8673\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 77.7526 - val_loss: 75.5217\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 77.0242 - val_loss: 79.0288\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 7ms/step - loss: 78.3391 - val_loss: 74.2154\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.7460 - val_loss: 73.8078\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.0662 - val_loss: 73.8385\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.5164 - val_loss: 73.6525\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 76.3992 - val_loss: 74.8072\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 76.4924 - val_loss: 72.2838\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.5838 - val_loss: 71.6301\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 72.9251 - val_loss: 70.9673\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 74.5521 - val_loss: 70.8530\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.1041 - val_loss: 70.2838\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 7ms/step - loss: 72.3628 - val_loss: 70.2356\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 5ms/step - loss: 72.7715 - val_loss: 72.1815\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 71.4596 - val_loss: 69.8035\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 7ms/step - loss: 72.0293 - val_loss: 71.3891\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 13ms/step - loss: 71.4519 - val_loss: 70.0605\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 70.1931 - val_loss: 72.7635\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 70.8785 - val_loss: 68.1742\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 12ms/step - loss: 69.6879 - val_loss: 67.8401\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 7ms/step - loss: 71.2522 - val_loss: 68.1271\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.8793 - val_loss: 67.6790\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.2109 - val_loss: 70.9401\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.2182 - val_loss: 67.0480\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 14ms/step - loss: 68.2388 - val_loss: 66.3771\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 12ms/step - loss: 67.6736 - val_loss: 65.7856\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 38ms/step - loss: 148873.1250 - val_loss: 100534.9531\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 65488.4102 - val_loss: 39377.5195\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 23403.3535 - val_loss: 12752.5059\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 8605.0322 - val_loss: 5259.4692\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 5ms/step - loss: 5547.1367 - val_loss: 3872.7549\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 4937.1489 - val_loss: 3526.4771\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 4587.8394 - val_loss: 3275.6724\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 4252.3149 - val_loss: 3040.5581\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 3914.1865 - val_loss: 2742.3416\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 3605.4124 - val_loss: 2524.4133\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 3311.2676 - val_loss: 2320.8604\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 3038.4829 - val_loss: 2142.9229\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 2788.1299 - val_loss: 1950.9929\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 2558.7378 - val_loss: 1782.9366\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 2333.3076 - val_loss: 1623.4170\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 7ms/step - loss: 2142.8896 - val_loss: 1475.2310\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 1959.4475 - val_loss: 1373.6362\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1799.5265 - val_loss: 1270.1155\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 1648.1691 - val_loss: 1150.7975\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1513.0115 - val_loss: 1066.3386\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 1387.1415 - val_loss: 979.0330\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 1277.6697 - val_loss: 907.6876\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 1170.4724 - val_loss: 836.7509\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 1076.3224 - val_loss: 780.0308\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 991.8577 - val_loss: 730.4523\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 913.0772 - val_loss: 675.6246\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 847.1420 - val_loss: 645.4613\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 782.5054 - val_loss: 597.9348\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 5ms/step - loss: 725.8373 - val_loss: 569.8940\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 673.5984 - val_loss: 533.2369\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 628.6133 - val_loss: 506.2663\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 585.1483 - val_loss: 481.2397\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 547.7234 - val_loss: 457.1783\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 513.8604 - val_loss: 435.7501\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 5ms/step - loss: 481.8370 - val_loss: 419.4054\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 455.9044 - val_loss: 397.0384\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 428.7820 - val_loss: 387.9397\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 407.0921 - val_loss: 370.9704\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 386.6071 - val_loss: 356.1523\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 5ms/step - loss: 370.1800 - val_loss: 346.9205\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 7ms/step - loss: 353.2520 - val_loss: 334.4855\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 336.5706 - val_loss: 322.3276\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 322.6795 - val_loss: 314.7822\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 309.7913 - val_loss: 303.7067\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 5ms/step - loss: 298.0772 - val_loss: 297.5754\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 5ms/step - loss: 287.4171 - val_loss: 286.9056\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 5ms/step - loss: 277.9313 - val_loss: 280.4897\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 7ms/step - loss: 268.4630 - val_loss: 274.2497\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 260.1821 - val_loss: 266.8202\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 252.4808 - val_loss: 258.2087\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 7ms/step - loss: 245.5084 - val_loss: 254.0366\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 238.4085 - val_loss: 245.7634\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 232.4923 - val_loss: 240.9252\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 226.3665 - val_loss: 236.6597\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 221.0854 - val_loss: 231.5624\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 216.6443 - val_loss: 228.2949\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 212.5094 - val_loss: 217.5890\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 206.5390 - val_loss: 216.6200\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 7ms/step - loss: 201.4957 - val_loss: 210.4602\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 5ms/step - loss: 197.9865 - val_loss: 205.2053\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 193.9736 - val_loss: 201.6044\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 189.8641 - val_loss: 197.3733\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 185.6445 - val_loss: 193.1920\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 182.9593 - val_loss: 188.8215\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 7ms/step - loss: 179.2067 - val_loss: 185.8322\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 175.8295 - val_loss: 181.5253\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 172.6055 - val_loss: 179.3811\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 169.8571 - val_loss: 174.4538\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 167.4636 - val_loss: 171.3379\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 7ms/step - loss: 164.7788 - val_loss: 169.0398\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 5ms/step - loss: 162.5082 - val_loss: 166.2407\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.0485 - val_loss: 164.4154\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 157.5724 - val_loss: 159.4897\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 155.6595 - val_loss: 157.8995\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 153.2644 - val_loss: 155.6646\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 7ms/step - loss: 151.1019 - val_loss: 151.9121\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.4392 - val_loss: 149.8538\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 12ms/step - loss: 147.1759 - val_loss: 148.2031\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 145.1444 - val_loss: 146.0412\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 7ms/step - loss: 144.0105 - val_loss: 143.9093\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 7ms/step - loss: 142.3432 - val_loss: 141.9726\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 5ms/step - loss: 140.7388 - val_loss: 140.2046\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 139.4117 - val_loss: 137.9859\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 7ms/step - loss: 139.9633 - val_loss: 140.2721\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 137.7041 - val_loss: 134.9825\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 136.2058 - val_loss: 133.3796\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 8ms/step - loss: 135.1329 - val_loss: 132.2773\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 11ms/step - loss: 133.5457 - val_loss: 130.7253\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 5ms/step - loss: 132.4880 - val_loss: 129.0909\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 14ms/step - loss: 131.6203 - val_loss: 128.0913\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 11ms/step - loss: 130.7608 - val_loss: 126.7565\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 129.9236 - val_loss: 126.4058\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 128.8015 - val_loss: 124.8761\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 127.7948 - val_loss: 124.2921\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 127.3167 - val_loss: 122.3332\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 7ms/step - loss: 127.6515 - val_loss: 121.6780\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 126.3859 - val_loss: 120.8246\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 5ms/step - loss: 124.9570 - val_loss: 119.7125\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 124.3964 - val_loss: 118.8393\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 5ms/step - loss: 123.3786 - val_loss: 118.3151\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 3140.5588 - val_loss: 2551.0835\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 2038.2169 - val_loss: 1567.8075\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 7ms/step - loss: 1257.8948 - val_loss: 992.6793\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 790.6411 - val_loss: 667.0770\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 528.4731 - val_loss: 501.4230\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 390.8301 - val_loss: 401.1662\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 316.5267 - val_loss: 341.7595\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 277.0757 - val_loss: 299.2306\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 250.2933 - val_loss: 269.0516\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 228.2947 - val_loss: 248.0628\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 208.1009 - val_loss: 216.0878\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 190.3009 - val_loss: 195.1787\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 177.2011 - val_loss: 179.4345\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 167.4862 - val_loss: 167.3596\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 5ms/step - loss: 163.5246 - val_loss: 164.4847\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.1717 - val_loss: 146.6266\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 145.8081 - val_loss: 144.4793\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.8081 - val_loss: 134.0799\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 135.0695 - val_loss: 126.5767\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 136.6687 - val_loss: 126.0169\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 128.3667 - val_loss: 125.7745\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 127.9542 - val_loss: 117.1641\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 5ms/step - loss: 127.8464 - val_loss: 119.2735\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 7ms/step - loss: 123.1508 - val_loss: 113.4644\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.9012 - val_loss: 124.0082\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 124.6295 - val_loss: 110.4808\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 7ms/step - loss: 119.4159 - val_loss: 110.7011\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 120.5649 - val_loss: 108.6958\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 119.5679 - val_loss: 114.3388\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 9ms/step - loss: 120.6017 - val_loss: 111.8661\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 125.0085 - val_loss: 108.5973\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.0667 - val_loss: 110.9092\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 7ms/step - loss: 122.1018 - val_loss: 111.9660\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 122.4598 - val_loss: 106.5982\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 7ms/step - loss: 114.9062 - val_loss: 106.2807\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.9101 - val_loss: 106.7515\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 120.0444 - val_loss: 104.8978\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 8ms/step - loss: 115.2616 - val_loss: 109.8892\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.7689 - val_loss: 106.3693\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.3719 - val_loss: 103.5643\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.4741 - val_loss: 103.8358\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.4233 - val_loss: 103.1464\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.0747 - val_loss: 105.8379\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 5ms/step - loss: 115.3942 - val_loss: 110.7052\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.6970 - val_loss: 108.0358\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 7ms/step - loss: 113.6139 - val_loss: 111.9225\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 5ms/step - loss: 115.1531 - val_loss: 102.8336\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 5ms/step - loss: 114.3805 - val_loss: 104.4289\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.2639 - val_loss: 103.4415\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.8909 - val_loss: 102.2493\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.2983 - val_loss: 119.3356\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.4578 - val_loss: 103.0204\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.1358 - val_loss: 104.9428\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 7ms/step - loss: 117.8499 - val_loss: 101.8349\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 124.6283 - val_loss: 102.0086\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.7571 - val_loss: 104.8801\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.9327 - val_loss: 104.7169\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.1281 - val_loss: 107.6771\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.6433 - val_loss: 104.5417\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 120.2492 - val_loss: 101.5630\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.4555 - val_loss: 103.0372\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 8ms/step - loss: 122.1423 - val_loss: 100.8018\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.7127 - val_loss: 100.9975\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.9600 - val_loss: 113.7329\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.3679 - val_loss: 108.7962\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 5ms/step - loss: 120.3179 - val_loss: 103.5772\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.6413 - val_loss: 102.7752\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.9695 - val_loss: 101.4354\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.1027 - val_loss: 100.9499\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 5ms/step - loss: 112.2909 - val_loss: 101.7581\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 13ms/step - loss: 114.3004 - val_loss: 107.0159\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 13ms/step - loss: 117.3085 - val_loss: 106.3659\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 7ms/step - loss: 116.1360 - val_loss: 100.3270\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 12ms/step - loss: 111.3386 - val_loss: 102.0533\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 13ms/step - loss: 112.0228 - val_loss: 100.4414\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.2400 - val_loss: 100.6980\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 5ms/step - loss: 112.0616 - val_loss: 100.5136\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.0174 - val_loss: 100.9167\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.1196 - val_loss: 101.0383\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.4761 - val_loss: 106.0468\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.2394 - val_loss: 103.1006\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.5056 - val_loss: 100.3223\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 7ms/step - loss: 117.4851 - val_loss: 100.7905\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.8016 - val_loss: 102.0893\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.5202 - val_loss: 109.8322\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 7ms/step - loss: 112.1567 - val_loss: 101.3140\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 5ms/step - loss: 114.0130 - val_loss: 100.6133\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.7167 - val_loss: 114.4500\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.1939 - val_loss: 106.5549\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.7811 - val_loss: 102.5052\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 3ms/step - loss: 113.2255 - val_loss: 103.5592\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.8327 - val_loss: 106.1364\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.1591 - val_loss: 101.3210\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 7ms/step - loss: 114.6911 - val_loss: 101.3032\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.6531 - val_loss: 129.2405\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 7ms/step - loss: 115.9940 - val_loss: 100.7013\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.8834 - val_loss: 100.5220\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 3ms/step - loss: 115.2427 - val_loss: 107.3806\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.2198 - val_loss: 106.9622\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 3ms/step - loss: 114.4374 - val_loss: 103.5771\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 35ms/step - loss: 38716.7539 - val_loss: 17666.0605\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 9ms/step - loss: 10247.5146 - val_loss: 3439.8767\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 2841.1929 - val_loss: 2377.7754\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 2193.2354 - val_loss: 1993.1165\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1907.2450 - val_loss: 1699.9098\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1698.1010 - val_loss: 1491.8092\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1503.6458 - val_loss: 1311.7430\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1332.2920 - val_loss: 1151.7643\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 1172.7440 - val_loss: 1007.3635\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 7ms/step - loss: 1033.6509 - val_loss: 880.5014\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 5ms/step - loss: 905.1493 - val_loss: 760.4827\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 792.5953 - val_loss: 669.8792\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 7ms/step - loss: 691.8257 - val_loss: 598.6499\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 609.7973 - val_loss: 539.3068\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 544.3984 - val_loss: 488.0482\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 496.5405 - val_loss: 449.8494\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 443.7948 - val_loss: 405.7901\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 5ms/step - loss: 406.6803 - val_loss: 379.1739\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 5ms/step - loss: 377.8930 - val_loss: 353.5584\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 5ms/step - loss: 353.3339 - val_loss: 333.0053\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 330.0237 - val_loss: 316.4382\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 7ms/step - loss: 310.6661 - val_loss: 297.4249\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 294.9087 - val_loss: 279.0707\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 276.9521 - val_loss: 268.7185\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 264.5002 - val_loss: 249.3022\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 7ms/step - loss: 248.2955 - val_loss: 241.8287\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 239.0259 - val_loss: 229.0276\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 228.1443 - val_loss: 220.8737\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 223.0934 - val_loss: 214.5568\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 7ms/step - loss: 211.4881 - val_loss: 206.6763\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 5ms/step - loss: 205.1455 - val_loss: 202.0457\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 198.6497 - val_loss: 194.7953\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 191.7212 - val_loss: 188.2476\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 7ms/step - loss: 185.7736 - val_loss: 182.3988\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 179.2061 - val_loss: 175.8374\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 173.3622 - val_loss: 170.5324\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.7528 - val_loss: 166.7249\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 5ms/step - loss: 165.2532 - val_loss: 162.0046\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 160.7581 - val_loss: 158.4585\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 157.3963 - val_loss: 155.1758\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 153.5626 - val_loss: 151.8048\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 150.5271 - val_loss: 150.1747\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.4089 - val_loss: 151.7449\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 146.3013 - val_loss: 145.3518\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 144.2733 - val_loss: 142.4655\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 141.6816 - val_loss: 140.5384\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 141.2621 - val_loss: 139.9804\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 5ms/step - loss: 139.2271 - val_loss: 136.5139\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 137.2994 - val_loss: 135.9532\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 135.2292 - val_loss: 135.5645\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.8008 - val_loss: 133.6945\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 7ms/step - loss: 133.3030 - val_loss: 132.4825\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 131.9661 - val_loss: 128.2440\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 13ms/step - loss: 130.2143 - val_loss: 126.8166\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.4990 - val_loss: 126.4255\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 131.8783 - val_loss: 124.5742\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 8ms/step - loss: 133.4416 - val_loss: 129.1322\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 12ms/step - loss: 127.3976 - val_loss: 122.5372\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 125.5572 - val_loss: 121.7334\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 15ms/step - loss: 124.8730 - val_loss: 120.0223\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 12ms/step - loss: 123.8517 - val_loss: 119.2186\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 10ms/step - loss: 123.8033 - val_loss: 118.7531\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 123.0275 - val_loss: 118.2421\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.5805 - val_loss: 117.2776\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 7ms/step - loss: 121.6920 - val_loss: 117.0854\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 124.1849 - val_loss: 120.0574\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 122.0789 - val_loss: 115.6276\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 120.8000 - val_loss: 114.9843\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 121.1514 - val_loss: 114.7956\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.9167 - val_loss: 116.9983\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.2302 - val_loss: 115.0451\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 119.3910 - val_loss: 114.1548\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 7ms/step - loss: 119.8055 - val_loss: 112.5799\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 119.6876 - val_loss: 112.7236\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.5269 - val_loss: 114.0441\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.9908 - val_loss: 113.4388\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.4820 - val_loss: 110.9037\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.2635 - val_loss: 111.5388\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.6582 - val_loss: 113.2438\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.7501 - val_loss: 114.9351\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.3700 - val_loss: 109.5922\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.0699 - val_loss: 111.1937\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.3985 - val_loss: 110.6631\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.4342 - val_loss: 111.1422\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.9521 - val_loss: 108.7631\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.9203 - val_loss: 108.8878\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.1470 - val_loss: 109.8700\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.9396 - val_loss: 110.6450\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.2315 - val_loss: 108.4745\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.2071 - val_loss: 110.0356\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.2506 - val_loss: 107.3477\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.6678 - val_loss: 107.2847\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.4474 - val_loss: 110.6358\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.9507 - val_loss: 107.9899\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.0383 - val_loss: 106.4391\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.3699 - val_loss: 106.8897\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.3735 - val_loss: 107.3900\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.3960 - val_loss: 105.6599\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.5915 - val_loss: 107.2734\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.9302 - val_loss: 109.6282\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 39ms/step - loss: 7102.3003 - val_loss: 5404.8037\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 4802.7397 - val_loss: 3999.7366\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 3872.5288 - val_loss: 3462.1113\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 3321.9531 - val_loss: 3051.4414\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 2913.2368 - val_loss: 2712.9927\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 2554.5706 - val_loss: 2391.4854\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 2270.5037 - val_loss: 2161.8638\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 2034.4143 - val_loss: 1938.8149\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 1832.8453 - val_loss: 1755.8186\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 1655.9963 - val_loss: 1574.2089\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1494.0128 - val_loss: 1455.3226\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 1366.4916 - val_loss: 1307.6432\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1255.1189 - val_loss: 1202.4119\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1146.4862 - val_loss: 1097.7144\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1053.1024 - val_loss: 1008.7312\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 971.3601 - val_loss: 930.0690\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 5ms/step - loss: 897.6002 - val_loss: 848.2458\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 832.0040 - val_loss: 790.0248\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 771.3919 - val_loss: 738.7289\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 718.2285 - val_loss: 672.2341\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 667.3732 - val_loss: 624.4807\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 619.0126 - val_loss: 588.2231\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 580.4099 - val_loss: 544.7543\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 537.3824 - val_loss: 506.7552\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 504.6888 - val_loss: 474.2379\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 469.5885 - val_loss: 441.9790\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 439.6841 - val_loss: 409.7673\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 408.6887 - val_loss: 387.6184\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 387.5665 - val_loss: 357.8762\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 359.1023 - val_loss: 334.2406\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 5ms/step - loss: 340.0282 - val_loss: 312.9333\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 316.8020 - val_loss: 294.0446\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 5ms/step - loss: 296.8573 - val_loss: 274.9253\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 7ms/step - loss: 283.4482 - val_loss: 269.0888\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 13ms/step - loss: 268.9900 - val_loss: 246.8549\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 247.8266 - val_loss: 226.6510\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 234.1078 - val_loss: 213.5687\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 13ms/step - loss: 218.7798 - val_loss: 199.6160\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 210.6421 - val_loss: 200.2460\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 7ms/step - loss: 199.0452 - val_loss: 179.6708\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 13ms/step - loss: 185.3036 - val_loss: 169.5634\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 13ms/step - loss: 177.1457 - val_loss: 168.2180\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.9270 - val_loss: 155.1146\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.6540 - val_loss: 146.3129\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 7ms/step - loss: 153.6423 - val_loss: 144.4680\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 13ms/step - loss: 147.3046 - val_loss: 139.5812\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 5ms/step - loss: 141.0099 - val_loss: 131.8220\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 136.1256 - val_loss: 126.5515\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 131.3687 - val_loss: 123.1660\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 127.2630 - val_loss: 120.2492\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 125.5966 - val_loss: 117.9662\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 122.9359 - val_loss: 116.1233\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.9287 - val_loss: 121.1479\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 7ms/step - loss: 118.9060 - val_loss: 119.2277\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 5ms/step - loss: 115.2015 - val_loss: 112.4022\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.3474 - val_loss: 111.3518\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.4553 - val_loss: 110.1692\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.7892 - val_loss: 109.5320\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 108.9751 - val_loss: 108.7079\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 108.7760 - val_loss: 108.4663\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.3456 - val_loss: 107.4431\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.2133 - val_loss: 107.0079\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 106.6153 - val_loss: 106.5035\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 104.8839 - val_loss: 109.0987\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.0963 - val_loss: 107.9659\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 106.0034 - val_loss: 106.1424\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 105.1756 - val_loss: 106.1624\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 104.6036 - val_loss: 106.1793\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 104.5542 - val_loss: 106.0307\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 103.7965 - val_loss: 106.6379\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 102.3333 - val_loss: 105.8712\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 3ms/step - loss: 103.5304 - val_loss: 106.9024\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 101.6385 - val_loss: 108.7690\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 101.8230 - val_loss: 105.7849\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 102.0799 - val_loss: 105.2269\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 101.8740 - val_loss: 105.5154\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 103.9504 - val_loss: 106.4871\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 102.5682 - val_loss: 105.0466\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 101.5369 - val_loss: 105.9646\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 7ms/step - loss: 101.1944 - val_loss: 105.0284\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 5ms/step - loss: 101.5844 - val_loss: 104.7384\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 101.3224 - val_loss: 107.7922\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 5ms/step - loss: 102.7055 - val_loss: 108.8791\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 100.1643 - val_loss: 105.3724\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 100.6426 - val_loss: 104.3092\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 99.8388 - val_loss: 107.1907\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 101.0751 - val_loss: 108.4302\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 5ms/step - loss: 102.5833 - val_loss: 107.5628\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 103.8374 - val_loss: 104.7789\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 99.9174 - val_loss: 105.2573\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 102.8937 - val_loss: 104.9203\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 103.6246 - val_loss: 105.4007\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 100.2373 - val_loss: 111.5588\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 103.3149 - val_loss: 104.2166\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 99.3682 - val_loss: 107.0053\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 102.0502 - val_loss: 104.3679\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 100.3326 - val_loss: 104.4529\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 3ms/step - loss: 101.8405 - val_loss: 104.3116\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 100.6470 - val_loss: 104.9463\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 100.5086 - val_loss: 104.5201\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 36ms/step - loss: 47423.4414 - val_loss: 23810.8203\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 13228.4414 - val_loss: 5234.2798\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 3455.9321 - val_loss: 2008.5530\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 2348.0972 - val_loss: 1749.4011\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 2099.5134 - val_loss: 1573.8794\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 5ms/step - loss: 1857.4834 - val_loss: 1402.6420\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 1647.0527 - val_loss: 1235.9528\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 1432.4285 - val_loss: 1063.2380\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 1238.8165 - val_loss: 919.9351\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 1055.3433 - val_loss: 784.5167\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 890.8492 - val_loss: 660.6638\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 750.4828 - val_loss: 550.9367\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 625.2620 - val_loss: 458.5203\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 523.6740 - val_loss: 383.2310\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 5ms/step - loss: 445.1212 - val_loss: 334.1106\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 389.7975 - val_loss: 298.4877\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 347.8513 - val_loss: 272.0489\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 316.3785 - val_loss: 254.1850\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 7ms/step - loss: 291.6760 - val_loss: 242.7559\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 275.4517 - val_loss: 231.9052\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 260.7643 - val_loss: 224.2701\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 250.1851 - val_loss: 217.6208\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 241.9081 - val_loss: 212.1880\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 234.3804 - val_loss: 207.9329\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 228.3363 - val_loss: 203.5422\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 223.2141 - val_loss: 200.3800\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 218.5480 - val_loss: 197.4239\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 5ms/step - loss: 213.5117 - val_loss: 194.9348\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 209.8786 - val_loss: 192.7085\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 7ms/step - loss: 206.6988 - val_loss: 190.2112\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 12ms/step - loss: 203.4563 - val_loss: 188.4749\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 200.2705 - val_loss: 186.1464\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 198.9646 - val_loss: 185.0771\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 7ms/step - loss: 195.0934 - val_loss: 183.6410\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 192.8415 - val_loss: 181.7068\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 8ms/step - loss: 190.9174 - val_loss: 180.6215\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 188.8976 - val_loss: 179.3885\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 186.9532 - val_loss: 178.4488\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 185.5127 - val_loss: 176.9061\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.1502 - val_loss: 175.9652\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 5ms/step - loss: 181.5360 - val_loss: 175.0378\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.7307 - val_loss: 174.2858\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 11ms/step - loss: 178.0387 - val_loss: 173.3757\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.0181 - val_loss: 172.5891\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 175.3518 - val_loss: 171.0354\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 174.0925 - val_loss: 170.3943\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 173.0973 - val_loss: 169.8985\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.5138 - val_loss: 169.0384\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 170.2028 - val_loss: 168.0715\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 169.2496 - val_loss: 167.2630\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 7ms/step - loss: 168.3530 - val_loss: 166.5121\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 166.9565 - val_loss: 165.4497\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.5586 - val_loss: 164.6532\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 165.4509 - val_loss: 163.6786\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 164.3748 - val_loss: 162.5844\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 163.3619 - val_loss: 161.9489\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 5ms/step - loss: 162.5409 - val_loss: 160.9826\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 5ms/step - loss: 161.2607 - val_loss: 159.9213\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 5ms/step - loss: 161.2175 - val_loss: 159.6162\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 159.9269 - val_loss: 158.5431\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 158.9893 - val_loss: 158.3095\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 158.0365 - val_loss: 157.8758\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 156.9795 - val_loss: 157.3286\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 7ms/step - loss: 156.1536 - val_loss: 156.7995\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.5790 - val_loss: 156.3461\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 7ms/step - loss: 154.7635 - val_loss: 155.0639\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 153.6122 - val_loss: 154.5623\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.9385 - val_loss: 153.6374\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.3653 - val_loss: 152.6761\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 151.4179 - val_loss: 152.3326\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 151.5582 - val_loss: 151.8517\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 149.6543 - val_loss: 150.5051\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 149.7222 - val_loss: 150.2382\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 7ms/step - loss: 148.9986 - val_loss: 149.2274\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 147.6129 - val_loss: 148.7066\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 7ms/step - loss: 147.3664 - val_loss: 147.4497\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 146.3618 - val_loss: 146.6331\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 145.9004 - val_loss: 146.4431\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 145.0774 - val_loss: 145.7085\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 7ms/step - loss: 144.4789 - val_loss: 144.7774\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 144.0548 - val_loss: 143.8294\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 5ms/step - loss: 143.1608 - val_loss: 143.5963\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 5ms/step - loss: 142.8028 - val_loss: 143.1970\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 142.6836 - val_loss: 142.4791\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 141.5432 - val_loss: 141.3086\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 141.0863 - val_loss: 140.9107\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 140.0293 - val_loss: 139.9251\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 140.2520 - val_loss: 140.4794\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 140.3735 - val_loss: 138.5476\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.9528 - val_loss: 138.4752\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 139.5211 - val_loss: 141.0228\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 138.1933 - val_loss: 137.2855\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 137.6279 - val_loss: 136.7905\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.0049 - val_loss: 135.3755\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 136.8002 - val_loss: 135.1069\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 135.4552 - val_loss: 134.5587\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 134.6738 - val_loss: 133.9884\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 134.1383 - val_loss: 133.1505\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 133.5442 - val_loss: 132.4765\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 133.6556 - val_loss: 132.5659\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 37ms/step - loss: 8431.1309 - val_loss: 7718.6909\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 6718.1719 - val_loss: 5864.8115\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 5487.1104 - val_loss: 4932.4937\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 7ms/step - loss: 4620.6562 - val_loss: 4106.0889\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 3878.1899 - val_loss: 3503.4175\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 3261.8047 - val_loss: 2926.1594\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 2774.7168 - val_loss: 2504.5291\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 2364.8811 - val_loss: 2173.1238\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 5ms/step - loss: 2030.2845 - val_loss: 1825.5243\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 5ms/step - loss: 1746.3503 - val_loss: 1611.4512\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1526.9873 - val_loss: 1437.5891\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1326.7000 - val_loss: 1238.3158\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 1155.0618 - val_loss: 1059.8948\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 7ms/step - loss: 1017.8531 - val_loss: 948.4353\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 906.2387 - val_loss: 821.2064\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 785.4631 - val_loss: 772.3134\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 711.3224 - val_loss: 666.9600\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 630.3444 - val_loss: 577.6331\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 5ms/step - loss: 562.3417 - val_loss: 515.9188\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 7ms/step - loss: 503.6914 - val_loss: 464.9977\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 12ms/step - loss: 455.4744 - val_loss: 421.0112\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 408.9043 - val_loss: 393.2146\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 7ms/step - loss: 371.0374 - val_loss: 342.7333\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 334.5041 - val_loss: 323.5699\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 310.6777 - val_loss: 286.4289\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 286.8992 - val_loss: 265.6790\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 5ms/step - loss: 258.8800 - val_loss: 238.9803\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 237.3342 - val_loss: 217.4566\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 13ms/step - loss: 221.4982 - val_loss: 208.1900\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 203.9707 - val_loss: 185.7814\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 192.3130 - val_loss: 171.8811\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 5ms/step - loss: 178.1534 - val_loss: 164.7731\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 169.1741 - val_loss: 151.4212\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 159.1717 - val_loss: 142.4668\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 151.9112 - val_loss: 134.7714\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 144.4012 - val_loss: 135.9544\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 139.4295 - val_loss: 125.5708\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.9337 - val_loss: 118.3296\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 130.4709 - val_loss: 114.8438\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 127.5081 - val_loss: 113.6385\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 125.7995 - val_loss: 107.8402\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 130.0174 - val_loss: 106.6158\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 126.4809 - val_loss: 104.5836\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 130.7728 - val_loss: 107.7123\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.3097 - val_loss: 99.0438\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.1850 - val_loss: 97.7651\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.3874 - val_loss: 96.5027\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.9949 - val_loss: 95.3260\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 8ms/step - loss: 112.0714 - val_loss: 101.8498\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.4617 - val_loss: 94.9891\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.0480 - val_loss: 93.9445\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.6568 - val_loss: 92.0472\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.7578 - val_loss: 91.4228\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.3460 - val_loss: 92.1034\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.1137 - val_loss: 90.4751\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 108.9153 - val_loss: 97.2910\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.3157 - val_loss: 89.9769\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.0187 - val_loss: 91.0002\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 108.0245 - val_loss: 89.1548\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 5ms/step - loss: 109.0396 - val_loss: 89.3432\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 108.3899 - val_loss: 89.7070\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 108.1342 - val_loss: 90.0584\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.7030 - val_loss: 88.9578\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.2792 - val_loss: 88.9518\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.2504 - val_loss: 87.0281\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 106.8505 - val_loss: 87.1183\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.5225 - val_loss: 92.2148\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 106.1411 - val_loss: 87.8196\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 105.5663 - val_loss: 86.6736\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 105.5731 - val_loss: 86.3406\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 106.1109 - val_loss: 88.9731\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.3598 - val_loss: 85.2899\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 105.8767 - val_loss: 84.7159\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 105.2632 - val_loss: 84.6872\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 104.3999 - val_loss: 88.7351\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 105.7163 - val_loss: 88.4511\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.0795 - val_loss: 91.0116\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 108.3732 - val_loss: 84.0959\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 108.2882 - val_loss: 86.2515\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 7ms/step - loss: 106.9042 - val_loss: 85.0347\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 105.8769 - val_loss: 85.2600\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 106.2993 - val_loss: 83.4202\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 103.9535 - val_loss: 83.1952\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 3ms/step - loss: 103.6256 - val_loss: 83.9107\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 7ms/step - loss: 103.3921 - val_loss: 82.8174\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 3ms/step - loss: 102.7249 - val_loss: 82.5848\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 7ms/step - loss: 103.7597 - val_loss: 82.4572\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 5ms/step - loss: 104.0770 - val_loss: 82.5821\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 103.4994 - val_loss: 82.2735\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 102.1242 - val_loss: 83.0362\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 103.1621 - val_loss: 82.2026\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 103.7104 - val_loss: 82.4210\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 102.5098 - val_loss: 92.2128\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 5ms/step - loss: 112.2848 - val_loss: 87.8350\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 104.3821 - val_loss: 82.0292\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 7ms/step - loss: 105.0282 - val_loss: 85.4470\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 102.7323 - val_loss: 86.8659\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 104.8802 - val_loss: 84.9432\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 102.2725 - val_loss: 81.3917\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 102.2215 - val_loss: 81.1932\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 39ms/step - loss: 1241.9556 - val_loss: 745.1056\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 651.6378 - val_loss: 567.0862\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 7ms/step - loss: 514.1537 - val_loss: 476.7620\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 7ms/step - loss: 452.9831 - val_loss: 433.5892\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 401.3155 - val_loss: 416.5107\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 364.5352 - val_loss: 381.7057\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 337.3718 - val_loss: 364.1333\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 318.1667 - val_loss: 337.7812\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 292.2381 - val_loss: 322.5758\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 275.1644 - val_loss: 311.4643\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 13ms/step - loss: 260.7512 - val_loss: 287.3804\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 244.3706 - val_loss: 269.8875\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 231.8786 - val_loss: 253.5316\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 13ms/step - loss: 221.8229 - val_loss: 240.3649\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 210.2428 - val_loss: 232.6364\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 14ms/step - loss: 203.0194 - val_loss: 224.7280\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 7ms/step - loss: 195.1639 - val_loss: 214.5661\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 5ms/step - loss: 187.1639 - val_loss: 208.8648\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 5ms/step - loss: 182.2218 - val_loss: 199.3658\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.0305 - val_loss: 190.7900\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 170.4893 - val_loss: 185.0806\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 5ms/step - loss: 166.1367 - val_loss: 179.8805\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 7ms/step - loss: 161.8340 - val_loss: 177.4504\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 12ms/step - loss: 158.6376 - val_loss: 172.3344\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 5ms/step - loss: 154.4094 - val_loss: 165.0132\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 153.8846 - val_loss: 169.5207\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 151.8978 - val_loss: 164.6286\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 13ms/step - loss: 148.4705 - val_loss: 152.8963\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 141.5010 - val_loss: 154.8537\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 144.4904 - val_loss: 145.4960\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.4091 - val_loss: 146.8994\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 8ms/step - loss: 136.5232 - val_loss: 139.8599\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 12ms/step - loss: 132.4808 - val_loss: 142.3092\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 12ms/step - loss: 130.6612 - val_loss: 135.3960\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 13ms/step - loss: 128.6750 - val_loss: 134.2431\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 128.4887 - val_loss: 133.6484\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 5ms/step - loss: 126.1846 - val_loss: 127.4712\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.2168 - val_loss: 128.3029\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 122.3001 - val_loss: 125.8226\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.3189 - val_loss: 131.4324\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 7ms/step - loss: 123.2563 - val_loss: 121.8696\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 5ms/step - loss: 121.3221 - val_loss: 120.4118\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.9762 - val_loss: 131.2338\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.1550 - val_loss: 123.6151\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 5ms/step - loss: 120.0669 - val_loss: 118.6666\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.1241 - val_loss: 116.0324\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 5ms/step - loss: 115.6933 - val_loss: 115.2803\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.6627 - val_loss: 114.3228\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.7615 - val_loss: 117.3548\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 7ms/step - loss: 114.9122 - val_loss: 113.2064\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.9976 - val_loss: 111.7338\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.7429 - val_loss: 112.7056\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.9741 - val_loss: 109.9601\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.2240 - val_loss: 110.7119\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.8157 - val_loss: 112.7076\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.3460 - val_loss: 110.5652\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.1194 - val_loss: 109.1516\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.8953 - val_loss: 109.6394\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.1395 - val_loss: 120.5299\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 7ms/step - loss: 112.1706 - val_loss: 108.4813\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 5ms/step - loss: 112.8712 - val_loss: 111.2676\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.4803 - val_loss: 111.2199\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 7ms/step - loss: 112.1024 - val_loss: 107.0012\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 5ms/step - loss: 111.3881 - val_loss: 106.6092\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.6226 - val_loss: 106.4622\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.9936 - val_loss: 107.2117\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.1508 - val_loss: 107.5807\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.7896 - val_loss: 106.5923\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.3520 - val_loss: 106.2427\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.1651 - val_loss: 104.7989\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 7ms/step - loss: 110.1540 - val_loss: 104.6361\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 5ms/step - loss: 112.5346 - val_loss: 105.0293\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 5ms/step - loss: 109.6446 - val_loss: 104.3316\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.8702 - val_loss: 105.5231\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 5ms/step - loss: 110.2510 - val_loss: 104.0623\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.4067 - val_loss: 105.6940\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 5ms/step - loss: 110.4878 - val_loss: 104.5808\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 5ms/step - loss: 110.4788 - val_loss: 107.8695\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 5ms/step - loss: 111.5427 - val_loss: 106.1686\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 5ms/step - loss: 109.1303 - val_loss: 109.1346\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 5ms/step - loss: 114.1355 - val_loss: 102.9989\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.5438 - val_loss: 104.9872\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.4794 - val_loss: 103.2229\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.4439 - val_loss: 103.0766\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.0822 - val_loss: 106.0747\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 108.5328 - val_loss: 103.4718\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 5ms/step - loss: 107.8647 - val_loss: 105.0595\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.0347 - val_loss: 102.7838\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 5ms/step - loss: 115.2402 - val_loss: 102.4822\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 7ms/step - loss: 108.8664 - val_loss: 106.1446\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 14ms/step - loss: 112.1553 - val_loss: 104.3567\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 8ms/step - loss: 108.0422 - val_loss: 102.0858\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 12ms/step - loss: 108.1174 - val_loss: 102.1009\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 8ms/step - loss: 106.9371 - val_loss: 103.5129\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 13ms/step - loss: 107.0765 - val_loss: 102.1164\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 15ms/step - loss: 111.1349 - val_loss: 102.8727\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 12ms/step - loss: 108.3876 - val_loss: 102.1598\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 8ms/step - loss: 108.9910 - val_loss: 103.1318\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 13ms/step - loss: 109.9547 - val_loss: 105.5177\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 16ms/step - loss: 110.3658 - val_loss: 101.5187\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 82ms/step - loss: 121181.1406 - val_loss: 76872.7344\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 19ms/step - loss: 52146.5469 - val_loss: 28019.9258\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 15ms/step - loss: 14521.3232 - val_loss: 4742.3018\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 8ms/step - loss: 2383.7939 - val_loss: 1531.3087\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1741.5302 - val_loss: 1426.9435\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 1550.6464 - val_loss: 1346.4325\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 1394.1809 - val_loss: 1229.0591\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1265.7014 - val_loss: 1139.8494\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 1156.5509 - val_loss: 1053.6482\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 1051.7618 - val_loss: 975.5788\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 7ms/step - loss: 959.7646 - val_loss: 904.0945\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 876.8103 - val_loss: 835.4389\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 800.7563 - val_loss: 778.7419\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 737.7419 - val_loss: 722.0422\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 676.6846 - val_loss: 672.7707\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 625.6262 - val_loss: 624.7425\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 576.6595 - val_loss: 583.4058\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 536.5068 - val_loss: 542.9086\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 8ms/step - loss: 496.2411 - val_loss: 506.3951\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 5ms/step - loss: 464.7809 - val_loss: 474.5970\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 430.4413 - val_loss: 441.1497\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 5ms/step - loss: 404.8491 - val_loss: 413.0569\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 5ms/step - loss: 377.4396 - val_loss: 385.1665\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 7ms/step - loss: 354.7861 - val_loss: 361.8365\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 334.7280 - val_loss: 339.0785\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 7ms/step - loss: 315.6977 - val_loss: 317.4362\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 299.6939 - val_loss: 298.0531\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 283.6480 - val_loss: 281.1928\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 5ms/step - loss: 271.0249 - val_loss: 264.7554\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 255.2759 - val_loss: 250.8075\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 5ms/step - loss: 242.1685 - val_loss: 235.3440\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 229.8894 - val_loss: 222.6355\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 219.3004 - val_loss: 213.0283\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 210.7892 - val_loss: 201.1173\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 200.3143 - val_loss: 192.5329\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 5ms/step - loss: 195.1042 - val_loss: 183.5658\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 5ms/step - loss: 187.7143 - val_loss: 176.6377\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 180.3138 - val_loss: 170.7968\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 175.6337 - val_loss: 164.4447\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 7ms/step - loss: 169.4782 - val_loss: 158.5836\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 164.9691 - val_loss: 152.6080\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 159.9314 - val_loss: 150.0026\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 156.4770 - val_loss: 145.2541\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 153.2545 - val_loss: 141.9470\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 148.3834 - val_loss: 137.5031\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 144.9412 - val_loss: 134.9662\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 142.7041 - val_loss: 131.5798\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 139.9697 - val_loss: 129.1496\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.1802 - val_loss: 127.9674\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 136.1542 - val_loss: 125.5599\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.2699 - val_loss: 125.3903\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 7ms/step - loss: 132.8618 - val_loss: 121.5676\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 5ms/step - loss: 131.4438 - val_loss: 120.1581\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 129.6778 - val_loss: 118.9326\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 128.1516 - val_loss: 117.6942\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 126.8666 - val_loss: 117.6312\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 127.0519 - val_loss: 115.6204\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 125.3568 - val_loss: 114.7815\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 7ms/step - loss: 124.6232 - val_loss: 116.0155\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 5ms/step - loss: 124.2678 - val_loss: 113.5533\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 124.6948 - val_loss: 114.2226\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 122.5398 - val_loss: 112.4702\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 122.5777 - val_loss: 112.1932\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.4147 - val_loss: 111.5776\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 121.4239 - val_loss: 110.8807\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 121.2792 - val_loss: 111.6441\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 3ms/step - loss: 120.9155 - val_loss: 111.3583\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.2057 - val_loss: 110.2614\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.8725 - val_loss: 109.8126\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.0646 - val_loss: 109.7397\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.4030 - val_loss: 109.4162\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.9162 - val_loss: 109.7254\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.8689 - val_loss: 110.4913\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 8ms/step - loss: 119.2615 - val_loss: 110.7389\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.0754 - val_loss: 108.3187\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 15ms/step - loss: 117.7777 - val_loss: 111.4911\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 11ms/step - loss: 118.9714 - val_loss: 108.3383\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.1830 - val_loss: 107.6468\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 13ms/step - loss: 117.5404 - val_loss: 107.5663\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 8ms/step - loss: 116.7165 - val_loss: 112.4040\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 11ms/step - loss: 117.8278 - val_loss: 107.6585\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.6062 - val_loss: 107.9531\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.8130 - val_loss: 107.0039\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 7ms/step - loss: 117.6808 - val_loss: 107.1282\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 7ms/step - loss: 117.8771 - val_loss: 106.4422\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 12ms/step - loss: 118.8874 - val_loss: 106.6504\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.7476 - val_loss: 106.6173\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 11ms/step - loss: 115.8314 - val_loss: 106.4005\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.3432 - val_loss: 107.4466\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 119.0448 - val_loss: 108.4823\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.9228 - val_loss: 105.7002\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.1229 - val_loss: 105.7576\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 5ms/step - loss: 114.9582 - val_loss: 105.8693\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.3905 - val_loss: 105.5535\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 7ms/step - loss: 115.5685 - val_loss: 105.5214\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.3302 - val_loss: 106.3553\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 116.1800 - val_loss: 109.4402\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.0692 - val_loss: 105.0110\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.9117 - val_loss: 105.3672\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.7784 - val_loss: 104.8142\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 78ms/step - loss: 3742.3582 - val_loss: 2618.2974\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 2359.8088 - val_loss: 1758.5378\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 1580.2261 - val_loss: 1335.3856\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1146.0391 - val_loss: 1040.7878\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 857.0194 - val_loss: 795.4196\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 674.1918 - val_loss: 628.7053\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 517.2064 - val_loss: 501.9128\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 5ms/step - loss: 410.5129 - val_loss: 395.2288\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 336.7309 - val_loss: 301.5916\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 267.8713 - val_loss: 246.3123\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 225.4587 - val_loss: 206.1623\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 194.5674 - val_loss: 178.7068\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 170.6062 - val_loss: 151.8138\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 149.9859 - val_loss: 135.5395\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.8053 - val_loss: 124.5824\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 7ms/step - loss: 132.0895 - val_loss: 117.0368\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 129.7444 - val_loss: 118.5974\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.4295 - val_loss: 109.5498\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.8664 - val_loss: 106.1861\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 7ms/step - loss: 118.3475 - val_loss: 107.5276\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 120.9528 - val_loss: 109.2192\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 120.9740 - val_loss: 112.4257\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.8002 - val_loss: 100.6484\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.8507 - val_loss: 100.0845\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.7812 - val_loss: 99.1515\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.9266 - val_loss: 99.0950\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.7170 - val_loss: 100.8719\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.3003 - val_loss: 115.6285\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 5ms/step - loss: 114.6610 - val_loss: 98.5817\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 5ms/step - loss: 112.2507 - val_loss: 98.0742\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 5ms/step - loss: 111.1219 - val_loss: 98.0164\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.5702 - val_loss: 98.3654\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 7ms/step - loss: 115.6720 - val_loss: 129.7666\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.3325 - val_loss: 107.3540\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.7920 - val_loss: 99.9396\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.1316 - val_loss: 99.8174\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 5ms/step - loss: 112.7331 - val_loss: 101.4133\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.2150 - val_loss: 98.4946\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.0410 - val_loss: 98.7431\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 7ms/step - loss: 111.0781 - val_loss: 105.2319\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 5ms/step - loss: 113.1702 - val_loss: 106.6325\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.8219 - val_loss: 97.6531\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.8208 - val_loss: 97.5490\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.9352 - val_loss: 98.1653\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 7ms/step - loss: 110.9344 - val_loss: 98.0593\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.5970 - val_loss: 100.3289\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.9816 - val_loss: 99.6005\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.2734 - val_loss: 98.0288\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.2249 - val_loss: 97.4452\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 5ms/step - loss: 111.4485 - val_loss: 97.8166\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.3312 - val_loss: 98.4324\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.4490 - val_loss: 100.1246\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 7ms/step - loss: 111.7076 - val_loss: 98.8950\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 12ms/step - loss: 111.8059 - val_loss: 102.2071\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.8061 - val_loss: 105.3010\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 13ms/step - loss: 113.0317 - val_loss: 98.2006\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 13ms/step - loss: 111.4083 - val_loss: 97.1215\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.3661 - val_loss: 98.4102\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 13ms/step - loss: 113.2339 - val_loss: 102.3566\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.8483 - val_loss: 97.3110\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.5821 - val_loss: 97.0397\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 9ms/step - loss: 112.3419 - val_loss: 97.2041\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 10ms/step - loss: 122.9992 - val_loss: 110.6373\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 5ms/step - loss: 112.9841 - val_loss: 131.1813\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.7259 - val_loss: 97.3489\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 7ms/step - loss: 113.1757 - val_loss: 107.8923\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 5ms/step - loss: 112.0861 - val_loss: 112.3328\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.1440 - val_loss: 99.7489\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.6199 - val_loss: 97.1310\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 5ms/step - loss: 112.3459 - val_loss: 96.7315\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.7466 - val_loss: 96.8072\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.9132 - val_loss: 98.8186\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.3785 - val_loss: 108.5345\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.1486 - val_loss: 96.8842\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.4731 - val_loss: 98.6813\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 7ms/step - loss: 114.5950 - val_loss: 107.2872\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.3938 - val_loss: 96.7417\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.4342 - val_loss: 99.8351\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.8185 - val_loss: 106.5414\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.9703 - val_loss: 101.6459\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.4510 - val_loss: 116.6012\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 132.8170 - val_loss: 122.7210\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 7ms/step - loss: 116.1576 - val_loss: 98.3195\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.7816 - val_loss: 96.8318\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.2437 - val_loss: 97.5987\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 5ms/step - loss: 110.2060 - val_loss: 97.7114\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.3572 - val_loss: 100.1283\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.4297 - val_loss: 96.9238\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.3980 - val_loss: 103.3687\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.1294 - val_loss: 160.9904\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 124.1946 - val_loss: 115.3134\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 5ms/step - loss: 118.4048 - val_loss: 96.9785\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.9644 - val_loss: 96.9473\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 7ms/step - loss: 113.0268 - val_loss: 108.2425\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.8443 - val_loss: 97.7695\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.3885 - val_loss: 105.1391\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.0140 - val_loss: 99.4697\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.9753 - val_loss: 96.9853\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.6784 - val_loss: 97.7646\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.2373 - val_loss: 146.7006\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 41ms/step - loss: 2691.8320 - val_loss: 1078.9944\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 694.4381 - val_loss: 689.6383\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 568.0812 - val_loss: 545.0851\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 467.5485 - val_loss: 463.3164\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 417.3271 - val_loss: 403.4824\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 382.7201 - val_loss: 365.8240\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 359.5533 - val_loss: 338.2179\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 5ms/step - loss: 338.6124 - val_loss: 315.9974\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 7ms/step - loss: 318.7419 - val_loss: 297.0091\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 5ms/step - loss: 303.4049 - val_loss: 276.9038\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 284.5335 - val_loss: 260.7051\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 269.0425 - val_loss: 244.7117\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 255.3758 - val_loss: 231.9086\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 242.7500 - val_loss: 220.7900\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 231.6491 - val_loss: 212.8786\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 7ms/step - loss: 222.8797 - val_loss: 208.1796\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 5ms/step - loss: 213.0085 - val_loss: 194.6295\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 203.2525 - val_loss: 187.6818\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 196.4125 - val_loss: 182.0667\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 189.5121 - val_loss: 175.7999\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.8595 - val_loss: 172.4247\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 179.2225 - val_loss: 167.7449\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 174.2942 - val_loss: 163.8715\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 171.9502 - val_loss: 162.7687\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 7ms/step - loss: 168.2420 - val_loss: 159.9766\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 164.5353 - val_loss: 155.1512\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.4029 - val_loss: 153.2736\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 159.3861 - val_loss: 153.1342\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 7ms/step - loss: 157.3176 - val_loss: 148.5124\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 5ms/step - loss: 154.6970 - val_loss: 147.2515\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.5717 - val_loss: 145.1198\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 151.3694 - val_loss: 143.6011\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 7ms/step - loss: 150.6265 - val_loss: 142.8200\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 5ms/step - loss: 148.3695 - val_loss: 139.8871\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 146.9272 - val_loss: 138.8717\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 7ms/step - loss: 145.4983 - val_loss: 138.3341\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 13ms/step - loss: 146.1962 - val_loss: 136.9026\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 144.6048 - val_loss: 135.3523\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 7ms/step - loss: 142.5482 - val_loss: 133.4527\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 5ms/step - loss: 140.9308 - val_loss: 132.2669\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 140.3489 - val_loss: 131.5818\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 139.3905 - val_loss: 130.9107\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 13ms/step - loss: 137.9613 - val_loss: 129.8450\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 15ms/step - loss: 137.4298 - val_loss: 128.3909\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 136.1616 - val_loss: 127.4155\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 135.7746 - val_loss: 133.2213\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 136.1232 - val_loss: 125.6473\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 8ms/step - loss: 133.1730 - val_loss: 129.0504\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 10ms/step - loss: 136.1157 - val_loss: 124.5611\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 133.1070 - val_loss: 123.5581\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 132.1040 - val_loss: 123.5912\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 131.8894 - val_loss: 121.8474\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 130.5367 - val_loss: 121.4620\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 130.8002 - val_loss: 121.0370\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 130.1865 - val_loss: 119.8871\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 128.5432 - val_loss: 119.6732\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 127.1651 - val_loss: 122.5846\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 5ms/step - loss: 129.2040 - val_loss: 119.0461\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 130.5833 - val_loss: 119.0682\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 127.0984 - val_loss: 118.3352\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 126.5005 - val_loss: 116.2773\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 125.8340 - val_loss: 115.8458\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 126.3652 - val_loss: 115.2704\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 126.0720 - val_loss: 117.2178\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 125.7194 - val_loss: 114.5405\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 7ms/step - loss: 124.8245 - val_loss: 116.0488\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 5ms/step - loss: 125.6683 - val_loss: 113.2241\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 123.7906 - val_loss: 112.8948\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.6799 - val_loss: 113.5013\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 7ms/step - loss: 122.5183 - val_loss: 112.7336\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.7886 - val_loss: 113.6089\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.0779 - val_loss: 112.4804\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 121.9111 - val_loss: 112.1332\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 121.4833 - val_loss: 111.2200\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.7935 - val_loss: 112.0445\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.7857 - val_loss: 110.7352\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.3358 - val_loss: 109.4188\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 119.3928 - val_loss: 109.0330\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.7641 - val_loss: 108.6806\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 119.6842 - val_loss: 108.8345\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 121.9020 - val_loss: 111.1468\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 120.1189 - val_loss: 107.6385\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 5ms/step - loss: 117.4878 - val_loss: 108.3477\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.3749 - val_loss: 107.7246\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.2709 - val_loss: 107.0136\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.0340 - val_loss: 106.5717\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.5420 - val_loss: 107.0334\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.3476 - val_loss: 107.3342\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 7ms/step - loss: 118.4683 - val_loss: 106.5127\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.8344 - val_loss: 105.8809\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 7ms/step - loss: 116.0545 - val_loss: 105.0728\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 5ms/step - loss: 115.8284 - val_loss: 104.8878\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 5ms/step - loss: 115.9292 - val_loss: 106.6162\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.6562 - val_loss: 104.3280\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.1347 - val_loss: 105.7458\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.2131 - val_loss: 108.9126\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.9721 - val_loss: 103.6338\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 7ms/step - loss: 114.8001 - val_loss: 103.7122\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.9189 - val_loss: 103.1688\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.6717 - val_loss: 103.0075\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 39ms/step - loss: 5708.8833 - val_loss: 4113.5225\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 3812.5010 - val_loss: 2455.0813\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 2479.2688 - val_loss: 1609.4519\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 1767.7559 - val_loss: 1208.1859\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1305.5469 - val_loss: 1070.3711\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 7ms/step - loss: 1063.6364 - val_loss: 916.9225\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 884.7012 - val_loss: 735.9680\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 768.5157 - val_loss: 647.5455\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 667.5684 - val_loss: 612.1166\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 595.6793 - val_loss: 521.7588\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 529.6924 - val_loss: 468.7670\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 5ms/step - loss: 483.2159 - val_loss: 467.0305\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 430.2029 - val_loss: 420.5230\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 395.7782 - val_loss: 374.9842\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 364.5086 - val_loss: 325.1939\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 327.3828 - val_loss: 310.2484\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 296.7505 - val_loss: 265.6411\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 5ms/step - loss: 274.9317 - val_loss: 244.4995\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 253.6068 - val_loss: 232.2715\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 236.0125 - val_loss: 215.0415\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 220.8965 - val_loss: 198.8439\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 13ms/step - loss: 206.1664 - val_loss: 191.0090\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 7ms/step - loss: 194.2145 - val_loss: 178.0410\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.1027 - val_loss: 174.7688\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.1558 - val_loss: 158.2910\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 167.0333 - val_loss: 153.1068\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.7006 - val_loss: 145.2972\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.4280 - val_loss: 139.9821\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 13ms/step - loss: 150.4188 - val_loss: 136.1261\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 13ms/step - loss: 144.7430 - val_loss: 131.9651\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 142.4757 - val_loss: 140.7301\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 13ms/step - loss: 139.1772 - val_loss: 126.5818\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 9ms/step - loss: 135.6400 - val_loss: 123.9206\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 8ms/step - loss: 133.6686 - val_loss: 121.4263\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 130.1238 - val_loss: 122.7219\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 128.4357 - val_loss: 124.6317\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 127.7273 - val_loss: 122.3168\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 124.9513 - val_loss: 115.6657\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 124.7162 - val_loss: 115.5235\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.9571 - val_loss: 113.6480\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 5ms/step - loss: 122.3647 - val_loss: 114.2037\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 122.8749 - val_loss: 112.0395\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 121.8917 - val_loss: 112.7818\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 123.1783 - val_loss: 115.0077\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.2005 - val_loss: 112.4683\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.4226 - val_loss: 112.9295\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.8607 - val_loss: 112.8707\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 120.1388 - val_loss: 112.2704\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.3681 - val_loss: 108.9013\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.6400 - val_loss: 109.7009\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.4301 - val_loss: 109.7564\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.7105 - val_loss: 107.6545\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.6238 - val_loss: 107.2469\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.2519 - val_loss: 107.3242\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.3885 - val_loss: 107.1007\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.4200 - val_loss: 109.5226\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.4287 - val_loss: 106.0756\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.9839 - val_loss: 107.0303\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.5713 - val_loss: 110.5362\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.1320 - val_loss: 109.2078\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.4339 - val_loss: 111.6005\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.7735 - val_loss: 105.8022\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.3301 - val_loss: 104.6384\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.7985 - val_loss: 104.6108\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.8229 - val_loss: 106.6361\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 5ms/step - loss: 114.0097 - val_loss: 104.1694\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.8529 - val_loss: 105.1604\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.7374 - val_loss: 104.1081\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.9576 - val_loss: 103.7345\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.3552 - val_loss: 107.0899\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.7744 - val_loss: 104.4447\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.0546 - val_loss: 104.6463\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.2786 - val_loss: 106.2487\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 7ms/step - loss: 115.2558 - val_loss: 103.2577\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.2849 - val_loss: 103.5383\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.0879 - val_loss: 103.1911\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.7359 - val_loss: 105.8855\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.6300 - val_loss: 105.1729\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.9432 - val_loss: 108.2882\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.6404 - val_loss: 104.1245\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.0899 - val_loss: 103.3990\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.2536 - val_loss: 103.8886\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.2433 - val_loss: 102.1525\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.7281 - val_loss: 104.2735\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.9668 - val_loss: 112.5318\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.4879 - val_loss: 109.7701\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.6071 - val_loss: 105.2519\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.6706 - val_loss: 104.9966\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 5ms/step - loss: 112.3066 - val_loss: 107.7494\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.2549 - val_loss: 101.7818\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 119.7376 - val_loss: 104.3753\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 7ms/step - loss: 116.4303 - val_loss: 103.0867\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.8328 - val_loss: 102.5093\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.0658 - val_loss: 107.3320\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.4357 - val_loss: 101.8631\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.7502 - val_loss: 104.0482\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 112.1239 - val_loss: 102.5909\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.5977 - val_loss: 105.1142\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.1115 - val_loss: 114.1948\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 5ms/step - loss: 118.7661 - val_loss: 104.9544\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 38ms/step - loss: 84661.6406 - val_loss: 55260.0469\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 45893.3438 - val_loss: 32288.0156\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 27365.2520 - val_loss: 20103.5781\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 7ms/step - loss: 17101.3223 - val_loss: 12918.8359\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 7ms/step - loss: 10956.4307 - val_loss: 8417.8955\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 7115.3750 - val_loss: 5489.2568\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 13ms/step - loss: 4648.0029 - val_loss: 3584.4182\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 3041.1372 - val_loss: 2379.3708\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 2031.4905 - val_loss: 1597.6810\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 5ms/step - loss: 1386.5905 - val_loss: 1100.3278\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 7ms/step - loss: 985.4591 - val_loss: 794.9813\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 738.5233 - val_loss: 613.0177\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 594.4793 - val_loss: 500.2322\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 510.3886 - val_loss: 437.4092\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 13ms/step - loss: 464.3986 - val_loss: 402.4214\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 438.6147 - val_loss: 381.5104\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 422.8415 - val_loss: 371.0156\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 7ms/step - loss: 414.1202 - val_loss: 363.9490\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 13ms/step - loss: 407.6235 - val_loss: 359.9865\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 12ms/step - loss: 403.0497 - val_loss: 356.5223\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 398.8664 - val_loss: 353.9880\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 394.9678 - val_loss: 351.3334\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 390.5986 - val_loss: 348.8230\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 5ms/step - loss: 386.3590 - val_loss: 346.1319\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 381.7943 - val_loss: 343.2656\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 377.3780 - val_loss: 340.1122\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 372.4506 - val_loss: 336.2371\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 367.4553 - val_loss: 332.1586\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 361.5277 - val_loss: 328.4374\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 356.0961 - val_loss: 324.2468\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 350.2034 - val_loss: 320.1813\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 344.3996 - val_loss: 315.2390\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 5ms/step - loss: 338.4207 - val_loss: 310.3702\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 5ms/step - loss: 331.6485 - val_loss: 305.5266\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 325.1334 - val_loss: 300.4504\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 317.5248 - val_loss: 295.7170\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 311.6774 - val_loss: 291.1743\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 305.5677 - val_loss: 287.2636\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 299.8923 - val_loss: 283.7447\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 294.0518 - val_loss: 280.5174\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 7ms/step - loss: 289.0171 - val_loss: 277.1605\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 283.8642 - val_loss: 274.0204\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 279.2282 - val_loss: 271.1967\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 274.4077 - val_loss: 268.5683\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 270.0929 - val_loss: 266.2772\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 266.9000 - val_loss: 264.4876\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 263.5324 - val_loss: 262.8758\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 260.9716 - val_loss: 261.6026\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 258.8215 - val_loss: 260.3948\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 256.7416 - val_loss: 258.9781\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 254.7092 - val_loss: 257.9655\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 253.2561 - val_loss: 257.1192\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 251.4779 - val_loss: 255.9865\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 250.3504 - val_loss: 254.9628\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 248.3840 - val_loss: 253.5415\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 246.9964 - val_loss: 252.4598\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 7ms/step - loss: 245.5449 - val_loss: 251.4495\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 244.0526 - val_loss: 250.2371\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 242.5886 - val_loss: 249.4290\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 241.0963 - val_loss: 248.4104\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 5ms/step - loss: 239.8584 - val_loss: 247.7420\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 238.4955 - val_loss: 246.6551\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 237.2491 - val_loss: 245.7222\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 236.0861 - val_loss: 244.8068\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 7ms/step - loss: 234.8213 - val_loss: 244.0375\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 5ms/step - loss: 233.6840 - val_loss: 243.4913\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 5ms/step - loss: 232.8068 - val_loss: 242.4852\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 231.5633 - val_loss: 241.5793\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 230.3682 - val_loss: 240.6935\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 229.5648 - val_loss: 239.5767\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 228.0415 - val_loss: 238.8463\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 227.4284 - val_loss: 237.7424\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 226.1211 - val_loss: 236.9048\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 7ms/step - loss: 225.5199 - val_loss: 236.2480\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 224.8169 - val_loss: 234.8427\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 223.1350 - val_loss: 234.0559\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 222.4730 - val_loss: 233.7509\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 221.2460 - val_loss: 232.1949\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 219.9437 - val_loss: 231.4676\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 218.8950 - val_loss: 230.6263\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 217.9077 - val_loss: 229.5400\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 216.4834 - val_loss: 228.3504\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 215.4089 - val_loss: 227.4536\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 214.2491 - val_loss: 226.6104\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 213.3531 - val_loss: 225.6431\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 211.7100 - val_loss: 224.4308\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 209.9474 - val_loss: 222.9134\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 7ms/step - loss: 208.3730 - val_loss: 221.3379\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 5ms/step - loss: 205.4162 - val_loss: 219.6810\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 202.9827 - val_loss: 217.0069\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 200.6317 - val_loss: 213.8331\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 197.4521 - val_loss: 210.8272\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 194.9120 - val_loss: 207.5378\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 191.5420 - val_loss: 202.6797\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 187.3754 - val_loss: 197.3865\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 182.8623 - val_loss: 190.2056\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.9153 - val_loss: 183.5117\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 173.3328 - val_loss: 176.3172\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 5ms/step - loss: 168.9653 - val_loss: 169.5905\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 162.5330 - val_loss: 161.5879\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 55ms/step - loss: 68974.2578 - val_loss: 39851.3125\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 20ms/step - loss: 25887.6504 - val_loss: 12959.9268\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 14ms/step - loss: 8625.7471 - val_loss: 5009.6108\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 4496.7012 - val_loss: 3930.4570\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 13ms/step - loss: 3865.0439 - val_loss: 3522.3640\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 12ms/step - loss: 3468.6917 - val_loss: 3160.6663\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 5ms/step - loss: 3132.2263 - val_loss: 2842.9148\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 2833.8022 - val_loss: 2574.6780\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 2584.6980 - val_loss: 2361.9739\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 7ms/step - loss: 2378.7886 - val_loss: 2185.9907\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 2213.7463 - val_loss: 2041.8206\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 2077.7444 - val_loss: 1919.5530\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 1955.5178 - val_loss: 1809.5127\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1841.8337 - val_loss: 1707.3849\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1737.2686 - val_loss: 1606.5944\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 1634.7152 - val_loss: 1519.2566\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 1542.5486 - val_loss: 1441.0269\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1455.9894 - val_loss: 1353.5376\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1375.0859 - val_loss: 1281.6525\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 5ms/step - loss: 1296.2454 - val_loss: 1211.1693\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 5ms/step - loss: 1225.2855 - val_loss: 1151.6423\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 1159.5055 - val_loss: 1089.7883\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 1096.7816 - val_loss: 1037.3643\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 1041.3872 - val_loss: 984.3550\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 986.5934 - val_loss: 938.4912\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 937.5720 - val_loss: 894.5859\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 890.6126 - val_loss: 854.3802\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 848.6962 - val_loss: 815.1761\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 808.4757 - val_loss: 782.2753\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 773.1080 - val_loss: 750.8300\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 740.9503 - val_loss: 722.2478\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 709.6785 - val_loss: 692.4249\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 680.2446 - val_loss: 669.1334\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 652.9901 - val_loss: 644.0056\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 7ms/step - loss: 628.4597 - val_loss: 621.6814\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 604.4559 - val_loss: 603.3884\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 584.4080 - val_loss: 582.7233\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 565.2469 - val_loss: 563.6499\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 547.0512 - val_loss: 549.4483\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 529.4220 - val_loss: 533.1534\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 512.4654 - val_loss: 517.5671\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 498.0486 - val_loss: 505.7325\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 484.9606 - val_loss: 490.4303\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 471.1466 - val_loss: 479.6563\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 7ms/step - loss: 458.6118 - val_loss: 467.9086\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 5ms/step - loss: 447.7309 - val_loss: 456.0509\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 436.0674 - val_loss: 446.5222\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 425.5444 - val_loss: 436.0487\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 416.0070 - val_loss: 427.1746\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 407.8926 - val_loss: 417.3489\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 397.7908 - val_loss: 409.0795\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 5ms/step - loss: 389.8273 - val_loss: 399.8055\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 381.1654 - val_loss: 390.8385\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 373.4715 - val_loss: 384.8172\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 366.5042 - val_loss: 376.1624\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 7ms/step - loss: 358.8276 - val_loss: 368.2720\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 352.6003 - val_loss: 361.9289\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 346.2020 - val_loss: 354.4313\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 5ms/step - loss: 338.5991 - val_loss: 346.6705\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 331.6710 - val_loss: 341.5784\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 7ms/step - loss: 325.8665 - val_loss: 333.5545\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 319.8438 - val_loss: 328.9669\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 314.5555 - val_loss: 321.0894\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 308.6167 - val_loss: 315.1306\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 303.5215 - val_loss: 309.7052\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 298.4504 - val_loss: 303.3204\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 293.1979 - val_loss: 299.0100\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 288.4440 - val_loss: 293.3606\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 7ms/step - loss: 284.3738 - val_loss: 288.4263\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 5ms/step - loss: 278.6963 - val_loss: 282.9219\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 273.5977 - val_loss: 278.0170\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 269.5684 - val_loss: 272.9253\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 265.8007 - val_loss: 269.1534\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 260.7626 - val_loss: 263.7904\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 256.5796 - val_loss: 259.1979\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 252.6760 - val_loss: 255.1189\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 7ms/step - loss: 249.1499 - val_loss: 250.7093\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 245.7152 - val_loss: 246.5645\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 243.3582 - val_loss: 243.0510\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 238.1087 - val_loss: 240.9946\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 235.2348 - val_loss: 235.2339\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 231.1135 - val_loss: 231.2082\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 5ms/step - loss: 228.4792 - val_loss: 227.8258\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 225.0476 - val_loss: 224.3247\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 222.4546 - val_loss: 221.3257\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 5ms/step - loss: 219.2852 - val_loss: 217.6208\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 7ms/step - loss: 216.9286 - val_loss: 214.4288\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 213.0483 - val_loss: 211.6300\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 13ms/step - loss: 211.5450 - val_loss: 210.1244\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 207.4880 - val_loss: 205.3124\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 13ms/step - loss: 204.6891 - val_loss: 202.7139\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 201.7467 - val_loss: 199.9498\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 199.9207 - val_loss: 197.5258\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 13ms/step - loss: 199.1955 - val_loss: 197.7353\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 8ms/step - loss: 197.6657 - val_loss: 192.0634\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 11ms/step - loss: 193.5034 - val_loss: 189.2199\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 190.3096 - val_loss: 186.8063\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 13ms/step - loss: 190.1358 - val_loss: 185.3901\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 186.5189 - val_loss: 182.4702\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.8466 - val_loss: 179.9252\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 37ms/step - loss: 60268.9727 - val_loss: 15576.1650\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 13166.6328 - val_loss: 9818.5371\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 10472.9072 - val_loss: 8519.9980\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 9292.1084 - val_loss: 7492.5112\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 8416.4756 - val_loss: 6809.6787\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 7524.0913 - val_loss: 6095.0884\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 6703.7852 - val_loss: 5465.3633\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 5959.9702 - val_loss: 4841.3760\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 7ms/step - loss: 5288.4995 - val_loss: 4379.6030\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 5ms/step - loss: 4693.1226 - val_loss: 3890.1040\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 4150.3877 - val_loss: 3500.2002\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 3710.7151 - val_loss: 3133.6646\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 3276.6152 - val_loss: 2783.7822\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 2925.2915 - val_loss: 2522.9016\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 2607.1848 - val_loss: 2282.4092\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 2331.9602 - val_loss: 2043.6807\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 7ms/step - loss: 2101.3967 - val_loss: 1857.8475\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 1888.7070 - val_loss: 1741.2733\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 1712.2711 - val_loss: 1565.4891\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1549.7681 - val_loss: 1449.8306\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 1412.3619 - val_loss: 1327.6123\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 1292.5402 - val_loss: 1213.2367\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 1182.1399 - val_loss: 1131.5839\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 7ms/step - loss: 1089.6150 - val_loss: 1080.6868\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 1003.9583 - val_loss: 975.3806\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 939.1840 - val_loss: 913.5759\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 874.7379 - val_loss: 862.2343\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 813.8981 - val_loss: 800.5518\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 760.0530 - val_loss: 752.9602\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 714.0438 - val_loss: 702.9636\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 7ms/step - loss: 673.7504 - val_loss: 660.6442\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 5ms/step - loss: 634.3949 - val_loss: 616.9749\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 5ms/step - loss: 598.7801 - val_loss: 581.4940\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 567.4636 - val_loss: 544.2582\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 543.0526 - val_loss: 532.0146\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 508.7382 - val_loss: 487.1817\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 484.0424 - val_loss: 471.9113\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 5ms/step - loss: 458.7037 - val_loss: 437.5484\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 5ms/step - loss: 438.1540 - val_loss: 420.1940\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 419.6401 - val_loss: 395.5788\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 400.3095 - val_loss: 385.6109\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 384.4530 - val_loss: 359.2880\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 369.3898 - val_loss: 344.5861\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 355.7508 - val_loss: 330.4508\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 343.6446 - val_loss: 318.5695\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 7ms/step - loss: 333.2779 - val_loss: 309.5771\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 323.8000 - val_loss: 297.4124\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 5ms/step - loss: 312.0296 - val_loss: 284.8395\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 5ms/step - loss: 305.3197 - val_loss: 277.0664\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 297.3411 - val_loss: 268.2917\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 291.6402 - val_loss: 262.0001\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 285.4985 - val_loss: 257.0609\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 7ms/step - loss: 282.1206 - val_loss: 254.3097\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 271.8511 - val_loss: 243.5173\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 7ms/step - loss: 266.6228 - val_loss: 243.2321\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 5ms/step - loss: 264.6533 - val_loss: 233.6542\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 258.2468 - val_loss: 229.2750\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 252.1225 - val_loss: 225.1935\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 250.6359 - val_loss: 222.8178\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 254.0020 - val_loss: 223.5393\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 245.2539 - val_loss: 212.5262\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 237.4672 - val_loss: 209.7620\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 7ms/step - loss: 234.8587 - val_loss: 206.4756\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 232.5316 - val_loss: 205.1469\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 230.4018 - val_loss: 202.4564\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 226.5997 - val_loss: 202.8011\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 228.5239 - val_loss: 199.6357\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 7ms/step - loss: 229.3958 - val_loss: 194.0359\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 218.6087 - val_loss: 196.7535\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 215.7901 - val_loss: 188.3734\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 214.4545 - val_loss: 186.9872\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 211.0215 - val_loss: 184.6257\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 12ms/step - loss: 207.7287 - val_loss: 189.8253\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 207.4073 - val_loss: 179.7935\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 7ms/step - loss: 203.8578 - val_loss: 177.2260\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 201.4982 - val_loss: 177.0987\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 13ms/step - loss: 198.0623 - val_loss: 173.2655\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 13ms/step - loss: 197.2598 - val_loss: 172.4502\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 193.8889 - val_loss: 169.8659\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 194.0110 - val_loss: 167.9675\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 191.2619 - val_loss: 171.2617\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 7ms/step - loss: 190.4795 - val_loss: 165.2859\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 13ms/step - loss: 185.1638 - val_loss: 162.5454\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 184.9784 - val_loss: 159.8364\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 7ms/step - loss: 180.9762 - val_loss: 164.1656\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 10ms/step - loss: 183.7186 - val_loss: 164.2585\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 180.5257 - val_loss: 162.2542\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.0999 - val_loss: 159.0190\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 175.4769 - val_loss: 166.5714\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 173.5038 - val_loss: 147.6380\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 170.9983 - val_loss: 152.1981\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 169.9474 - val_loss: 144.3272\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 166.5639 - val_loss: 142.5313\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 163.5331 - val_loss: 142.6637\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.9064 - val_loss: 139.2241\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.7243 - val_loss: 138.1561\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 159.7740 - val_loss: 136.4395\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 157.5431 - val_loss: 135.0040\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 157.8275 - val_loss: 133.4123\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.1388 - val_loss: 136.5880\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 37ms/step - loss: 2614.4844 - val_loss: 2091.6421\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 9ms/step - loss: 2029.1897 - val_loss: 1591.7556\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 1567.6682 - val_loss: 1209.3798\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 1152.6036 - val_loss: 936.9898\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 889.3320 - val_loss: 751.5759\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 701.1698 - val_loss: 627.4479\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 7ms/step - loss: 569.9220 - val_loss: 545.8790\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 490.0020 - val_loss: 488.2720\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 426.5285 - val_loss: 437.6782\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 384.9793 - val_loss: 398.7302\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 354.1332 - val_loss: 366.9164\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 328.3590 - val_loss: 340.7897\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 306.0168 - val_loss: 316.5315\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 288.9726 - val_loss: 296.4439\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 277.3889 - val_loss: 292.7199\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 262.5152 - val_loss: 268.3907\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 248.8444 - val_loss: 254.6646\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 241.0192 - val_loss: 245.4305\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 234.5728 - val_loss: 238.2837\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 223.4487 - val_loss: 222.6668\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 216.6142 - val_loss: 215.6145\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 210.0912 - val_loss: 215.6670\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 205.1274 - val_loss: 201.5117\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 5ms/step - loss: 198.2470 - val_loss: 195.6249\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 194.0714 - val_loss: 195.0621\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 189.7484 - val_loss: 185.3227\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 187.7031 - val_loss: 182.8470\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 180.0550 - val_loss: 176.5266\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 7ms/step - loss: 176.5202 - val_loss: 172.7100\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 174.4754 - val_loss: 171.2685\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 7ms/step - loss: 174.3607 - val_loss: 172.0282\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.2573 - val_loss: 163.7382\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 167.8039 - val_loss: 159.4378\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 164.2164 - val_loss: 160.1979\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.7321 - val_loss: 155.2390\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 157.9814 - val_loss: 153.9232\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.0474 - val_loss: 153.2772\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 153.7839 - val_loss: 153.4262\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 153.0426 - val_loss: 146.2674\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.9472 - val_loss: 146.0213\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 7ms/step - loss: 151.4300 - val_loss: 142.6359\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 147.2104 - val_loss: 141.0645\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 145.8023 - val_loss: 142.3336\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 146.9296 - val_loss: 152.4875\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 148.8028 - val_loss: 137.8033\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 142.0018 - val_loss: 136.7457\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 141.0336 - val_loss: 136.1458\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 140.2831 - val_loss: 134.0894\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 7ms/step - loss: 139.0953 - val_loss: 131.8143\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 137.4650 - val_loss: 131.7086\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 137.2399 - val_loss: 134.3632\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 137.0975 - val_loss: 129.4315\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 135.1729 - val_loss: 127.7985\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 7ms/step - loss: 133.6799 - val_loss: 127.3309\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 132.7882 - val_loss: 126.7510\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 133.1251 - val_loss: 125.4498\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 131.9263 - val_loss: 127.4555\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 132.6021 - val_loss: 124.5266\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 130.1219 - val_loss: 126.1154\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 129.5421 - val_loss: 122.4464\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 8ms/step - loss: 128.9077 - val_loss: 121.4842\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 7ms/step - loss: 127.3896 - val_loss: 123.5046\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 129.4711 - val_loss: 123.2152\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 7ms/step - loss: 126.5225 - val_loss: 120.2176\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 126.0738 - val_loss: 119.7942\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 13ms/step - loss: 129.2649 - val_loss: 125.1287\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 131.0693 - val_loss: 122.5038\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 129.2309 - val_loss: 120.4893\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 124.8247 - val_loss: 117.2023\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.7190 - val_loss: 118.0047\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 8ms/step - loss: 125.1592 - val_loss: 116.9413\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 7ms/step - loss: 124.1181 - val_loss: 115.8577\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.0825 - val_loss: 115.3335\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 13ms/step - loss: 122.6413 - val_loss: 116.3851\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.7836 - val_loss: 114.5427\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.1047 - val_loss: 115.1357\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 7ms/step - loss: 122.6709 - val_loss: 114.2130\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 12ms/step - loss: 120.6580 - val_loss: 113.5885\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 5ms/step - loss: 120.8292 - val_loss: 113.3959\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.1406 - val_loss: 113.0429\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.3146 - val_loss: 114.2851\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.8833 - val_loss: 112.3323\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 119.4049 - val_loss: 114.8846\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.7601 - val_loss: 112.0729\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.6116 - val_loss: 111.8844\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 119.3369 - val_loss: 111.6718\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.3781 - val_loss: 111.5547\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.4867 - val_loss: 111.6373\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 120.5002 - val_loss: 114.4120\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.9756 - val_loss: 113.7219\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 119.1797 - val_loss: 112.1593\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 119.3770 - val_loss: 113.5346\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 121.4245 - val_loss: 111.6994\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 7ms/step - loss: 118.2448 - val_loss: 110.7243\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.0567 - val_loss: 110.4462\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.3581 - val_loss: 110.5633\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.1843 - val_loss: 118.1342\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 7ms/step - loss: 119.1285 - val_loss: 109.3920\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.2815 - val_loss: 111.3142\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.9531 - val_loss: 111.2281\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 40ms/step - loss: 492646.5625 - val_loss: 418304.7188\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 348622.0938 - val_loss: 285870.0625\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 232309.9844 - val_loss: 186207.9688\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 148090.9688 - val_loss: 117257.5156\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 91030.0234 - val_loss: 70952.7734\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 53610.3203 - val_loss: 41532.4492\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 30453.2207 - val_loss: 23869.9531\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 17128.1211 - val_loss: 13818.7148\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 9936.9521 - val_loss: 8606.0078\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 6325.9180 - val_loss: 6114.7725\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 4706.8267 - val_loss: 4944.5825\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 7ms/step - loss: 4015.2634 - val_loss: 4412.8784\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 3727.7725 - val_loss: 4158.6680\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 3601.2095 - val_loss: 4029.6101\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 7ms/step - loss: 3534.3567 - val_loss: 3949.4194\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 3488.4783 - val_loss: 3888.1946\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 5ms/step - loss: 3446.4612 - val_loss: 3830.0615\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 3407.0569 - val_loss: 3776.9070\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 7ms/step - loss: 3364.6782 - val_loss: 3722.3398\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 3323.6914 - val_loss: 3673.9062\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 3281.5396 - val_loss: 3618.2715\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 3240.1587 - val_loss: 3567.0474\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 3200.5195 - val_loss: 3512.0764\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 3157.7754 - val_loss: 3465.3035\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 3114.9709 - val_loss: 3413.0967\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 3073.4041 - val_loss: 3359.4482\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 5ms/step - loss: 3032.0898 - val_loss: 3302.4751\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 5ms/step - loss: 2987.6846 - val_loss: 3250.1252\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 2945.3838 - val_loss: 3198.6992\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 2902.7896 - val_loss: 3149.6699\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 2857.2642 - val_loss: 3090.0288\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 2813.4014 - val_loss: 3036.8948\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 2771.2065 - val_loss: 2988.1963\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 2728.7429 - val_loss: 2943.8062\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 2683.2935 - val_loss: 2878.5144\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 7ms/step - loss: 2636.2375 - val_loss: 2829.5388\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 5ms/step - loss: 2585.6821 - val_loss: 2769.3027\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 2535.3540 - val_loss: 2715.5190\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 2486.4441 - val_loss: 2660.9299\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 2436.3240 - val_loss: 2603.3184\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 2381.2104 - val_loss: 2551.3240\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 2330.0625 - val_loss: 2494.8213\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 2276.3145 - val_loss: 2432.8850\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 8ms/step - loss: 2220.4341 - val_loss: 2366.7351\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 2165.6841 - val_loss: 2308.3901\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 2108.8052 - val_loss: 2251.8201\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 2051.8003 - val_loss: 2185.5232\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 1993.4924 - val_loss: 2129.5461\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 7ms/step - loss: 1935.5432 - val_loss: 2069.4263\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 7ms/step - loss: 1877.4719 - val_loss: 2003.4337\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 9ms/step - loss: 1816.1228 - val_loss: 1942.4739\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 5ms/step - loss: 1754.8856 - val_loss: 1876.5995\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 1693.2999 - val_loss: 1814.9951\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 1630.8514 - val_loss: 1749.0186\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 13ms/step - loss: 1569.6886 - val_loss: 1685.3451\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 1509.0826 - val_loss: 1625.2943\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 7ms/step - loss: 1449.4899 - val_loss: 1563.6234\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 5ms/step - loss: 1390.8044 - val_loss: 1503.4973\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 13ms/step - loss: 1335.5896 - val_loss: 1438.2196\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 1278.9915 - val_loss: 1379.4990\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 1225.2001 - val_loss: 1321.7196\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 1173.8025 - val_loss: 1262.1875\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 7ms/step - loss: 1127.5854 - val_loss: 1203.7302\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 12ms/step - loss: 1078.7708 - val_loss: 1156.4348\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 1039.0549 - val_loss: 1107.5620\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 8ms/step - loss: 1001.7927 - val_loss: 1065.4921\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 9ms/step - loss: 969.1433 - val_loss: 1029.5419\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 5ms/step - loss: 938.1206 - val_loss: 991.9559\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 5ms/step - loss: 911.0959 - val_loss: 961.0473\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 5ms/step - loss: 886.1116 - val_loss: 931.6455\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 863.5972 - val_loss: 904.5479\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 843.4457 - val_loss: 881.5895\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 824.5144 - val_loss: 856.7528\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 807.6841 - val_loss: 837.8618\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 793.5994 - val_loss: 817.6039\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 7ms/step - loss: 780.3381 - val_loss: 803.0992\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 763.9115 - val_loss: 784.9126\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 5ms/step - loss: 750.9899 - val_loss: 769.3347\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 7ms/step - loss: 739.1665 - val_loss: 755.7034\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 728.0444 - val_loss: 741.7695\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 716.8224 - val_loss: 728.7173\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 706.3147 - val_loss: 718.0259\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 7ms/step - loss: 697.8715 - val_loss: 704.3497\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 5ms/step - loss: 687.0564 - val_loss: 693.5181\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 678.3064 - val_loss: 683.0128\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 668.8834 - val_loss: 671.7526\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 661.5670 - val_loss: 661.1613\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 652.8785 - val_loss: 651.7216\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 644.9898 - val_loss: 643.0662\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 638.6497 - val_loss: 634.3266\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 7ms/step - loss: 631.0371 - val_loss: 625.9057\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 624.3724 - val_loss: 617.3353\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 617.0298 - val_loss: 611.3109\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 610.3473 - val_loss: 602.3123\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 604.0336 - val_loss: 595.0017\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 7ms/step - loss: 598.0430 - val_loss: 586.5606\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 590.7972 - val_loss: 579.5860\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 584.7371 - val_loss: 573.5767\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 578.0671 - val_loss: 565.9005\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 572.0283 - val_loss: 559.5195\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 38ms/step - loss: 76406.9141 - val_loss: 39542.2109\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 24918.1777 - val_loss: 10046.2998\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 6444.2695 - val_loss: 2445.1628\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 2120.1804 - val_loss: 1316.8490\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1453.1697 - val_loss: 1283.8003\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 7ms/step - loss: 1369.6571 - val_loss: 1267.8634\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 1323.1487 - val_loss: 1219.4620\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 1276.5929 - val_loss: 1185.3052\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 7ms/step - loss: 1227.9070 - val_loss: 1136.6436\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 1181.9077 - val_loss: 1097.9084\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 1133.9673 - val_loss: 1052.7545\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 1087.5522 - val_loss: 1011.9011\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 1042.8835 - val_loss: 983.6520\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 998.9379 - val_loss: 935.1545\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 959.2399 - val_loss: 905.5259\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 916.3215 - val_loss: 865.3698\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 877.6837 - val_loss: 837.3469\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 839.3585 - val_loss: 799.0132\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 805.3915 - val_loss: 766.4269\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 771.6819 - val_loss: 740.4218\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 5ms/step - loss: 742.7649 - val_loss: 709.0946\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 7ms/step - loss: 712.1463 - val_loss: 694.5190\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 681.5529 - val_loss: 659.3427\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 657.5231 - val_loss: 639.0595\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 629.4608 - val_loss: 613.2563\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 606.7589 - val_loss: 596.9029\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 586.5177 - val_loss: 572.5635\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 564.1460 - val_loss: 558.0507\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 545.3211 - val_loss: 537.6166\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 527.5368 - val_loss: 521.3287\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 511.0887 - val_loss: 507.1010\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 494.6421 - val_loss: 490.0792\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 479.2845 - val_loss: 474.7704\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 464.6927 - val_loss: 463.9257\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 451.5862 - val_loss: 449.8340\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 439.3548 - val_loss: 439.1306\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 427.1768 - val_loss: 427.5284\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 7ms/step - loss: 415.0280 - val_loss: 414.4206\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 13ms/step - loss: 404.5157 - val_loss: 405.5539\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 12ms/step - loss: 396.2728 - val_loss: 398.4742\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 384.8629 - val_loss: 384.5126\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 375.3842 - val_loss: 374.9112\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 366.8357 - val_loss: 367.1344\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 358.2025 - val_loss: 355.9020\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 351.3599 - val_loss: 350.1904\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 13ms/step - loss: 342.8600 - val_loss: 339.2195\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 336.3354 - val_loss: 335.3333\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 328.1782 - val_loss: 325.8257\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 13ms/step - loss: 321.5532 - val_loss: 320.2427\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 7ms/step - loss: 315.3298 - val_loss: 311.1245\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 7ms/step - loss: 308.8547 - val_loss: 304.4444\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 10ms/step - loss: 302.5375 - val_loss: 300.2075\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 297.1259 - val_loss: 293.6324\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 291.0861 - val_loss: 285.9325\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 285.7370 - val_loss: 282.1401\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 280.5651 - val_loss: 273.8383\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 5ms/step - loss: 276.3380 - val_loss: 269.4908\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 270.8983 - val_loss: 264.1985\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 265.3343 - val_loss: 258.0867\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 261.4610 - val_loss: 252.5017\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 256.1618 - val_loss: 247.5196\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 251.8806 - val_loss: 243.7110\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 248.6485 - val_loss: 238.6104\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 243.4436 - val_loss: 235.6558\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 239.4783 - val_loss: 230.2080\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 234.7659 - val_loss: 226.4753\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 231.3603 - val_loss: 221.8622\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 230.6776 - val_loss: 220.0658\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 224.5194 - val_loss: 213.5435\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 220.2252 - val_loss: 210.0657\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 217.8750 - val_loss: 207.6978\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 213.7877 - val_loss: 202.5359\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 210.2845 - val_loss: 199.3935\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 206.8806 - val_loss: 195.0235\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 204.7309 - val_loss: 192.5184\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 7ms/step - loss: 201.6254 - val_loss: 189.7231\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 198.2943 - val_loss: 185.6480\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 195.7577 - val_loss: 182.2613\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 193.5562 - val_loss: 179.5014\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 191.4110 - val_loss: 177.1892\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 7ms/step - loss: 187.7326 - val_loss: 173.8184\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 186.9246 - val_loss: 171.2641\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 184.7331 - val_loss: 169.9963\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 180.8499 - val_loss: 167.3345\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.0743 - val_loss: 163.8161\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 7ms/step - loss: 177.4068 - val_loss: 164.0097\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 173.5972 - val_loss: 158.2502\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 171.2498 - val_loss: 157.4277\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 169.8653 - val_loss: 153.8480\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 168.7714 - val_loss: 153.3233\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.3231 - val_loss: 151.3114\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 164.7845 - val_loss: 147.6029\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 5ms/step - loss: 162.4433 - val_loss: 145.4899\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 159.8444 - val_loss: 144.5680\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.6498 - val_loss: 142.0534\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 157.1995 - val_loss: 140.1841\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.8999 - val_loss: 138.7661\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.3733 - val_loss: 137.4208\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 151.5714 - val_loss: 139.0048\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.5804 - val_loss: 134.1532\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 39ms/step - loss: 141472.3125 - val_loss: 102926.1875\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 84322.1250 - val_loss: 60415.2188\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 49361.6211 - val_loss: 34614.8398\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 28055.7148 - val_loss: 19265.5918\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 15452.9199 - val_loss: 10210.9229\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 8112.6851 - val_loss: 5112.3213\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 4063.8076 - val_loss: 2447.8042\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 2016.9987 - val_loss: 1175.1587\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 1074.7101 - val_loss: 647.6177\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 677.7432 - val_loss: 460.6617\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 532.5034 - val_loss: 399.2605\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 479.2746 - val_loss: 379.4159\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 458.1194 - val_loss: 370.3186\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 7ms/step - loss: 444.4773 - val_loss: 362.6111\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 433.9673 - val_loss: 354.9810\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 423.3571 - val_loss: 346.9854\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 413.8090 - val_loss: 338.7371\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 404.3305 - val_loss: 330.7762\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 394.5778 - val_loss: 323.0642\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 385.6173 - val_loss: 315.3886\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 5ms/step - loss: 376.6535 - val_loss: 307.4102\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 367.5080 - val_loss: 299.7932\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 359.4094 - val_loss: 293.8396\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 350.5661 - val_loss: 287.3716\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 343.6000 - val_loss: 279.5257\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 5ms/step - loss: 335.1584 - val_loss: 274.1854\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 328.7353 - val_loss: 269.0112\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 8ms/step - loss: 320.5463 - val_loss: 262.3625\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 13ms/step - loss: 314.1564 - val_loss: 257.5531\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 13ms/step - loss: 307.6330 - val_loss: 251.6900\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 13ms/step - loss: 301.2672 - val_loss: 247.1932\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 14ms/step - loss: 295.4842 - val_loss: 243.4442\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 13ms/step - loss: 289.5577 - val_loss: 237.5277\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 283.9880 - val_loss: 234.0470\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 7ms/step - loss: 278.3723 - val_loss: 229.6691\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 7ms/step - loss: 273.5831 - val_loss: 226.9781\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 13ms/step - loss: 268.4019 - val_loss: 222.5773\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 11ms/step - loss: 264.0305 - val_loss: 219.2455\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 259.3598 - val_loss: 216.4459\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 7ms/step - loss: 255.1180 - val_loss: 212.6861\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 250.9022 - val_loss: 210.2710\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 7ms/step - loss: 247.1297 - val_loss: 207.6858\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 243.3528 - val_loss: 204.9833\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 239.6284 - val_loss: 202.0215\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 236.2231 - val_loss: 199.6598\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 7ms/step - loss: 232.7992 - val_loss: 197.8652\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 229.5659 - val_loss: 195.6157\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 226.6660 - val_loss: 193.3436\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 223.7281 - val_loss: 192.2900\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 221.1143 - val_loss: 189.3203\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 8ms/step - loss: 218.3463 - val_loss: 188.5276\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 11ms/step - loss: 215.6527 - val_loss: 186.5408\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 213.0858 - val_loss: 184.8633\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 210.8753 - val_loss: 183.9178\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 208.5343 - val_loss: 181.9633\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 206.2568 - val_loss: 180.6276\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 204.6535 - val_loss: 179.6260\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 202.7426 - val_loss: 177.9420\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 200.3858 - val_loss: 176.6427\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 5ms/step - loss: 198.6438 - val_loss: 176.0943\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 196.6226 - val_loss: 174.8250\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 194.8976 - val_loss: 172.8214\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 7ms/step - loss: 193.5665 - val_loss: 172.2330\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 191.7382 - val_loss: 170.9675\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 190.0694 - val_loss: 170.0867\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 188.7588 - val_loss: 169.2283\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 187.0956 - val_loss: 167.9490\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 185.7484 - val_loss: 166.8878\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 184.3888 - val_loss: 166.5331\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 183.3098 - val_loss: 165.0260\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 181.6613 - val_loss: 164.2462\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 181.2330 - val_loss: 163.6238\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.3592 - val_loss: 162.4848\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.8975 - val_loss: 161.5475\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 176.8602 - val_loss: 161.2585\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 7ms/step - loss: 175.7410 - val_loss: 159.9002\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 174.5793 - val_loss: 159.5318\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 173.5258 - val_loss: 158.7235\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 172.5616 - val_loss: 157.7971\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 171.4657 - val_loss: 157.4363\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 5ms/step - loss: 170.4275 - val_loss: 156.4926\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 5ms/step - loss: 169.6335 - val_loss: 155.7591\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 7ms/step - loss: 168.4899 - val_loss: 154.9044\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 5ms/step - loss: 168.2418 - val_loss: 154.7274\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 166.7421 - val_loss: 153.5234\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 166.1886 - val_loss: 152.6470\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 164.8945 - val_loss: 152.7931\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 5ms/step - loss: 164.2368 - val_loss: 152.4470\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 3ms/step - loss: 163.3640 - val_loss: 150.9347\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 162.6174 - val_loss: 150.9198\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 162.6209 - val_loss: 149.9212\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 161.3296 - val_loss: 149.6080\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 5ms/step - loss: 160.4682 - val_loss: 148.4599\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.3098 - val_loss: 148.5522\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 158.6644 - val_loss: 147.9616\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 157.9454 - val_loss: 147.2038\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 5ms/step - loss: 157.1940 - val_loss: 147.2059\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.7898 - val_loss: 146.0538\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 155.6081 - val_loss: 145.6381\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 7ms/step - loss: 155.3622 - val_loss: 144.6234\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_mse = np.mean(mse_list)\n",
        "mean_mse"
      ],
      "metadata": {
        "id": "T8UbqjFjZH6F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6b74668-becd-4219-e7fe-ddca8440aeb4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "169.48894686957613"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "std_mse = np.std(mse_list)\n",
        "std_mse"
      ],
      "metadata": {
        "id": "EYnknV4IZe2J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d9e0904-c98a-4629-feb5-1100bc4943db"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "202.54831400363884"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}