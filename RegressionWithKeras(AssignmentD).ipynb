{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O730iQKMPnLn"
      },
      "outputs": [],
      "source": [
        "#Importing required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "bA4Zav-iPv2J"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the dataset\n",
        "df = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wTpvdw-tP2Al",
        "outputId": "8e2f399a-c5e3-431c-be8b-ea49154b6a88"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
              "0   540.0                 0.0      0.0  162.0               2.5   \n",
              "1   540.0                 0.0      0.0  162.0               2.5   \n",
              "2   332.5               142.5      0.0  228.0               0.0   \n",
              "3   332.5               142.5      0.0  228.0               0.0   \n",
              "4   198.6               132.4      0.0  192.0               0.0   \n",
              "\n",
              "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
              "0            1040.0           676.0   28     79.99  \n",
              "1            1055.0           676.0   28     61.89  \n",
              "2             932.0           594.0  270     40.27  \n",
              "3             932.0           594.0  365     41.05  \n",
              "4             978.4           825.5  360     44.30  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e0b89e98-8016-4f19-9486-38ee81cada41\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "      <th>Strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>79.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1055.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>61.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>270</td>\n",
              "      <td>40.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>365</td>\n",
              "      <td>41.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198.6</td>\n",
              "      <td>132.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978.4</td>\n",
              "      <td>825.5</td>\n",
              "      <td>360</td>\n",
              "      <td>44.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0b89e98-8016-4f19-9486-38ee81cada41')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e0b89e98-8016-4f19-9486-38ee81cada41 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e0b89e98-8016-4f19-9486-38ee81cada41');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7d68627b-01e0-4935-9c06-714255639580\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d68627b-01e0-4935-9c06-714255639580')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7d68627b-01e0-4935-9c06-714255639580 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1030,\n  \"fields\": [\n    {\n      \"column\": \"Cement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 104.50636449481543,\n        \"min\": 102.0,\n        \"max\": 540.0,\n        \"num_unique_values\": 278,\n        \"samples\": [\n          337.9,\n          290.2,\n          262.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Blast Furnace Slag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 86.27934174810551,\n        \"min\": 0.0,\n        \"max\": 359.4,\n        \"num_unique_values\": 185,\n        \"samples\": [\n          94.7,\n          119.0,\n          136.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fly Ash\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63.99700415268812,\n        \"min\": 0.0,\n        \"max\": 200.1,\n        \"num_unique_values\": 156,\n        \"samples\": [\n          98.0,\n          142.0,\n          195.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Water\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.354218565032525,\n        \"min\": 121.8,\n        \"max\": 247.0,\n        \"num_unique_values\": 195,\n        \"samples\": [\n          195.4,\n          183.8,\n          127.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Superplasticizer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.973841392485506,\n        \"min\": 0.0,\n        \"max\": 32.2,\n        \"num_unique_values\": 111,\n        \"samples\": [\n          15.0,\n          28.2,\n          16.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Coarse Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 77.75395396672091,\n        \"min\": 801.0,\n        \"max\": 1145.0,\n        \"num_unique_values\": 284,\n        \"samples\": [\n          852.1,\n          913.9,\n          914.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fine Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80.17598014240434,\n        \"min\": 594.0,\n        \"max\": 992.6,\n        \"num_unique_values\": 302,\n        \"samples\": [\n          710.0,\n          695.4,\n          769.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63,\n        \"min\": 1,\n        \"max\": 365,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          91,\n          100,\n          28\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Strength\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.705741961912505,\n        \"min\": 2.33,\n        \"max\": 82.6,\n        \"num_unique_values\": 845,\n        \"samples\": [\n          41.68,\n          39.59,\n          2.33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the library for splitting the data\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Z_DmcoEPP-OP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = df.columns"
      ],
      "metadata": {
        "id": "1J39fpo0Rlam"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = df[column_names[column_names!='Strength']]\n",
        "target = df['Strength']"
      ],
      "metadata": {
        "id": "QWJXyaljRrwb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor_norm = predictor - predictor.mean()/predictor.std()\n",
        "predictor_norm.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dJ1CZugBbF5w",
        "outputId": "eac2f3af-f273-49f1-edf3-05529de04f06"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Cement  Blast Furnace Slag   Fly Ash       Water  Superplasticizer  \\\n",
              "0  537.309562           -0.856472 -0.846733  153.497358          1.461362   \n",
              "1  537.309562           -0.856472 -0.846733  153.497358          1.461362   \n",
              "2  329.809562          141.643528 -0.846733  219.497358         -1.038638   \n",
              "3  329.809562          141.643528 -0.846733  219.497358         -1.038638   \n",
              "4  195.909562          131.543528 -0.846733  183.497358         -1.038638   \n",
              "\n",
              "   Coarse Aggregate  Fine Aggregate         Age  \n",
              "0        1027.48721      666.351468   27.277154  \n",
              "1        1042.48721      666.351468   27.277154  \n",
              "2         919.48721      584.351468  269.277154  \n",
              "3         919.48721      584.351468  364.277154  \n",
              "4         965.88721      815.851468  359.277154  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-154a1521-af03-47d0-b3e7-2b8d6b33f549\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement</th>\n",
              "      <th>Blast Furnace Slag</th>\n",
              "      <th>Fly Ash</th>\n",
              "      <th>Water</th>\n",
              "      <th>Superplasticizer</th>\n",
              "      <th>Coarse Aggregate</th>\n",
              "      <th>Fine Aggregate</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>537.309562</td>\n",
              "      <td>-0.856472</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>153.497358</td>\n",
              "      <td>1.461362</td>\n",
              "      <td>1027.48721</td>\n",
              "      <td>666.351468</td>\n",
              "      <td>27.277154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>537.309562</td>\n",
              "      <td>-0.856472</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>153.497358</td>\n",
              "      <td>1.461362</td>\n",
              "      <td>1042.48721</td>\n",
              "      <td>666.351468</td>\n",
              "      <td>27.277154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>329.809562</td>\n",
              "      <td>141.643528</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>219.497358</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>919.48721</td>\n",
              "      <td>584.351468</td>\n",
              "      <td>269.277154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>329.809562</td>\n",
              "      <td>141.643528</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>219.497358</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>919.48721</td>\n",
              "      <td>584.351468</td>\n",
              "      <td>364.277154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>195.909562</td>\n",
              "      <td>131.543528</td>\n",
              "      <td>-0.846733</td>\n",
              "      <td>183.497358</td>\n",
              "      <td>-1.038638</td>\n",
              "      <td>965.88721</td>\n",
              "      <td>815.851468</td>\n",
              "      <td>359.277154</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-154a1521-af03-47d0-b3e7-2b8d6b33f549')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-154a1521-af03-47d0-b3e7-2b8d6b33f549 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-154a1521-af03-47d0-b3e7-2b8d6b33f549');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-66e3d7d9-8611-45d5-af14-ec23924cae26\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-66e3d7d9-8611-45d5-af14-ec23924cae26')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-66e3d7d9-8611-45d5-af14-ec23924cae26 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "predictor_norm",
              "summary": "{\n  \"name\": \"predictor_norm\",\n  \"rows\": 1030,\n  \"fields\": [\n    {\n      \"column\": \"Cement\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 104.50636449481549,\n        \"min\": 99.3095622889875,\n        \"max\": 537.3095622889875,\n        \"num_unique_values\": 278,\n        \"samples\": [\n          335.20956228898746,\n          287.50956228898747,\n          259.3095622889875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Blast Furnace Slag\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 86.27934174810541,\n        \"min\": -0.8564718244890995,\n        \"max\": 358.54352817551086,\n        \"num_unique_values\": 185,\n        \"samples\": [\n          93.8435281755109,\n          118.1435281755109,\n          135.44352817551092\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fly Ash\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63.997004152687005,\n        \"min\": -0.8467325968146431,\n        \"max\": 199.25326740318536,\n        \"num_unique_values\": 156,\n        \"samples\": [\n          97.15326740318535,\n          141.15326740318537,\n          194.15326740318537\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Water\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.35421856503253,\n        \"min\": 113.29735772346575,\n        \"max\": 238.49735772346574,\n        \"num_unique_values\": 195,\n        \"samples\": [\n          186.89735772346575,\n          175.29735772346575,\n          118.79735772346575\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Superplasticizer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.973841392485511,\n        \"min\": -1.0386382541022263,\n        \"max\": 31.161361745897775,\n        \"num_unique_values\": 111,\n        \"samples\": [\n          13.961361745897774,\n          27.16136174589777,\n          15.461361745897774\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Coarse Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 77.75395396672074,\n        \"min\": 788.4872095577898,\n        \"max\": 1132.4872095577898,\n        \"num_unique_values\": 284,\n        \"samples\": [\n          839.5872095577898,\n          901.3872095577898,\n          901.4872095577898\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fine Aggregate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80.17598014240454,\n        \"min\": 584.3514683068058,\n        \"max\": 982.9514683068059,\n        \"num_unique_values\": 302,\n        \"samples\": [\n          700.3514683068058,\n          685.7514683068058,\n          759.6514683068058\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 63.16991158103307,\n        \"min\": 0.2771537148068416,\n        \"max\": 364.27715371480684,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          90.27715371480684,\n          99.27715371480684,\n          27.277153714806843\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(predictor_norm, target, test_size=0.3)"
      ],
      "metadata": {
        "id": "ebOSamb-Qb-4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating the model\n",
        "def regression_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(10, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "  model.add(Dense(10, activation='relu'))\n",
        "  model.add(Dense(10, activation='relu'))\n",
        "  model.add(Dense(1))\n",
        "\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "  return model"
      ],
      "metadata": {
        "id": "Rd3VB3JmQ5Tr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Evaluation\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "VwLfN2MXXDqs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_list=[]"
      ],
      "metadata": {
        "id": "IsDm8oCIWH7v"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(50):\n",
        "  model = regression_model()\n",
        "  model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100, verbose=2)\n",
        "\n",
        "  y_pred = model.predict(x_test)\n",
        "  mse = mean_squared_error(y_test, y_pred)\n",
        "  mse_list.append(mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqU3NIJ_YZP8",
        "outputId": "3158ba5b-2ca8-4aab-ca6f-14fe315b6141"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "23/23 - 2s - 101ms/step - loss: 10192.7041 - val_loss: 4257.6650\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 5ms/step - loss: 1949.4924 - val_loss: 568.9017\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 5ms/step - loss: 390.4113 - val_loss: 292.7914\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 7ms/step - loss: 293.8714 - val_loss: 279.6465\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 13ms/step - loss: 283.5892 - val_loss: 273.7753\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 7ms/step - loss: 278.9595 - val_loss: 270.9781\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 7ms/step - loss: 274.8074 - val_loss: 264.6072\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 8ms/step - loss: 273.7788 - val_loss: 263.5361\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 12ms/step - loss: 266.6390 - val_loss: 259.4191\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 8ms/step - loss: 259.9579 - val_loss: 249.7547\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 12ms/step - loss: 255.4494 - val_loss: 246.3288\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 8ms/step - loss: 250.6493 - val_loss: 244.1248\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 7ms/step - loss: 246.8295 - val_loss: 237.7982\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 15ms/step - loss: 243.1991 - val_loss: 236.0022\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 14ms/step - loss: 236.4466 - val_loss: 231.8515\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 20ms/step - loss: 229.3537 - val_loss: 222.4062\n",
            "Epoch 17/100\n",
            "23/23 - 1s - 23ms/step - loss: 223.3494 - val_loss: 219.4172\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 19ms/step - loss: 212.1487 - val_loss: 213.1575\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 21ms/step - loss: 199.5305 - val_loss: 195.4892\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 17ms/step - loss: 187.8353 - val_loss: 185.7036\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 180.6005 - val_loss: 189.6417\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 172.7758 - val_loss: 174.1737\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 171.4274 - val_loss: 163.9969\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 157.9877 - val_loss: 171.4508\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.2193 - val_loss: 157.5605\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 143.9241 - val_loss: 147.9579\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.5123 - val_loss: 143.0846\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 132.9810 - val_loss: 139.2548\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 128.6038 - val_loss: 134.5947\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 3ms/step - loss: 124.4092 - val_loss: 147.1235\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 119.8892 - val_loss: 125.2598\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.7031 - val_loss: 121.4031\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.1003 - val_loss: 119.7727\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.4863 - val_loss: 115.4374\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 106.9719 - val_loss: 118.1981\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 5ms/step - loss: 102.8452 - val_loss: 117.2477\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 103.0383 - val_loss: 108.7546\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 99.6653 - val_loss: 111.4258\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 3ms/step - loss: 99.2685 - val_loss: 112.3605\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 97.4959 - val_loss: 104.5331\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 3ms/step - loss: 95.7414 - val_loss: 103.0907\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 3ms/step - loss: 94.5288 - val_loss: 106.3397\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 94.0476 - val_loss: 101.6265\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 95.3923 - val_loss: 106.3892\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 92.3078 - val_loss: 99.6386\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 91.7021 - val_loss: 99.4121\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 91.4907 - val_loss: 105.3223\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 3ms/step - loss: 90.3011 - val_loss: 99.8693\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 91.9100 - val_loss: 98.5640\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 94.5189 - val_loss: 102.9129\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 90.8645 - val_loss: 98.5688\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 89.0237 - val_loss: 96.7586\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 86.7427 - val_loss: 98.4279\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 91.2083 - val_loss: 96.2269\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 88.9331 - val_loss: 95.8081\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 86.8141 - val_loss: 95.9607\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.7372 - val_loss: 95.2265\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.7775 - val_loss: 96.0878\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.4214 - val_loss: 96.0300\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 88.8655 - val_loss: 93.6471\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.9324 - val_loss: 96.0800\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 83.9261 - val_loss: 93.5178\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 83.4076 - val_loss: 93.0285\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 85.1737 - val_loss: 92.8051\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.9309 - val_loss: 94.1822\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.1946 - val_loss: 94.0070\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.7011 - val_loss: 94.4317\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 83.8856 - val_loss: 94.4455\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 86.1654 - val_loss: 94.6247\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.3969 - val_loss: 90.7436\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 81.4478 - val_loss: 91.3240\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.0642 - val_loss: 90.9828\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.3280 - val_loss: 91.6996\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.2001 - val_loss: 89.7336\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.8298 - val_loss: 90.6263\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.3132 - val_loss: 92.7693\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.1258 - val_loss: 89.3644\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.0589 - val_loss: 95.1034\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 82.5079 - val_loss: 89.8760\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.6978 - val_loss: 88.4669\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 81.7744 - val_loss: 88.4312\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 79.8347 - val_loss: 88.6743\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.4143 - val_loss: 88.8437\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.3234 - val_loss: 89.6593\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 79.3894 - val_loss: 102.5158\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.1834 - val_loss: 87.3953\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 7ms/step - loss: 78.6705 - val_loss: 87.3317\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 5ms/step - loss: 79.0640 - val_loss: 87.4479\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 79.0452 - val_loss: 89.1107\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.3841 - val_loss: 87.3451\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.3628 - val_loss: 87.4794\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 78.5056 - val_loss: 87.0704\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.0280 - val_loss: 87.0017\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.3436 - val_loss: 92.1701\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.0007 - val_loss: 89.2719\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 5ms/step - loss: 83.4446 - val_loss: 96.7088\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 8ms/step - loss: 81.2672 - val_loss: 86.0866\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 10ms/step - loss: 79.3048 - val_loss: 96.8324\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 12ms/step - loss: 80.7695 - val_loss: 91.6511\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 8ms/step - loss: 77.7059 - val_loss: 87.7515\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 101ms/step - loss: 11727.6562 - val_loss: 3251.6670\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 1672.9955 - val_loss: 676.7430\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 15ms/step - loss: 552.4590 - val_loss: 396.9626\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 8ms/step - loss: 399.9735 - val_loss: 353.1480\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 15ms/step - loss: 372.0257 - val_loss: 343.8184\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 8ms/step - loss: 362.6910 - val_loss: 341.5641\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 13ms/step - loss: 359.0161 - val_loss: 339.9453\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 12ms/step - loss: 356.1935 - val_loss: 338.2438\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 13ms/step - loss: 353.7234 - val_loss: 336.3930\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 351.4236 - val_loss: 333.8448\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 13ms/step - loss: 349.3003 - val_loss: 332.5082\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 345.8080 - val_loss: 329.3291\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 343.3883 - val_loss: 326.6693\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 19ms/step - loss: 340.6887 - val_loss: 324.8922\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 337.8248 - val_loss: 322.0475\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 13ms/step - loss: 335.4218 - val_loss: 319.3425\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 13ms/step - loss: 332.5709 - val_loss: 317.2869\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 329.9048 - val_loss: 315.1626\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 327.4214 - val_loss: 313.4048\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 13ms/step - loss: 325.0815 - val_loss: 310.2683\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 322.4229 - val_loss: 308.1339\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 13ms/step - loss: 319.6813 - val_loss: 306.7969\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 16ms/step - loss: 317.3980 - val_loss: 304.3163\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 314.9525 - val_loss: 302.1589\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 13ms/step - loss: 312.7913 - val_loss: 299.2312\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 309.8932 - val_loss: 297.4549\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 307.5049 - val_loss: 295.4803\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 305.1235 - val_loss: 292.8344\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 302.8467 - val_loss: 290.3409\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 299.9714 - val_loss: 289.1090\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 8ms/step - loss: 297.1853 - val_loss: 286.4187\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 11ms/step - loss: 292.4547 - val_loss: 279.6626\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 277.7080 - val_loss: 261.3588\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 261.2337 - val_loss: 248.9665\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 18ms/step - loss: 247.4890 - val_loss: 238.8876\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 8ms/step - loss: 235.4199 - val_loss: 229.4937\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 224.0498 - val_loss: 222.3830\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 7ms/step - loss: 214.8867 - val_loss: 214.9614\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 5ms/step - loss: 207.6139 - val_loss: 208.3329\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 10ms/step - loss: 200.8075 - val_loss: 202.7677\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 11ms/step - loss: 195.1383 - val_loss: 199.3574\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 12ms/step - loss: 189.9693 - val_loss: 193.4704\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 184.7859 - val_loss: 188.4532\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 178.9902 - val_loss: 185.4024\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 174.6537 - val_loss: 180.7902\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 172.0703 - val_loss: 177.5938\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.3112 - val_loss: 173.8676\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.7538 - val_loss: 169.3351\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 13ms/step - loss: 158.0250 - val_loss: 166.5948\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.9841 - val_loss: 164.7050\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 7ms/step - loss: 150.6001 - val_loss: 158.1765\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.0409 - val_loss: 155.2000\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 13ms/step - loss: 143.7083 - val_loss: 151.8120\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 141.0523 - val_loss: 151.0270\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 12ms/step - loss: 137.6078 - val_loss: 146.6129\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 7ms/step - loss: 135.1501 - val_loss: 143.8707\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 10ms/step - loss: 132.1607 - val_loss: 142.3269\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 13ms/step - loss: 129.0222 - val_loss: 139.3443\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 10ms/step - loss: 125.8754 - val_loss: 136.5404\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 8ms/step - loss: 123.8317 - val_loss: 136.4866\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 9ms/step - loss: 121.7324 - val_loss: 132.2096\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 7ms/step - loss: 119.5137 - val_loss: 129.9940\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 16ms/step - loss: 116.4051 - val_loss: 127.9230\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.3742 - val_loss: 126.3126\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 15ms/step - loss: 113.4414 - val_loss: 124.1888\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 7ms/step - loss: 110.7894 - val_loss: 121.6507\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 16ms/step - loss: 108.1987 - val_loss: 120.4303\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 9ms/step - loss: 106.5258 - val_loss: 117.7701\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 14ms/step - loss: 105.1150 - val_loss: 116.4013\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 11ms/step - loss: 103.7976 - val_loss: 116.1768\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 101.9889 - val_loss: 113.4901\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 99.7729 - val_loss: 112.4327\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 99.3999 - val_loss: 109.6499\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 7ms/step - loss: 97.3279 - val_loss: 108.9789\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 97.8097 - val_loss: 110.6155\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 5ms/step - loss: 97.9311 - val_loss: 106.7714\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 94.5219 - val_loss: 105.1301\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 5ms/step - loss: 93.7030 - val_loss: 105.3131\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 92.3998 - val_loss: 103.7842\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 92.3723 - val_loss: 102.8484\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 90.8079 - val_loss: 102.7250\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 91.2826 - val_loss: 102.9640\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 89.6359 - val_loss: 103.6641\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 5ms/step - loss: 89.4672 - val_loss: 100.7517\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 5ms/step - loss: 88.4003 - val_loss: 100.3270\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 87.2165 - val_loss: 99.4961\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 5ms/step - loss: 89.6346 - val_loss: 101.5821\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 87.6218 - val_loss: 96.9763\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 5ms/step - loss: 86.7199 - val_loss: 96.4640\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 85.7629 - val_loss: 95.2767\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.4595 - val_loss: 96.3653\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.6928 - val_loss: 94.2888\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 5ms/step - loss: 84.7272 - val_loss: 94.0498\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 7ms/step - loss: 84.3850 - val_loss: 93.6278\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 83.5848 - val_loss: 91.9868\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 5ms/step - loss: 83.1330 - val_loss: 92.5488\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 5ms/step - loss: 82.9048 - val_loss: 92.1889\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.5390 - val_loss: 90.4745\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 5ms/step - loss: 82.9156 - val_loss: 91.6520\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 5ms/step - loss: 82.0801 - val_loss: 89.9550\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 71ms/step - loss: 592.1351 - val_loss: 286.1942\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 6ms/step - loss: 239.1412 - val_loss: 230.6600\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 225.1252 - val_loss: 226.7515\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 5ms/step - loss: 221.0286 - val_loss: 218.9825\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 5ms/step - loss: 213.5024 - val_loss: 214.5584\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 5ms/step - loss: 206.5640 - val_loss: 207.6208\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 198.5755 - val_loss: 200.2054\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 191.1528 - val_loss: 196.2255\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 8ms/step - loss: 184.4762 - val_loss: 187.8386\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 5ms/step - loss: 176.9802 - val_loss: 182.2038\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 170.3579 - val_loss: 178.0313\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 163.8854 - val_loss: 170.9926\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.6010 - val_loss: 168.6767\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 151.1618 - val_loss: 160.8414\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 143.0741 - val_loss: 153.1641\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 136.1955 - val_loss: 145.8367\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 5ms/step - loss: 129.4294 - val_loss: 138.6697\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 5ms/step - loss: 120.0241 - val_loss: 127.8850\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.6066 - val_loss: 120.8659\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.4644 - val_loss: 115.7838\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 101.7790 - val_loss: 108.8138\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 97.6891 - val_loss: 104.7365\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 5ms/step - loss: 93.6321 - val_loss: 102.7922\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 92.3351 - val_loss: 102.3591\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 3ms/step - loss: 89.5727 - val_loss: 98.2839\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 7ms/step - loss: 87.6990 - val_loss: 102.7755\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 5ms/step - loss: 87.3283 - val_loss: 97.1365\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 86.9744 - val_loss: 94.7213\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.4092 - val_loss: 92.7656\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 84.4223 - val_loss: 91.7527\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 84.1302 - val_loss: 90.8722\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.8306 - val_loss: 90.6055\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 8ms/step - loss: 81.8438 - val_loss: 89.8046\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 13ms/step - loss: 81.8062 - val_loss: 90.2066\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.2748 - val_loss: 89.1234\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.0732 - val_loss: 91.1655\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.7371 - val_loss: 90.9056\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.2065 - val_loss: 89.7095\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 7ms/step - loss: 78.4860 - val_loss: 87.4718\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.3532 - val_loss: 87.0531\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.0864 - val_loss: 87.0355\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.5090 - val_loss: 89.7654\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.2211 - val_loss: 87.3226\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 5ms/step - loss: 77.7905 - val_loss: 84.5212\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.4267 - val_loss: 85.3619\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 14ms/step - loss: 75.9746 - val_loss: 85.5461\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 12ms/step - loss: 75.5056 - val_loss: 84.4335\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.7377 - val_loss: 86.8783\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 75.1793 - val_loss: 83.6826\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.1749 - val_loss: 82.9321\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 5ms/step - loss: 76.3904 - val_loss: 90.9089\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.6250 - val_loss: 82.3593\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 74.4448 - val_loss: 83.8726\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.3049 - val_loss: 81.3154\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 72.8960 - val_loss: 81.3524\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 72.3407 - val_loss: 83.2644\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 72.0540 - val_loss: 80.8976\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 7ms/step - loss: 71.7707 - val_loss: 84.8449\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.5594 - val_loss: 81.8860\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.9252 - val_loss: 79.9348\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.6984 - val_loss: 79.4047\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 72.3910 - val_loss: 81.9587\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.5766 - val_loss: 78.7896\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.0076 - val_loss: 79.9745\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.2342 - val_loss: 84.9689\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.0773 - val_loss: 78.6025\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 69.3238 - val_loss: 77.2290\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 5ms/step - loss: 68.4186 - val_loss: 77.2498\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 3ms/step - loss: 69.2487 - val_loss: 76.7066\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 7ms/step - loss: 68.1651 - val_loss: 79.5656\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.2980 - val_loss: 76.5409\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.6873 - val_loss: 75.7980\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.4737 - val_loss: 75.7109\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 7ms/step - loss: 67.2161 - val_loss: 75.6829\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.0560 - val_loss: 74.9892\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 7ms/step - loss: 67.5384 - val_loss: 74.5778\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 66.7604 - val_loss: 76.9056\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 66.7214 - val_loss: 74.1209\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 65.9337 - val_loss: 74.1248\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 65.4671 - val_loss: 72.9475\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 65.7149 - val_loss: 73.1100\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 65.2812 - val_loss: 73.1489\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 65.1383 - val_loss: 72.8016\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 65.2829 - val_loss: 72.8678\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 64.6828 - val_loss: 71.2946\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 64.9993 - val_loss: 71.2744\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 3ms/step - loss: 66.2274 - val_loss: 71.8498\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 65.8315 - val_loss: 72.2502\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 65.5432 - val_loss: 71.2898\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 63.7757 - val_loss: 70.6531\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 7ms/step - loss: 63.6605 - val_loss: 71.5464\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 64.8019 - val_loss: 72.3584\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 3ms/step - loss: 64.5369 - val_loss: 70.3705\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 63.5147 - val_loss: 69.4230\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 62.6615 - val_loss: 70.0348\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 62.7964 - val_loss: 70.1707\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 3ms/step - loss: 62.3920 - val_loss: 69.1619\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 63.0125 - val_loss: 69.0774\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 7ms/step - loss: 62.5853 - val_loss: 69.4758\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 61.2304 - val_loss: 68.5952\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 55ms/step - loss: 639.6617 - val_loss: 352.6009\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 319.5344 - val_loss: 319.1131\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 300.7475 - val_loss: 297.8802\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 287.1978 - val_loss: 285.7191\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 273.7976 - val_loss: 274.2988\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 261.9771 - val_loss: 263.2437\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 251.3267 - val_loss: 256.7475\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 3ms/step - loss: 239.6059 - val_loss: 239.5529\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 227.7562 - val_loss: 233.6199\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 219.7387 - val_loss: 226.5592\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 7ms/step - loss: 211.9082 - val_loss: 218.8022\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 205.5698 - val_loss: 213.1993\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 197.6906 - val_loss: 207.3047\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 191.9837 - val_loss: 201.2452\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 3ms/step - loss: 186.2066 - val_loss: 196.8459\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 7ms/step - loss: 181.8329 - val_loss: 191.7103\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 7ms/step - loss: 175.1478 - val_loss: 186.6521\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 12ms/step - loss: 171.0558 - val_loss: 183.8312\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 5ms/step - loss: 167.1828 - val_loss: 179.4096\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.0277 - val_loss: 173.7168\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 5ms/step - loss: 157.8421 - val_loss: 169.4086\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 7ms/step - loss: 153.0384 - val_loss: 165.9013\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 12ms/step - loss: 149.2397 - val_loss: 167.2381\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 13ms/step - loss: 143.4772 - val_loss: 155.3727\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 139.2979 - val_loss: 146.7139\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 127.8091 - val_loss: 131.7095\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 14ms/step - loss: 118.6870 - val_loss: 119.6703\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 13ms/step - loss: 111.8307 - val_loss: 113.6992\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 11ms/step - loss: 107.4850 - val_loss: 113.3381\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 104.8696 - val_loss: 110.8400\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 103.0759 - val_loss: 111.9261\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 101.3067 - val_loss: 108.7497\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 7ms/step - loss: 100.6357 - val_loss: 106.2882\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 5ms/step - loss: 99.9412 - val_loss: 107.0592\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 7ms/step - loss: 99.1855 - val_loss: 104.8773\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 96.1228 - val_loss: 103.6667\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 7ms/step - loss: 95.7727 - val_loss: 102.8468\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 93.5191 - val_loss: 102.2941\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 5ms/step - loss: 92.9891 - val_loss: 101.3407\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 7ms/step - loss: 97.5155 - val_loss: 100.8376\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 5ms/step - loss: 90.8457 - val_loss: 98.5482\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 7ms/step - loss: 89.7905 - val_loss: 102.0827\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 90.8197 - val_loss: 103.9044\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 89.4537 - val_loss: 98.7288\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 3ms/step - loss: 86.5885 - val_loss: 96.1107\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 3ms/step - loss: 85.8306 - val_loss: 94.7584\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 85.8556 - val_loss: 94.6286\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 3ms/step - loss: 88.8969 - val_loss: 98.8717\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 85.2454 - val_loss: 92.6428\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 84.5654 - val_loss: 94.9395\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 85.0165 - val_loss: 96.6824\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.1838 - val_loss: 95.0309\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 81.1305 - val_loss: 88.7911\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.8770 - val_loss: 88.0128\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.8726 - val_loss: 87.2812\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 78.0614 - val_loss: 86.1045\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 3ms/step - loss: 75.7123 - val_loss: 89.4614\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.2945 - val_loss: 84.4801\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.1394 - val_loss: 86.0327\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.7185 - val_loss: 83.6219\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.7076 - val_loss: 83.0355\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 7ms/step - loss: 73.1611 - val_loss: 82.0783\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 71.9756 - val_loss: 81.6016\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 5ms/step - loss: 71.0116 - val_loss: 80.9695\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 5ms/step - loss: 71.1354 - val_loss: 79.6832\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 70.2072 - val_loss: 80.6152\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 3ms/step - loss: 69.5151 - val_loss: 78.6577\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 69.6817 - val_loss: 78.4163\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 7ms/step - loss: 71.5642 - val_loss: 78.7065\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 5ms/step - loss: 68.7079 - val_loss: 77.3692\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.0179 - val_loss: 76.5943\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 3ms/step - loss: 67.5181 - val_loss: 76.3604\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 67.5996 - val_loss: 79.5240\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 7ms/step - loss: 68.6933 - val_loss: 75.7444\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 65.9702 - val_loss: 75.0580\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 66.4178 - val_loss: 79.5588\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.0076 - val_loss: 76.5080\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.7744 - val_loss: 77.1353\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 65.3039 - val_loss: 74.3434\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 3ms/step - loss: 66.1984 - val_loss: 79.8866\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 7ms/step - loss: 64.6329 - val_loss: 73.4773\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 64.1007 - val_loss: 72.7048\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 63.6163 - val_loss: 75.3880\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 3ms/step - loss: 64.9815 - val_loss: 71.8382\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 62.9504 - val_loss: 74.0789\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 65.1110 - val_loss: 71.7939\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 62.2805 - val_loss: 71.6789\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 62.6881 - val_loss: 77.3013\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 63.4258 - val_loss: 70.7307\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 7ms/step - loss: 63.2439 - val_loss: 70.4732\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 64.8795 - val_loss: 79.5576\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 5ms/step - loss: 68.7457 - val_loss: 70.7109\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 5ms/step - loss: 63.2182 - val_loss: 72.9804\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 62.0133 - val_loss: 70.7742\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 3ms/step - loss: 61.4567 - val_loss: 69.4355\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 61.3701 - val_loss: 70.0978\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 3ms/step - loss: 60.3541 - val_loss: 69.5581\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 7ms/step - loss: 60.4751 - val_loss: 69.3016\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 5ms/step - loss: 60.4821 - val_loss: 68.9219\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 60.8102 - val_loss: 68.2886\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 67ms/step - loss: 465.1542 - val_loss: 392.5014\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 18ms/step - loss: 316.6174 - val_loss: 295.9100\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 278.0424 - val_loss: 282.9952\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 7ms/step - loss: 252.2275 - val_loss: 242.1144\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 223.1728 - val_loss: 205.4064\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 186.4353 - val_loss: 165.6904\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 9ms/step - loss: 161.9081 - val_loss: 148.9556\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 10ms/step - loss: 145.7568 - val_loss: 136.5022\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 13ms/step - loss: 135.5813 - val_loss: 130.4597\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 5ms/step - loss: 126.0320 - val_loss: 122.8972\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 5ms/step - loss: 120.3888 - val_loss: 117.4864\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.0147 - val_loss: 114.1263\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 115.7313 - val_loss: 113.6954\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.6984 - val_loss: 109.2190\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 108.9822 - val_loss: 108.3998\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.3209 - val_loss: 106.0157\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 104.3019 - val_loss: 104.5259\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.3979 - val_loss: 103.9245\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 102.9457 - val_loss: 104.6530\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 101.5289 - val_loss: 100.7810\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 7ms/step - loss: 99.7568 - val_loss: 101.1385\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 11ms/step - loss: 97.5268 - val_loss: 101.5308\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 5ms/step - loss: 97.0407 - val_loss: 97.7582\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 96.4859 - val_loss: 98.1554\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 94.3292 - val_loss: 99.2400\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 95.3861 - val_loss: 99.8542\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 97.0401 - val_loss: 97.9419\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 94.2388 - val_loss: 92.9276\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 93.9129 - val_loss: 92.9987\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 89.7505 - val_loss: 91.1452\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 87.7858 - val_loss: 91.0615\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 87.5496 - val_loss: 91.3380\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 87.2835 - val_loss: 89.0064\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 7ms/step - loss: 85.5924 - val_loss: 87.9539\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 86.4577 - val_loss: 89.7692\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 5ms/step - loss: 83.3214 - val_loss: 90.2669\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 3ms/step - loss: 84.4106 - val_loss: 91.0613\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.4970 - val_loss: 85.1302\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.2860 - val_loss: 86.2326\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.9115 - val_loss: 83.8848\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.2612 - val_loss: 83.7368\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.7423 - val_loss: 83.8097\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 5ms/step - loss: 78.5735 - val_loss: 82.0134\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.3571 - val_loss: 80.9755\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.4623 - val_loss: 81.0096\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 78.9941 - val_loss: 80.0605\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.9034 - val_loss: 82.8657\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.5738 - val_loss: 79.6016\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 7ms/step - loss: 73.0898 - val_loss: 78.2083\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 72.6990 - val_loss: 77.5081\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.2686 - val_loss: 77.7625\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 7ms/step - loss: 75.4303 - val_loss: 81.0273\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.6033 - val_loss: 76.2414\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 71.7580 - val_loss: 76.7663\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 71.8389 - val_loss: 76.6846\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 5ms/step - loss: 70.7065 - val_loss: 74.6858\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.0601 - val_loss: 75.0408\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 69.5031 - val_loss: 74.3473\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 69.0022 - val_loss: 73.8998\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 67.9611 - val_loss: 74.1522\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.4397 - val_loss: 74.1328\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 67.3087 - val_loss: 81.3691\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.7598 - val_loss: 75.3348\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 68.4491 - val_loss: 72.8142\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 3ms/step - loss: 66.9291 - val_loss: 71.9295\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 66.8739 - val_loss: 74.8210\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 7ms/step - loss: 67.0475 - val_loss: 73.0258\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 5ms/step - loss: 66.2821 - val_loss: 70.9024\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 66.7325 - val_loss: 71.1648\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.2750 - val_loss: 70.4193\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 5ms/step - loss: 65.8514 - val_loss: 70.1209\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 64.7196 - val_loss: 72.8422\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 66.7065 - val_loss: 70.8327\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 64.3386 - val_loss: 69.2249\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 63.7757 - val_loss: 69.2484\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 5ms/step - loss: 64.6272 - val_loss: 73.1116\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 67.0939 - val_loss: 68.5966\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 3ms/step - loss: 63.5822 - val_loss: 70.5545\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 63.6065 - val_loss: 67.8544\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 62.6444 - val_loss: 67.0410\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 7ms/step - loss: 63.8004 - val_loss: 66.8452\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 61.5014 - val_loss: 70.1167\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 5ms/step - loss: 61.9995 - val_loss: 66.0339\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 62.1979 - val_loss: 66.3751\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 62.3007 - val_loss: 68.4043\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 5ms/step - loss: 62.3519 - val_loss: 64.9202\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 7ms/step - loss: 59.3463 - val_loss: 69.2954\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 7ms/step - loss: 59.4964 - val_loss: 68.0904\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 60.8784 - val_loss: 63.5996\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 7ms/step - loss: 59.8094 - val_loss: 65.4852\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 13ms/step - loss: 62.0783 - val_loss: 68.4025\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 59.0109 - val_loss: 64.1624\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 57.3518 - val_loss: 62.0962\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 58.0668 - val_loss: 61.8168\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 57.4695 - val_loss: 62.5815\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 7ms/step - loss: 59.2178 - val_loss: 63.2887\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 56.0322 - val_loss: 61.0004\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 13ms/step - loss: 55.3593 - val_loss: 60.5779\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 54.4630 - val_loss: 60.3779\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 54.8368 - val_loss: 59.8879\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 59ms/step - loss: 88542.5703 - val_loss: 33406.8984\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 14219.2734 - val_loss: 2684.5642\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 893.5196 - val_loss: 454.4967\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 379.8995 - val_loss: 319.1273\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 303.6410 - val_loss: 311.0964\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 297.4731 - val_loss: 304.6296\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 291.1078 - val_loss: 298.2019\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 282.3417 - val_loss: 290.3594\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 275.0104 - val_loss: 282.4981\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 268.1390 - val_loss: 275.4707\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 263.2367 - val_loss: 272.1068\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 7ms/step - loss: 261.1807 - val_loss: 266.6474\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 7ms/step - loss: 257.4865 - val_loss: 262.8340\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 5ms/step - loss: 253.5240 - val_loss: 260.0170\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 7ms/step - loss: 252.7200 - val_loss: 255.7044\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 245.5879 - val_loss: 252.8449\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 243.6138 - val_loss: 249.5779\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 240.7295 - val_loss: 245.3944\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 236.9001 - val_loss: 243.1668\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 234.2046 - val_loss: 239.2713\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 3ms/step - loss: 231.4795 - val_loss: 236.3687\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 7ms/step - loss: 229.1589 - val_loss: 235.2690\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 227.3059 - val_loss: 233.0433\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 5ms/step - loss: 223.6507 - val_loss: 228.6821\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 220.9823 - val_loss: 228.1554\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 219.6348 - val_loss: 223.8105\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 5ms/step - loss: 216.4723 - val_loss: 222.9721\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 7ms/step - loss: 214.6154 - val_loss: 218.4874\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 214.6432 - val_loss: 217.2433\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 3ms/step - loss: 210.3736 - val_loss: 215.9121\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 7ms/step - loss: 207.5633 - val_loss: 211.6130\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 206.5084 - val_loss: 209.7340\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 204.8104 - val_loss: 208.1070\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 202.4903 - val_loss: 205.5898\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 7ms/step - loss: 201.1646 - val_loss: 203.4696\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 198.6411 - val_loss: 203.3360\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 196.3794 - val_loss: 199.7389\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 196.4157 - val_loss: 198.3218\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 194.6710 - val_loss: 196.1028\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 191.2358 - val_loss: 196.1938\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 7ms/step - loss: 190.6118 - val_loss: 193.0317\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 5ms/step - loss: 188.5158 - val_loss: 190.5779\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 3ms/step - loss: 191.4364 - val_loss: 196.7982\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 184.8016 - val_loss: 188.1353\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 7ms/step - loss: 186.1916 - val_loss: 185.4281\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 184.3111 - val_loss: 184.1810\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 182.8589 - val_loss: 183.8322\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 178.5652 - val_loss: 181.9490\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.1830 - val_loss: 179.5619\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 174.5022 - val_loss: 177.6480\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 7ms/step - loss: 173.9636 - val_loss: 175.7729\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 7ms/step - loss: 172.4274 - val_loss: 180.3913\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 170.7104 - val_loss: 173.5494\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 5ms/step - loss: 167.4287 - val_loss: 171.6276\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 7ms/step - loss: 169.5798 - val_loss: 170.2957\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 167.8475 - val_loss: 175.3296\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 164.6089 - val_loss: 170.4398\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.0014 - val_loss: 166.2654\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 159.3281 - val_loss: 165.2919\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 5ms/step - loss: 158.6539 - val_loss: 162.1845\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 159.0180 - val_loss: 159.9484\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 154.9887 - val_loss: 158.9635\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 155.5309 - val_loss: 158.1397\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 154.0693 - val_loss: 155.3794\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.7453 - val_loss: 164.9011\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 151.7651 - val_loss: 155.0876\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 147.9771 - val_loss: 150.7376\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 146.0558 - val_loss: 150.0081\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 7ms/step - loss: 143.8544 - val_loss: 148.0059\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 143.6367 - val_loss: 147.0578\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 140.9256 - val_loss: 145.6793\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 19ms/step - loss: 139.5885 - val_loss: 144.3153\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 8ms/step - loss: 138.3964 - val_loss: 146.3822\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 139.9868 - val_loss: 150.1285\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 139.2135 - val_loss: 152.1647\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 136.7612 - val_loss: 140.9649\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 5ms/step - loss: 135.3519 - val_loss: 139.4939\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 133.9485 - val_loss: 139.2233\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 7ms/step - loss: 130.8967 - val_loss: 137.0683\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 130.8229 - val_loss: 135.9018\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 7ms/step - loss: 130.1048 - val_loss: 134.5162\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 12ms/step - loss: 127.9272 - val_loss: 139.7042\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 127.6878 - val_loss: 132.5260\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 15ms/step - loss: 127.7409 - val_loss: 134.7414\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 11ms/step - loss: 125.8274 - val_loss: 135.7473\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 11ms/step - loss: 125.4520 - val_loss: 134.9820\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 124.3227 - val_loss: 134.9384\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 123.2912 - val_loss: 129.2996\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 3ms/step - loss: 122.0601 - val_loss: 129.2024\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.4118 - val_loss: 131.5838\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 7ms/step - loss: 121.8025 - val_loss: 126.1848\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 5ms/step - loss: 122.3538 - val_loss: 125.9294\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 122.2582 - val_loss: 135.7085\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 121.8542 - val_loss: 124.8625\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.3761 - val_loss: 124.9015\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.9412 - val_loss: 122.9670\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.5162 - val_loss: 125.3123\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.7502 - val_loss: 124.5125\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 7ms/step - loss: 116.7211 - val_loss: 121.9004\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.0255 - val_loss: 121.3083\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 57ms/step - loss: 945.2615 - val_loss: 647.5494\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 557.6580 - val_loss: 496.3646\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 468.0542 - val_loss: 456.6883\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 424.7711 - val_loss: 418.3635\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 398.0163 - val_loss: 382.9766\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 374.5712 - val_loss: 363.0859\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 358.1683 - val_loss: 343.6980\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 341.6043 - val_loss: 333.3585\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 326.9812 - val_loss: 329.1994\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 315.4879 - val_loss: 304.3729\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 7ms/step - loss: 305.0224 - val_loss: 294.9277\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 301.4368 - val_loss: 284.1977\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 290.4199 - val_loss: 324.9547\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 280.2369 - val_loss: 272.6685\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 3ms/step - loss: 272.0312 - val_loss: 260.3892\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 262.4856 - val_loss: 262.0834\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 3ms/step - loss: 257.3033 - val_loss: 262.2505\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 7ms/step - loss: 251.3366 - val_loss: 254.3582\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 246.4300 - val_loss: 237.0647\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 5ms/step - loss: 236.1798 - val_loss: 227.8233\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 233.8837 - val_loss: 220.6386\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 224.6187 - val_loss: 213.9136\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 219.9876 - val_loss: 206.5384\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 210.3191 - val_loss: 205.6853\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 3ms/step - loss: 201.0884 - val_loss: 191.2571\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 5ms/step - loss: 194.1527 - val_loss: 182.9904\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 7ms/step - loss: 191.0525 - val_loss: 179.5141\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 185.7409 - val_loss: 177.0770\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 181.0974 - val_loss: 168.3295\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 7ms/step - loss: 172.6236 - val_loss: 164.8176\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 165.6571 - val_loss: 155.0939\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 157.9733 - val_loss: 149.4429\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 153.0597 - val_loss: 139.3084\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 143.7337 - val_loss: 134.6340\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 7ms/step - loss: 135.9650 - val_loss: 131.6146\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 130.9096 - val_loss: 126.3360\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 129.8102 - val_loss: 142.6926\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 127.5705 - val_loss: 120.5867\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.3845 - val_loss: 124.1652\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 7ms/step - loss: 119.8737 - val_loss: 115.7775\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.9905 - val_loss: 113.9888\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 7ms/step - loss: 115.2841 - val_loss: 133.6427\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 5ms/step - loss: 118.0042 - val_loss: 112.4628\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.3662 - val_loss: 118.0906\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.9259 - val_loss: 110.5550\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 7ms/step - loss: 108.0424 - val_loss: 110.0823\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 5ms/step - loss: 106.8038 - val_loss: 107.0854\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 3ms/step - loss: 106.5346 - val_loss: 106.4852\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 103.8415 - val_loss: 111.4855\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 106.6636 - val_loss: 106.2424\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 5ms/step - loss: 101.7096 - val_loss: 107.3356\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 7ms/step - loss: 99.6245 - val_loss: 102.7960\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 98.4864 - val_loss: 101.5723\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 98.0013 - val_loss: 105.5503\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 98.4457 - val_loss: 101.4566\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 5ms/step - loss: 100.6044 - val_loss: 103.6585\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 104.7850 - val_loss: 109.8180\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 8ms/step - loss: 102.1632 - val_loss: 101.2812\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 11ms/step - loss: 93.6418 - val_loss: 97.4374\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 91.7880 - val_loss: 96.5039\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 7ms/step - loss: 91.6022 - val_loss: 104.7143\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 14ms/step - loss: 89.6087 - val_loss: 97.7210\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 11ms/step - loss: 92.6226 - val_loss: 102.0695\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 94.0648 - val_loss: 95.3984\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 13ms/step - loss: 87.8629 - val_loss: 97.4205\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 5ms/step - loss: 88.1113 - val_loss: 93.3522\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 86.0211 - val_loss: 94.7780\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 84.4328 - val_loss: 94.9731\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 7ms/step - loss: 87.3512 - val_loss: 92.0814\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 5ms/step - loss: 87.0737 - val_loss: 92.0796\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 83.5771 - val_loss: 90.8319\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.2194 - val_loss: 89.9861\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.9108 - val_loss: 91.5767\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 81.7000 - val_loss: 91.3070\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.9256 - val_loss: 89.6451\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.8049 - val_loss: 88.1094\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.9720 - val_loss: 87.6958\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 7ms/step - loss: 79.3646 - val_loss: 90.3497\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 78.2605 - val_loss: 88.3146\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.1850 - val_loss: 102.7300\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.7147 - val_loss: 86.4565\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.8188 - val_loss: 91.4196\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 77.3754 - val_loss: 87.8091\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 5ms/step - loss: 78.3765 - val_loss: 84.5977\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.0703 - val_loss: 85.7464\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 5ms/step - loss: 75.4173 - val_loss: 84.3072\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 3ms/step - loss: 76.3008 - val_loss: 83.8002\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.4715 - val_loss: 85.5264\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.0264 - val_loss: 86.0094\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 3ms/step - loss: 75.6720 - val_loss: 84.2657\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 74.8266 - val_loss: 88.8058\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.3158 - val_loss: 82.4383\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 5ms/step - loss: 73.6440 - val_loss: 83.3935\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 5ms/step - loss: 74.5012 - val_loss: 82.7742\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.1160 - val_loss: 81.6354\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 72.7262 - val_loss: 81.3471\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 3ms/step - loss: 73.7749 - val_loss: 82.1240\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.8824 - val_loss: 80.5842\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.5316 - val_loss: 81.1937\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.6304 - val_loss: 80.3494\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 74ms/step - loss: 141209.1719 - val_loss: 62956.6875\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 5ms/step - loss: 28686.3418 - val_loss: 5181.0713\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 5ms/step - loss: 1417.0490 - val_loss: 829.2888\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 747.6403 - val_loss: 563.0969\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 559.1853 - val_loss: 574.3433\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 5ms/step - loss: 549.6286 - val_loss: 542.2596\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 533.6221 - val_loss: 537.7939\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 5ms/step - loss: 521.8257 - val_loss: 519.8228\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 508.6856 - val_loss: 508.2386\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 496.4488 - val_loss: 496.3369\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 484.5530 - val_loss: 484.1018\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 472.1042 - val_loss: 473.3850\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 460.2026 - val_loss: 455.2423\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 447.9982 - val_loss: 448.8751\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 435.5733 - val_loss: 432.6407\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 7ms/step - loss: 422.5616 - val_loss: 424.7616\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 411.3755 - val_loss: 413.5654\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 7ms/step - loss: 402.7441 - val_loss: 408.7847\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 390.3587 - val_loss: 388.6493\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 7ms/step - loss: 380.3719 - val_loss: 380.3863\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 369.9076 - val_loss: 370.7235\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 7ms/step - loss: 360.3130 - val_loss: 359.7810\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 351.0576 - val_loss: 355.5144\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 341.8986 - val_loss: 343.8566\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 333.5846 - val_loss: 335.1926\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 325.2993 - val_loss: 327.0305\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 317.1796 - val_loss: 318.9127\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 311.0388 - val_loss: 312.6289\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 309.2431 - val_loss: 317.9869\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 8ms/step - loss: 296.7271 - val_loss: 297.0071\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 7ms/step - loss: 288.5085 - val_loss: 293.5634\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 12ms/step - loss: 282.6400 - val_loss: 281.6929\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 13ms/step - loss: 276.1081 - val_loss: 280.5929\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 269.3151 - val_loss: 271.0589\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 7ms/step - loss: 264.3646 - val_loss: 266.3429\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 12ms/step - loss: 257.8740 - val_loss: 265.6691\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 7ms/step - loss: 253.2147 - val_loss: 256.3362\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 12ms/step - loss: 250.0879 - val_loss: 248.2013\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 241.8216 - val_loss: 254.7099\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 9ms/step - loss: 240.3277 - val_loss: 247.4086\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 233.3545 - val_loss: 236.6779\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 229.1796 - val_loss: 234.9162\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 224.3571 - val_loss: 230.4037\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 220.3641 - val_loss: 222.7573\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 217.1135 - val_loss: 225.1669\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 212.3277 - val_loss: 217.2413\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 209.4570 - val_loss: 212.8911\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 7ms/step - loss: 204.9832 - val_loss: 226.5186\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 206.1651 - val_loss: 213.2401\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 199.5371 - val_loss: 202.9281\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 197.1352 - val_loss: 200.0368\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 192.2802 - val_loss: 195.5448\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 189.0825 - val_loss: 205.4760\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 185.4240 - val_loss: 192.6812\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.3954 - val_loss: 191.4322\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.8223 - val_loss: 188.1957\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 178.4785 - val_loss: 187.7421\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 5ms/step - loss: 174.5390 - val_loss: 183.2175\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 171.3199 - val_loss: 181.4922\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.0422 - val_loss: 175.4943\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 165.5138 - val_loss: 175.3599\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 164.2662 - val_loss: 177.0772\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 161.2086 - val_loss: 167.5090\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 159.5961 - val_loss: 166.5672\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 5ms/step - loss: 156.4931 - val_loss: 166.8769\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 153.9995 - val_loss: 176.8207\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.9320 - val_loss: 175.0490\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 151.9819 - val_loss: 159.2146\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 147.8206 - val_loss: 154.7460\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 145.4703 - val_loss: 166.5647\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 145.4419 - val_loss: 155.4617\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 7ms/step - loss: 143.0709 - val_loss: 153.7488\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 140.8824 - val_loss: 147.8949\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 138.8074 - val_loss: 147.0333\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 7ms/step - loss: 139.6428 - val_loss: 144.9346\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 135.2504 - val_loss: 155.4120\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 136.3395 - val_loss: 153.1870\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 131.9832 - val_loss: 141.7269\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 129.7783 - val_loss: 139.8250\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 129.1598 - val_loss: 138.6930\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 126.7799 - val_loss: 136.7273\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 127.2092 - val_loss: 135.8484\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 124.8354 - val_loss: 138.9831\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.3678 - val_loss: 133.9756\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 8ms/step - loss: 122.4471 - val_loss: 133.0510\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 12ms/step - loss: 120.3586 - val_loss: 131.4482\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 120.3954 - val_loss: 130.7021\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 7ms/step - loss: 118.9404 - val_loss: 132.5086\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.6899 - val_loss: 129.7022\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 118.0140 - val_loss: 137.8053\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 12ms/step - loss: 118.2664 - val_loss: 127.5377\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 9ms/step - loss: 117.8341 - val_loss: 126.0158\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 5ms/step - loss: 114.3491 - val_loss: 126.4620\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.8513 - val_loss: 125.6890\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 5ms/step - loss: 112.6021 - val_loss: 126.3478\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.5286 - val_loss: 127.8374\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 110.6190 - val_loss: 123.4414\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.7001 - val_loss: 125.5583\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.0362 - val_loss: 123.4575\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.2493 - val_loss: 126.8787\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 56ms/step - loss: 842.2275 - val_loss: 408.4079\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 335.5597 - val_loss: 275.5536\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 239.9556 - val_loss: 230.2712\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 211.7746 - val_loss: 217.1393\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 201.1974 - val_loss: 210.5499\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 8ms/step - loss: 192.7809 - val_loss: 202.9800\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.8968 - val_loss: 192.3927\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 5ms/step - loss: 175.2093 - val_loss: 182.9193\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 7ms/step - loss: 168.4852 - val_loss: 176.1948\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 7ms/step - loss: 162.9934 - val_loss: 167.4525\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 12ms/step - loss: 154.9945 - val_loss: 163.5165\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.1142 - val_loss: 161.1411\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 143.4579 - val_loss: 163.0216\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 139.9838 - val_loss: 152.5374\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 8ms/step - loss: 135.2312 - val_loss: 147.1095\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 11ms/step - loss: 131.7932 - val_loss: 139.1932\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 13ms/step - loss: 127.6961 - val_loss: 135.6963\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 8ms/step - loss: 123.3418 - val_loss: 129.9330\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 10ms/step - loss: 121.4193 - val_loss: 138.7598\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.2976 - val_loss: 135.2348\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.7737 - val_loss: 123.5418\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.3169 - val_loss: 123.2502\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.9691 - val_loss: 117.6584\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.0949 - val_loss: 119.1965\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 106.9814 - val_loss: 117.6210\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 105.9372 - val_loss: 113.9770\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 7ms/step - loss: 106.1429 - val_loss: 111.8779\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 101.8121 - val_loss: 109.1162\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 99.8447 - val_loss: 106.4308\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 7ms/step - loss: 97.6204 - val_loss: 104.4064\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 96.2872 - val_loss: 103.8008\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 95.9303 - val_loss: 101.6995\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 93.7821 - val_loss: 102.4596\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 92.3799 - val_loss: 98.4317\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 7ms/step - loss: 90.7605 - val_loss: 98.8171\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 89.7337 - val_loss: 98.7355\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 88.8274 - val_loss: 98.0943\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 89.2940 - val_loss: 95.0931\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 7ms/step - loss: 86.5670 - val_loss: 93.1019\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 5ms/step - loss: 86.2180 - val_loss: 95.5076\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 83.4435 - val_loss: 97.0777\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 89.5953 - val_loss: 91.6458\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.1516 - val_loss: 90.1412\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 83.2359 - val_loss: 89.4563\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 5ms/step - loss: 82.9564 - val_loss: 88.8409\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 7ms/step - loss: 81.6413 - val_loss: 87.9534\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.0136 - val_loss: 90.4414\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 80.4045 - val_loss: 87.2086\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.9700 - val_loss: 86.0096\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 80.3437 - val_loss: 90.9065\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 80.0743 - val_loss: 90.6638\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.5252 - val_loss: 86.4775\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.6265 - val_loss: 83.9311\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.7112 - val_loss: 90.3919\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.2420 - val_loss: 88.6304\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 75.7345 - val_loss: 90.8969\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 7ms/step - loss: 74.7465 - val_loss: 82.2512\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 5ms/step - loss: 74.8302 - val_loss: 82.0413\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.1640 - val_loss: 83.9073\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 72.9143 - val_loss: 81.5278\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 72.3165 - val_loss: 81.4216\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 72.8771 - val_loss: 80.3840\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.2188 - val_loss: 81.7825\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.0923 - val_loss: 79.7545\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.3686 - val_loss: 79.6060\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 5ms/step - loss: 71.9598 - val_loss: 78.8169\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 70.4053 - val_loss: 78.7060\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 7ms/step - loss: 70.0971 - val_loss: 82.3836\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.5991 - val_loss: 86.1469\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.5229 - val_loss: 78.2651\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.3453 - val_loss: 77.5580\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 70.7694 - val_loss: 79.8764\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 5ms/step - loss: 68.5309 - val_loss: 76.8129\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 5ms/step - loss: 68.7431 - val_loss: 76.5769\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 68.5607 - val_loss: 76.1595\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 7ms/step - loss: 68.5060 - val_loss: 80.0546\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.6801 - val_loss: 76.0906\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.2053 - val_loss: 75.9582\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.8778 - val_loss: 77.1575\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.3182 - val_loss: 76.3313\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 67.2928 - val_loss: 74.9989\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.4467 - val_loss: 74.5180\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 66.7019 - val_loss: 74.4545\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.0185 - val_loss: 74.6162\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 66.6109 - val_loss: 74.6360\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.6573 - val_loss: 77.4266\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.1370 - val_loss: 73.6348\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 5ms/step - loss: 65.1240 - val_loss: 72.9475\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 5ms/step - loss: 66.1066 - val_loss: 73.6954\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 67.2696 - val_loss: 74.8063\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 65.2820 - val_loss: 77.7012\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 64.9752 - val_loss: 72.6731\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 64.7589 - val_loss: 81.9205\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 7ms/step - loss: 65.4550 - val_loss: 74.4178\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 7ms/step - loss: 64.5468 - val_loss: 72.7716\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 8ms/step - loss: 63.6304 - val_loss: 71.6843\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 63.4009 - val_loss: 71.2851\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 63.1230 - val_loss: 71.3761\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 5ms/step - loss: 63.9996 - val_loss: 71.4508\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 64.0731 - val_loss: 71.7573\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 75ms/step - loss: 12578.9248 - val_loss: 1314.3329\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 417.5299 - val_loss: 294.4987\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 241.8148 - val_loss: 208.2362\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 197.5432 - val_loss: 197.3157\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 189.0128 - val_loss: 192.5291\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 184.1808 - val_loss: 186.8666\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.8149 - val_loss: 182.4413\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 7ms/step - loss: 174.0407 - val_loss: 178.2385\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 5ms/step - loss: 169.0011 - val_loss: 172.2696\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 3ms/step - loss: 164.9207 - val_loss: 167.5451\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 7ms/step - loss: 160.5236 - val_loss: 164.0600\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 157.5273 - val_loss: 159.7105\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 153.9942 - val_loss: 155.6008\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 3ms/step - loss: 150.1147 - val_loss: 152.8229\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 146.0072 - val_loss: 148.1236\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 7ms/step - loss: 143.3534 - val_loss: 145.1926\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 139.4899 - val_loss: 143.2928\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 137.2894 - val_loss: 141.2361\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.5591 - val_loss: 139.2510\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 7ms/step - loss: 133.2676 - val_loss: 139.2540\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 3ms/step - loss: 130.2290 - val_loss: 137.1917\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 128.4886 - val_loss: 134.2736\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 127.5246 - val_loss: 133.0317\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 125.5114 - val_loss: 132.3034\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 124.1698 - val_loss: 130.2725\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.9022 - val_loss: 129.7512\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 5ms/step - loss: 122.7581 - val_loss: 132.2848\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.5336 - val_loss: 132.1707\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 123.2952 - val_loss: 128.7333\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.5746 - val_loss: 125.4984\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.7232 - val_loss: 123.8278\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.5094 - val_loss: 122.3234\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.4697 - val_loss: 121.2546\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.1215 - val_loss: 120.0529\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.5057 - val_loss: 119.6627\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.2608 - val_loss: 117.5483\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.2634 - val_loss: 116.3704\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.9206 - val_loss: 117.1721\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.8646 - val_loss: 114.6968\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.5026 - val_loss: 112.9500\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.3905 - val_loss: 112.0795\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 106.4764 - val_loss: 110.6116\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 106.5641 - val_loss: 111.3542\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 5ms/step - loss: 105.4808 - val_loss: 111.3734\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 103.8850 - val_loss: 108.3326\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 102.2370 - val_loss: 106.2358\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 101.0779 - val_loss: 105.7697\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 99.9827 - val_loss: 104.0340\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 99.3920 - val_loss: 103.4656\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 98.3181 - val_loss: 101.9192\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 97.4076 - val_loss: 101.6110\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 97.0579 - val_loss: 100.7575\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 5ms/step - loss: 97.7350 - val_loss: 99.2415\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 5ms/step - loss: 95.9934 - val_loss: 100.1216\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 94.3365 - val_loss: 98.2646\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 5ms/step - loss: 93.8594 - val_loss: 96.9952\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 7ms/step - loss: 93.4270 - val_loss: 96.5175\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 5ms/step - loss: 92.8043 - val_loss: 95.1124\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 93.6725 - val_loss: 97.6138\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 91.1382 - val_loss: 93.5979\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 7ms/step - loss: 89.7401 - val_loss: 93.4195\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 88.4373 - val_loss: 92.0357\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 3ms/step - loss: 89.2150 - val_loss: 95.0258\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 88.1387 - val_loss: 94.6132\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 87.0180 - val_loss: 89.7723\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.5511 - val_loss: 89.3860\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.2720 - val_loss: 88.7091\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 83.1883 - val_loss: 88.7796\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 87.1229 - val_loss: 87.6167\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 84.2739 - val_loss: 86.6743\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.6842 - val_loss: 88.2497\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 80.3867 - val_loss: 85.4096\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 79.7014 - val_loss: 84.8953\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.9829 - val_loss: 85.8925\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 78.6652 - val_loss: 83.6699\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 7ms/step - loss: 78.3237 - val_loss: 85.0906\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.7564 - val_loss: 82.9052\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 76.8649 - val_loss: 81.6369\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 8ms/step - loss: 76.7904 - val_loss: 82.1006\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.3934 - val_loss: 82.1493\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.7660 - val_loss: 80.1927\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.9427 - val_loss: 84.4721\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.0715 - val_loss: 83.1695\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.4531 - val_loss: 84.8496\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 7ms/step - loss: 72.8945 - val_loss: 76.9915\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 5ms/step - loss: 71.0081 - val_loss: 78.1789\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 7ms/step - loss: 70.1270 - val_loss: 75.7718\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 71.0832 - val_loss: 78.5196\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 13ms/step - loss: 70.2352 - val_loss: 77.5276\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.1722 - val_loss: 74.1468\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.2205 - val_loss: 74.3337\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 13ms/step - loss: 70.3403 - val_loss: 75.4113\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.5929 - val_loss: 73.1153\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 11ms/step - loss: 68.7635 - val_loss: 73.4583\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.3062 - val_loss: 79.1569\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 67.6786 - val_loss: 70.7263\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 65.1552 - val_loss: 70.0337\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 3ms/step - loss: 67.0421 - val_loss: 72.0541\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 7ms/step - loss: 65.2286 - val_loss: 69.3814\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 5ms/step - loss: 64.5684 - val_loss: 69.4387\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 56ms/step - loss: 1510.2522 - val_loss: 580.9080\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 494.4148 - val_loss: 422.0318\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 403.9502 - val_loss: 378.0819\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 7ms/step - loss: 352.7969 - val_loss: 343.5167\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 321.6441 - val_loss: 317.2493\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 298.7448 - val_loss: 296.9442\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 7ms/step - loss: 279.3681 - val_loss: 284.4694\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 265.1541 - val_loss: 270.4269\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 7ms/step - loss: 256.2877 - val_loss: 263.3001\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 244.7501 - val_loss: 252.8921\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 237.5126 - val_loss: 245.0697\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 229.8698 - val_loss: 238.8133\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 222.3256 - val_loss: 239.5042\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 223.5143 - val_loss: 228.3848\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 212.7680 - val_loss: 223.2133\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 208.3091 - val_loss: 218.4702\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 203.1349 - val_loss: 218.2926\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 200.1826 - val_loss: 212.8061\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 195.4205 - val_loss: 206.0863\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 193.0340 - val_loss: 202.1466\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 188.7330 - val_loss: 200.1491\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 184.0521 - val_loss: 196.4152\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 182.1578 - val_loss: 194.9124\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 7ms/step - loss: 179.3118 - val_loss: 198.2886\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.4525 - val_loss: 191.1168\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.0891 - val_loss: 198.3776\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 172.8444 - val_loss: 182.7882\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 167.4253 - val_loss: 182.1597\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 164.3632 - val_loss: 177.8645\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 162.3209 - val_loss: 175.1874\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.9347 - val_loss: 173.1570\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.1594 - val_loss: 171.2487\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 7ms/step - loss: 156.5079 - val_loss: 170.4104\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 154.1010 - val_loss: 168.1795\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 153.5642 - val_loss: 168.2648\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.5026 - val_loss: 164.2195\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 151.6719 - val_loss: 163.3706\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 146.6576 - val_loss: 163.4044\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 144.0392 - val_loss: 156.5832\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 143.7958 - val_loss: 162.3261\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 142.8310 - val_loss: 152.4167\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 137.3324 - val_loss: 150.2795\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 135.6572 - val_loss: 147.3405\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.0512 - val_loss: 146.0412\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 132.9276 - val_loss: 143.8923\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 128.8904 - val_loss: 141.0967\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 127.0488 - val_loss: 138.9305\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 126.8533 - val_loss: 135.7917\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 122.7060 - val_loss: 137.1864\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 122.4948 - val_loss: 129.0914\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.6984 - val_loss: 129.0005\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.8096 - val_loss: 125.0128\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 7ms/step - loss: 115.2516 - val_loss: 121.5015\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.5857 - val_loss: 122.9090\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.5501 - val_loss: 133.4061\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.2490 - val_loss: 116.8771\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 106.1911 - val_loss: 124.0189\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 5ms/step - loss: 105.1743 - val_loss: 110.6621\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 103.9187 - val_loss: 109.1346\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 7ms/step - loss: 104.2349 - val_loss: 111.3345\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 99.7481 - val_loss: 104.9174\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 99.6649 - val_loss: 104.2964\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 98.3852 - val_loss: 107.1186\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 7ms/step - loss: 100.6953 - val_loss: 118.3155\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 7ms/step - loss: 97.0006 - val_loss: 98.8501\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 13ms/step - loss: 95.7828 - val_loss: 98.2154\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 13ms/step - loss: 91.4170 - val_loss: 96.0183\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 89.1403 - val_loss: 97.9120\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 5ms/step - loss: 90.1436 - val_loss: 93.4797\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 86.3115 - val_loss: 91.3297\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.9299 - val_loss: 90.2993\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 83.7955 - val_loss: 89.2290\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.5396 - val_loss: 88.5659\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.8493 - val_loss: 87.2206\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 13ms/step - loss: 80.7397 - val_loss: 85.7930\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 80.3211 - val_loss: 85.6211\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 7ms/step - loss: 84.2849 - val_loss: 91.7054\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 11ms/step - loss: 82.3891 - val_loss: 82.9936\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 76.5226 - val_loss: 82.0661\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 75.2374 - val_loss: 82.2717\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 74.3851 - val_loss: 83.0967\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.5731 - val_loss: 80.6302\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.4180 - val_loss: 83.2625\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.7475 - val_loss: 79.9568\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 5ms/step - loss: 72.8189 - val_loss: 80.2308\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 72.1452 - val_loss: 77.2732\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 7ms/step - loss: 70.7294 - val_loss: 77.9938\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.4317 - val_loss: 81.5242\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 3ms/step - loss: 72.9138 - val_loss: 80.3431\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.0251 - val_loss: 79.7943\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.2296 - val_loss: 76.4843\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 3ms/step - loss: 69.3904 - val_loss: 75.1437\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.1412 - val_loss: 80.5642\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.0092 - val_loss: 77.2026\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 68.0734 - val_loss: 75.5416\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 66.3500 - val_loss: 73.4241\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 67.6328 - val_loss: 72.4524\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.6102 - val_loss: 86.9677\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.1428 - val_loss: 73.0365\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 66.2854 - val_loss: 72.9782\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 57ms/step - loss: 107677.9609 - val_loss: 59294.8398\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 32647.6172 - val_loss: 12852.1367\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 5696.2490 - val_loss: 1467.8198\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 955.2001 - val_loss: 673.5021\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 484.9441 - val_loss: 385.2066\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 326.9083 - val_loss: 287.4283\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 271.2802 - val_loss: 249.0491\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 240.9708 - val_loss: 225.7251\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 7ms/step - loss: 221.5704 - val_loss: 215.3121\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 208.4689 - val_loss: 207.6254\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 198.1230 - val_loss: 207.4387\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 191.5715 - val_loss: 196.0236\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 184.2509 - val_loss: 193.7981\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.4465 - val_loss: 193.5006\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 177.0694 - val_loss: 187.8116\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 172.8696 - val_loss: 185.1606\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 171.6793 - val_loss: 182.8600\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 169.5101 - val_loss: 184.4519\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 167.1361 - val_loss: 184.8763\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 7ms/step - loss: 164.9641 - val_loss: 177.8449\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 165.3819 - val_loss: 175.8486\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.2604 - val_loss: 179.5097\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 157.9937 - val_loss: 172.8423\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.0386 - val_loss: 170.7150\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.7728 - val_loss: 174.2075\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.5778 - val_loss: 167.9628\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 154.1713 - val_loss: 168.9228\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 151.8385 - val_loss: 167.2304\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 151.7159 - val_loss: 165.5319\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.7104 - val_loss: 162.7130\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 148.9423 - val_loss: 165.1105\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 147.3461 - val_loss: 161.0276\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 5ms/step - loss: 146.4703 - val_loss: 160.0510\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 145.3514 - val_loss: 158.7955\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 144.6389 - val_loss: 162.1650\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 144.1941 - val_loss: 158.8661\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 142.1060 - val_loss: 155.9876\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 147.1649 - val_loss: 153.2382\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 142.9322 - val_loss: 155.1468\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 140.6660 - val_loss: 156.1410\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 140.0226 - val_loss: 157.6375\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 142.7955 - val_loss: 159.0816\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 7ms/step - loss: 140.8950 - val_loss: 155.6216\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 139.5885 - val_loss: 153.6476\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 138.7599 - val_loss: 155.2884\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 137.1819 - val_loss: 144.9469\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 134.6285 - val_loss: 144.4001\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 133.4181 - val_loss: 152.0177\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 7ms/step - loss: 133.9697 - val_loss: 143.0457\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 132.6426 - val_loss: 147.6009\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 131.9536 - val_loss: 142.5977\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 7ms/step - loss: 130.2158 - val_loss: 140.3614\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 132.0690 - val_loss: 139.9286\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 129.5893 - val_loss: 142.4133\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 129.3776 - val_loss: 138.8907\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 7ms/step - loss: 129.4590 - val_loss: 141.6529\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 12ms/step - loss: 127.9532 - val_loss: 137.8666\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 7ms/step - loss: 127.7654 - val_loss: 137.9655\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 126.3569 - val_loss: 137.1044\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 13ms/step - loss: 125.7059 - val_loss: 136.6590\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 13ms/step - loss: 125.3015 - val_loss: 136.1136\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 12ms/step - loss: 124.7203 - val_loss: 135.5426\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 5ms/step - loss: 126.2925 - val_loss: 134.6259\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 123.1110 - val_loss: 134.1706\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.8703 - val_loss: 133.4745\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 7ms/step - loss: 123.6697 - val_loss: 132.4406\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 5ms/step - loss: 124.3303 - val_loss: 134.1580\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.7552 - val_loss: 132.4978\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.2721 - val_loss: 134.7412\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 121.6045 - val_loss: 131.3988\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.0590 - val_loss: 137.0021\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.8941 - val_loss: 129.7566\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.9221 - val_loss: 131.9697\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.9677 - val_loss: 129.0342\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.0121 - val_loss: 132.1203\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.1206 - val_loss: 127.8637\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 5ms/step - loss: 118.1699 - val_loss: 130.7827\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 5ms/step - loss: 115.4382 - val_loss: 131.5674\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.8052 - val_loss: 127.4268\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.4658 - val_loss: 126.4688\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 7ms/step - loss: 116.3273 - val_loss: 132.5682\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.2139 - val_loss: 129.0566\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 7ms/step - loss: 117.9064 - val_loss: 132.6870\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.4050 - val_loss: 125.3713\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.5863 - val_loss: 126.4138\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.1867 - val_loss: 124.9729\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.0632 - val_loss: 124.6917\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.5445 - val_loss: 129.1561\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 7ms/step - loss: 113.5208 - val_loss: 127.0959\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.2103 - val_loss: 124.5864\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 5ms/step - loss: 110.7743 - val_loss: 123.6058\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.7895 - val_loss: 123.6624\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.0991 - val_loss: 123.9389\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.2723 - val_loss: 122.6334\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 7ms/step - loss: 110.8365 - val_loss: 131.4633\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.2985 - val_loss: 121.9991\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 108.8852 - val_loss: 125.1874\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.3669 - val_loss: 122.7903\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 7ms/step - loss: 108.1614 - val_loss: 127.9142\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.4501 - val_loss: 123.3119\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 56ms/step - loss: 3228.9338 - val_loss: 340.1027\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 320.3952 - val_loss: 352.1797\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 289.8686 - val_loss: 269.0410\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 271.9310 - val_loss: 268.6164\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 268.9995 - val_loss: 269.1091\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 267.5307 - val_loss: 264.9532\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 5ms/step - loss: 266.2479 - val_loss: 264.5554\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 263.2252 - val_loss: 259.5366\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 260.7628 - val_loss: 261.1990\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 258.8126 - val_loss: 258.1328\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 5ms/step - loss: 257.9134 - val_loss: 259.4409\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 257.2323 - val_loss: 259.9417\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 256.0500 - val_loss: 256.4263\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 254.9159 - val_loss: 255.5833\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 254.5854 - val_loss: 251.7205\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 242.3268 - val_loss: 224.7355\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 217.2648 - val_loss: 216.1243\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 205.2850 - val_loss: 202.7567\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 197.2869 - val_loss: 204.3969\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 7ms/step - loss: 188.0534 - val_loss: 184.6707\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.3619 - val_loss: 177.2876\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 5ms/step - loss: 174.5789 - val_loss: 169.7263\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 7ms/step - loss: 167.2906 - val_loss: 168.0256\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.6118 - val_loss: 164.5925\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 153.2849 - val_loss: 151.5724\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 146.1343 - val_loss: 146.7804\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 141.5823 - val_loss: 143.0052\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.7346 - val_loss: 131.7790\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 131.0507 - val_loss: 128.1384\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 7ms/step - loss: 124.7851 - val_loss: 122.3068\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 8ms/step - loss: 121.1492 - val_loss: 117.8543\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.0670 - val_loss: 113.6003\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 12ms/step - loss: 115.6384 - val_loss: 107.9078\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.0796 - val_loss: 111.7156\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 106.5916 - val_loss: 104.8174\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 103.6153 - val_loss: 100.7518\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 7ms/step - loss: 102.1658 - val_loss: 99.8895\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 13ms/step - loss: 99.6065 - val_loss: 97.4506\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 12ms/step - loss: 99.0215 - val_loss: 96.7204\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 97.4021 - val_loss: 97.0889\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 14ms/step - loss: 98.9451 - val_loss: 99.3252\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 98.2545 - val_loss: 93.8316\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 93.8828 - val_loss: 93.4450\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 93.3280 - val_loss: 94.3224\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 94.8411 - val_loss: 92.7558\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 91.7377 - val_loss: 92.5880\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 91.0612 - val_loss: 90.9542\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 90.5435 - val_loss: 92.3144\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 89.5668 - val_loss: 90.3533\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 89.7395 - val_loss: 89.2295\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.8193 - val_loss: 96.7050\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 87.6638 - val_loss: 89.4078\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 85.7147 - val_loss: 87.2584\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.9394 - val_loss: 86.5109\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.1569 - val_loss: 86.8245\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 84.3947 - val_loss: 91.3296\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.5384 - val_loss: 86.5347\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.3149 - val_loss: 89.0338\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 83.9401 - val_loss: 84.7408\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.7890 - val_loss: 88.0315\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 7ms/step - loss: 84.3900 - val_loss: 84.7471\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 5ms/step - loss: 81.4268 - val_loss: 84.5032\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 80.1864 - val_loss: 84.6025\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.7202 - val_loss: 83.6313\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 7ms/step - loss: 79.4763 - val_loss: 83.4321\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 5ms/step - loss: 78.8853 - val_loss: 82.5035\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.6860 - val_loss: 83.6505\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 5ms/step - loss: 77.7157 - val_loss: 83.6463\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 78.7196 - val_loss: 82.1964\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 77.3360 - val_loss: 81.6486\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.0928 - val_loss: 83.9147\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 7ms/step - loss: 78.1894 - val_loss: 91.3170\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.1582 - val_loss: 83.0711\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.9966 - val_loss: 80.4234\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 76.2774 - val_loss: 80.1945\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.8409 - val_loss: 84.4984\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.5265 - val_loss: 79.1497\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.5891 - val_loss: 82.4531\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.5920 - val_loss: 79.1355\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 7ms/step - loss: 74.0695 - val_loss: 80.6544\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.2691 - val_loss: 78.7719\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 5ms/step - loss: 73.4566 - val_loss: 85.3821\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.5784 - val_loss: 80.7477\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 7ms/step - loss: 72.8607 - val_loss: 77.9897\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.7345 - val_loss: 77.3814\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.2277 - val_loss: 78.8275\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 72.8125 - val_loss: 77.7551\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 71.7524 - val_loss: 82.1391\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 7ms/step - loss: 71.3854 - val_loss: 85.2769\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 71.8680 - val_loss: 78.9430\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.9530 - val_loss: 77.1053\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.0493 - val_loss: 79.9454\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 70.4279 - val_loss: 78.2625\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 3ms/step - loss: 69.9406 - val_loss: 77.0275\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.7966 - val_loss: 77.4356\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.7385 - val_loss: 76.8078\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 8ms/step - loss: 68.6504 - val_loss: 78.4840\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.8803 - val_loss: 77.4318\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.8000 - val_loss: 78.0314\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 68.1251 - val_loss: 78.3662\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 57ms/step - loss: 355.2298 - val_loss: 336.7748\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 302.4519 - val_loss: 292.1557\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 5ms/step - loss: 280.9722 - val_loss: 271.6080\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 7ms/step - loss: 261.6287 - val_loss: 256.6290\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 5ms/step - loss: 242.5442 - val_loss: 245.4145\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 230.2640 - val_loss: 233.8972\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 219.8687 - val_loss: 223.5000\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 7ms/step - loss: 208.8688 - val_loss: 214.9347\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 7ms/step - loss: 201.5473 - val_loss: 211.0586\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 11ms/step - loss: 193.4673 - val_loss: 201.2718\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 184.9779 - val_loss: 188.1561\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 5ms/step - loss: 177.8510 - val_loss: 181.1956\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.6443 - val_loss: 182.2881\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.3491 - val_loss: 174.1948\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 7ms/step - loss: 157.4109 - val_loss: 163.5911\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 13ms/step - loss: 153.2400 - val_loss: 156.9298\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 13ms/step - loss: 148.5807 - val_loss: 152.2420\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 142.9673 - val_loss: 148.0340\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 13ms/step - loss: 138.8015 - val_loss: 144.0067\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 135.5291 - val_loss: 142.5345\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 7ms/step - loss: 131.8280 - val_loss: 137.0182\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 128.8841 - val_loss: 136.0449\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 128.2940 - val_loss: 139.0453\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 125.6268 - val_loss: 130.2678\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 122.4397 - val_loss: 129.3245\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 5ms/step - loss: 121.2965 - val_loss: 127.4426\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 5ms/step - loss: 118.4860 - val_loss: 125.2281\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.6889 - val_loss: 124.7554\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.1646 - val_loss: 122.3537\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.4923 - val_loss: 122.5803\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 7ms/step - loss: 115.0533 - val_loss: 120.5867\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.1252 - val_loss: 119.5047\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.0383 - val_loss: 118.3211\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.7125 - val_loss: 117.5525\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.9985 - val_loss: 118.8122\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.4989 - val_loss: 120.5565\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.4653 - val_loss: 118.2365\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.4560 - val_loss: 115.7555\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.1646 - val_loss: 125.1164\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 3ms/step - loss: 115.0683 - val_loss: 114.3958\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.0183 - val_loss: 112.7582\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 5ms/step - loss: 105.2768 - val_loss: 131.5880\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.7907 - val_loss: 109.2765\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 102.4316 - val_loss: 106.7658\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 103.7939 - val_loss: 105.3410\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 98.5257 - val_loss: 98.8264\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 98.0964 - val_loss: 106.0305\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 97.3361 - val_loss: 102.2347\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 99.4071 - val_loss: 114.8943\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 96.4132 - val_loss: 96.4261\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 90.4762 - val_loss: 96.9884\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 89.1105 - val_loss: 98.5001\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 5ms/step - loss: 90.5125 - val_loss: 94.4366\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 87.0827 - val_loss: 92.6998\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.2258 - val_loss: 90.9240\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 83.4445 - val_loss: 89.7646\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 83.9022 - val_loss: 91.4021\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 83.8707 - val_loss: 93.1081\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 83.5327 - val_loss: 87.9631\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 5ms/step - loss: 82.2307 - val_loss: 86.6933\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.0329 - val_loss: 93.7669\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.5884 - val_loss: 85.0545\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 78.6898 - val_loss: 85.6230\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.3750 - val_loss: 88.0593\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.3394 - val_loss: 83.6147\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.6660 - val_loss: 89.4083\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.8825 - val_loss: 82.4469\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 76.2863 - val_loss: 82.9363\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.8128 - val_loss: 80.8705\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 5ms/step - loss: 74.6069 - val_loss: 86.5960\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 5ms/step - loss: 76.9289 - val_loss: 88.7735\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.4401 - val_loss: 80.3853\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 72.7051 - val_loss: 78.3897\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.4080 - val_loss: 79.7188\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 71.8133 - val_loss: 77.8158\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.8295 - val_loss: 77.4104\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.1607 - val_loss: 81.1034\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.7979 - val_loss: 76.2954\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 70.9716 - val_loss: 76.9282\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.0986 - val_loss: 75.6461\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.3972 - val_loss: 74.8131\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.5395 - val_loss: 90.9651\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 70.9917 - val_loss: 76.3043\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.5550 - val_loss: 76.8438\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 7ms/step - loss: 76.4849 - val_loss: 76.6869\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 5ms/step - loss: 66.4777 - val_loss: 77.3764\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.5823 - val_loss: 72.3322\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 66.2871 - val_loss: 75.0070\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 67.3155 - val_loss: 72.2874\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 66.3200 - val_loss: 70.7040\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 5ms/step - loss: 64.7437 - val_loss: 70.2590\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 3ms/step - loss: 65.1065 - val_loss: 69.6057\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 69.0122 - val_loss: 71.3507\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.0608 - val_loss: 79.8607\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 68.1381 - val_loss: 74.7595\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 68.3500 - val_loss: 74.2607\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 62.6168 - val_loss: 70.0498\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 62.6768 - val_loss: 67.7361\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 63.4609 - val_loss: 67.0565\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 62.2186 - val_loss: 67.7225\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 79ms/step - loss: 43030.7930 - val_loss: 25595.0664\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 18ms/step - loss: 16782.5469 - val_loss: 10712.9717\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 13ms/step - loss: 7240.4141 - val_loss: 4807.9443\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 13ms/step - loss: 2948.9365 - val_loss: 1469.1742\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 704.7469 - val_loss: 324.8928\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 301.0763 - val_loss: 267.6588\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 7ms/step - loss: 276.8987 - val_loss: 263.3845\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 265.3471 - val_loss: 253.7854\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 258.7541 - val_loss: 248.2524\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 254.9532 - val_loss: 246.5979\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 251.4779 - val_loss: 245.3232\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 248.7448 - val_loss: 242.8700\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 246.7000 - val_loss: 239.9856\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 244.5359 - val_loss: 240.9942\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 241.5120 - val_loss: 237.1634\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 238.6473 - val_loss: 236.3503\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 236.1349 - val_loss: 231.9430\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 233.4666 - val_loss: 230.1015\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 3ms/step - loss: 229.6857 - val_loss: 226.3839\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 226.1474 - val_loss: 223.8944\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 222.0141 - val_loss: 221.7422\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 218.3655 - val_loss: 218.0529\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 213.7088 - val_loss: 211.2935\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 7ms/step - loss: 208.2241 - val_loss: 206.6247\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 5ms/step - loss: 203.5578 - val_loss: 201.3292\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 196.1360 - val_loss: 192.4042\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 187.7169 - val_loss: 183.9553\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.8716 - val_loss: 178.4462\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 170.2347 - val_loss: 164.3541\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 160.4807 - val_loss: 157.0280\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.2789 - val_loss: 151.3828\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 3ms/step - loss: 144.4737 - val_loss: 142.0854\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.1964 - val_loss: 135.7873\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 132.0205 - val_loss: 129.3167\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 126.1788 - val_loss: 125.7460\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.6925 - val_loss: 122.1813\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.1425 - val_loss: 117.3422\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.2568 - val_loss: 120.5445\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 108.8047 - val_loss: 113.4005\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 106.2290 - val_loss: 111.0841\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 104.2942 - val_loss: 108.4354\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 102.1985 - val_loss: 107.0241\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 7ms/step - loss: 100.7845 - val_loss: 105.6397\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 99.1434 - val_loss: 104.9549\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 98.7444 - val_loss: 107.1377\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 5ms/step - loss: 98.5317 - val_loss: 103.3069\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 7ms/step - loss: 95.4186 - val_loss: 101.0060\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 95.0016 - val_loss: 102.2566\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 94.1469 - val_loss: 100.2832\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 5ms/step - loss: 94.7570 - val_loss: 99.1941\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 93.2500 - val_loss: 98.3961\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 92.1530 - val_loss: 98.4079\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 91.6160 - val_loss: 98.0561\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 7ms/step - loss: 91.8100 - val_loss: 99.5221\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 91.8205 - val_loss: 96.3353\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 5ms/step - loss: 90.5447 - val_loss: 96.1132\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 7ms/step - loss: 89.9055 - val_loss: 96.2079\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 89.5877 - val_loss: 100.6643\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 7ms/step - loss: 89.7039 - val_loss: 96.5260\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 88.9962 - val_loss: 94.6266\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 87.8626 - val_loss: 93.5166\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 88.8836 - val_loss: 95.3795\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 87.6572 - val_loss: 93.8250\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 87.7345 - val_loss: 92.1530\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 86.7982 - val_loss: 92.1614\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 86.0786 - val_loss: 92.8506\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 86.2723 - val_loss: 91.8143\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 5ms/step - loss: 85.5103 - val_loss: 91.9776\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 7ms/step - loss: 85.4517 - val_loss: 91.2313\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.2422 - val_loss: 91.7185\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 83.8972 - val_loss: 91.2323\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.8573 - val_loss: 94.4750\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 85.7494 - val_loss: 90.7938\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 83.1193 - val_loss: 90.6825\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.8997 - val_loss: 90.5679\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 5ms/step - loss: 82.9126 - val_loss: 90.2561\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.4546 - val_loss: 89.6096\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.6582 - val_loss: 89.3076\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 81.3751 - val_loss: 88.9563\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 3ms/step - loss: 81.5129 - val_loss: 88.6370\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 7ms/step - loss: 82.1458 - val_loss: 89.6575\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 81.4673 - val_loss: 88.8474\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 80.8175 - val_loss: 86.9754\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 80.7417 - val_loss: 87.4222\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 8ms/step - loss: 80.2699 - val_loss: 86.5940\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.5663 - val_loss: 86.2049\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 5ms/step - loss: 79.4384 - val_loss: 87.3155\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.7675 - val_loss: 85.5297\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 7ms/step - loss: 78.5785 - val_loss: 85.3852\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 12ms/step - loss: 78.7134 - val_loss: 85.7047\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.1704 - val_loss: 86.2407\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.9191 - val_loss: 84.6150\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.3498 - val_loss: 84.3534\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 7ms/step - loss: 77.3167 - val_loss: 84.8524\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 8ms/step - loss: 77.3384 - val_loss: 83.3947\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 11ms/step - loss: 77.1154 - val_loss: 87.3027\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.8823 - val_loss: 82.9520\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.3519 - val_loss: 83.4808\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.5956 - val_loss: 86.4653\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 7ms/step - loss: 76.7339 - val_loss: 83.6942\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 56ms/step - loss: 88264.3984 - val_loss: 49187.7656\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 30947.0566 - val_loss: 15389.8691\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 8884.8887 - val_loss: 3740.1008\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 7ms/step - loss: 2556.0662 - val_loss: 1467.3038\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1173.5564 - val_loss: 780.4300\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 680.4546 - val_loss: 513.0995\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 478.0883 - val_loss: 416.0827\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 386.4045 - val_loss: 359.2653\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 7ms/step - loss: 329.1259 - val_loss: 314.1420\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 285.9393 - val_loss: 281.5911\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 257.1241 - val_loss: 262.1404\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 7ms/step - loss: 243.0233 - val_loss: 252.2433\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 234.4844 - val_loss: 246.6128\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 229.5263 - val_loss: 243.2223\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 226.0800 - val_loss: 241.1345\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 222.5581 - val_loss: 238.2547\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 219.9803 - val_loss: 235.8700\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 216.9544 - val_loss: 234.3059\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 214.4613 - val_loss: 232.0366\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 212.2325 - val_loss: 229.6331\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 209.5608 - val_loss: 227.2076\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 207.5881 - val_loss: 225.0717\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 206.8457 - val_loss: 223.6402\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 204.2430 - val_loss: 221.9925\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 202.3067 - val_loss: 219.3985\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 200.3675 - val_loss: 218.6640\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 198.9037 - val_loss: 217.1393\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 197.1432 - val_loss: 215.0482\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 195.9484 - val_loss: 213.7195\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 194.3103 - val_loss: 212.6798\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 193.1489 - val_loss: 210.7511\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 191.2436 - val_loss: 210.3816\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 190.1528 - val_loss: 208.1077\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 189.0157 - val_loss: 206.9161\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 7ms/step - loss: 187.9373 - val_loss: 205.8794\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 5ms/step - loss: 187.4020 - val_loss: 204.3974\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 184.9153 - val_loss: 203.9273\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.3273 - val_loss: 201.8409\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 181.9582 - val_loss: 200.7335\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 3ms/step - loss: 180.5045 - val_loss: 199.3266\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 7ms/step - loss: 180.1924 - val_loss: 198.9204\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 178.1529 - val_loss: 196.7465\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 7ms/step - loss: 177.0055 - val_loss: 196.0297\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 175.6959 - val_loss: 194.8611\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 174.9855 - val_loss: 193.8838\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 175.1982 - val_loss: 192.0609\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 173.4721 - val_loss: 192.8686\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 172.0248 - val_loss: 189.8701\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 170.8059 - val_loss: 188.6236\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 169.2638 - val_loss: 187.5945\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.4087 - val_loss: 186.2946\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 167.9337 - val_loss: 185.1617\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.1560 - val_loss: 183.7327\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 165.5804 - val_loss: 182.3539\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 164.8650 - val_loss: 181.2895\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 163.0242 - val_loss: 181.0479\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.5058 - val_loss: 179.1752\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 161.5761 - val_loss: 177.9902\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.0860 - val_loss: 177.3639\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 7ms/step - loss: 159.9218 - val_loss: 175.5232\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 158.2298 - val_loss: 174.7397\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.8795 - val_loss: 172.9255\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 155.8901 - val_loss: 172.0044\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.8438 - val_loss: 170.9791\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 7ms/step - loss: 153.7528 - val_loss: 170.1777\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.7607 - val_loss: 167.9545\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 8ms/step - loss: 151.3447 - val_loss: 168.1144\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 13ms/step - loss: 149.8863 - val_loss: 166.0195\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.2278 - val_loss: 165.1030\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 148.0771 - val_loss: 164.4533\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 147.9585 - val_loss: 162.6706\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 145.4905 - val_loss: 162.4426\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 145.2014 - val_loss: 161.5449\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 143.9024 - val_loss: 159.7680\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 13ms/step - loss: 142.4607 - val_loss: 157.7119\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 7ms/step - loss: 141.1567 - val_loss: 156.5390\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 139.3403 - val_loss: 155.2374\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 13ms/step - loss: 138.8567 - val_loss: 154.3546\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 7ms/step - loss: 138.0483 - val_loss: 153.4506\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 136.2768 - val_loss: 152.0302\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 11ms/step - loss: 135.4223 - val_loss: 150.6329\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.0735 - val_loss: 149.8442\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.4853 - val_loss: 148.3748\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 131.9371 - val_loss: 147.4227\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 131.0611 - val_loss: 147.8811\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 3ms/step - loss: 129.5462 - val_loss: 146.0962\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 129.1628 - val_loss: 144.3682\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 128.3049 - val_loss: 142.7618\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 125.8944 - val_loss: 143.6462\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 126.7684 - val_loss: 140.8080\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 124.3018 - val_loss: 139.5056\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.0744 - val_loss: 138.3587\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 7ms/step - loss: 122.5091 - val_loss: 137.1604\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.3063 - val_loss: 136.7081\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.8389 - val_loss: 134.9809\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.6863 - val_loss: 134.2097\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 120.2590 - val_loss: 137.5657\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.4876 - val_loss: 132.8456\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.7075 - val_loss: 131.7347\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 7ms/step - loss: 115.8303 - val_loss: 131.6864\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 79ms/step - loss: 2125.2119 - val_loss: 939.3802\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 598.0920 - val_loss: 395.6822\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 292.3160 - val_loss: 256.4336\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 249.2114 - val_loss: 246.5462\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 245.1997 - val_loss: 245.3901\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 241.9223 - val_loss: 242.5103\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 239.7157 - val_loss: 240.4900\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 236.8501 - val_loss: 236.8469\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 234.0691 - val_loss: 233.7400\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 230.6293 - val_loss: 228.7973\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 225.1984 - val_loss: 221.5352\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 220.0111 - val_loss: 219.9259\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 214.7309 - val_loss: 212.5637\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 211.2724 - val_loss: 210.0554\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 206.8040 - val_loss: 205.3890\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 203.0304 - val_loss: 203.0806\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 7ms/step - loss: 199.2422 - val_loss: 198.4172\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 5ms/step - loss: 195.8240 - val_loss: 193.3079\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 7ms/step - loss: 192.1926 - val_loss: 191.1574\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 189.4422 - val_loss: 186.5704\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 186.7380 - val_loss: 187.2990\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 182.9313 - val_loss: 182.5629\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 178.7297 - val_loss: 175.9053\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 7ms/step - loss: 175.4079 - val_loss: 175.3550\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.8676 - val_loss: 170.7098\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 168.2487 - val_loss: 167.4984\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 165.2732 - val_loss: 166.0326\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 163.7034 - val_loss: 159.6266\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.2144 - val_loss: 161.7735\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 157.5854 - val_loss: 157.8139\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 153.4559 - val_loss: 150.8838\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 150.1735 - val_loss: 149.1286\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 146.8210 - val_loss: 146.4178\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 144.6610 - val_loss: 142.8848\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 140.9943 - val_loss: 137.2318\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 137.5521 - val_loss: 135.5016\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.0938 - val_loss: 130.5410\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 5ms/step - loss: 132.2513 - val_loss: 131.9307\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 128.1108 - val_loss: 123.2372\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 124.1646 - val_loss: 119.2655\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 121.3484 - val_loss: 119.4782\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.4659 - val_loss: 111.5929\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.6090 - val_loss: 113.6420\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 8ms/step - loss: 113.6963 - val_loss: 112.1844\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 11ms/step - loss: 111.5568 - val_loss: 103.4472\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 13ms/step - loss: 109.1814 - val_loss: 104.2863\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 106.0022 - val_loss: 105.3406\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 106.3200 - val_loss: 100.9223\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 7ms/step - loss: 103.0014 - val_loss: 97.5565\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 12ms/step - loss: 100.6253 - val_loss: 93.6694\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 8ms/step - loss: 100.2881 - val_loss: 95.2436\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 12ms/step - loss: 97.1159 - val_loss: 91.5124\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 12ms/step - loss: 97.0625 - val_loss: 88.7807\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 11ms/step - loss: 96.0957 - val_loss: 87.5604\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 92.2945 - val_loss: 88.1552\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 91.2519 - val_loss: 85.1279\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 7ms/step - loss: 90.1449 - val_loss: 84.0155\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 87.9447 - val_loss: 83.0970\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 86.7766 - val_loss: 83.8414\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.7217 - val_loss: 80.3447\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.2016 - val_loss: 78.9186\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.1131 - val_loss: 82.3374\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 7ms/step - loss: 86.0395 - val_loss: 77.6799\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 80.5952 - val_loss: 77.5683\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.6552 - val_loss: 74.8266\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 78.6724 - val_loss: 79.3003\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 5ms/step - loss: 77.4192 - val_loss: 73.3079\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 75.7474 - val_loss: 71.7249\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.0019 - val_loss: 70.4621\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.4306 - val_loss: 69.5736\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.7838 - val_loss: 68.5945\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.4002 - val_loss: 69.0579\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 7ms/step - loss: 68.9059 - val_loss: 68.6250\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.4430 - val_loss: 68.2155\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 5ms/step - loss: 67.0447 - val_loss: 66.9333\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 65.6842 - val_loss: 64.9392\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 64.6401 - val_loss: 64.5696\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 63.3402 - val_loss: 68.6886\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 63.4104 - val_loss: 65.3466\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 63.1998 - val_loss: 64.8207\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 63.7396 - val_loss: 68.4327\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 61.7183 - val_loss: 61.4861\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 5ms/step - loss: 61.0618 - val_loss: 61.0006\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 5ms/step - loss: 60.0553 - val_loss: 59.3551\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 58.1358 - val_loss: 59.0222\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 58.2946 - val_loss: 60.3870\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 7ms/step - loss: 60.3823 - val_loss: 61.4513\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 56.4014 - val_loss: 58.8810\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 56.7460 - val_loss: 59.1665\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 55.8030 - val_loss: 57.6076\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 55.2085 - val_loss: 57.2668\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 5ms/step - loss: 55.1867 - val_loss: 66.3510\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 7ms/step - loss: 55.4138 - val_loss: 57.7802\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 53.8671 - val_loss: 59.4298\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 53.3977 - val_loss: 55.8816\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 55.7072 - val_loss: 55.3866\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 53.4548 - val_loss: 55.2284\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 52.8084 - val_loss: 57.1564\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 53.5382 - val_loss: 56.5249\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 7ms/step - loss: 51.9574 - val_loss: 55.7156\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 58ms/step - loss: 1294.9180 - val_loss: 359.8248\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 340.0578 - val_loss: 250.4935\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 241.1390 - val_loss: 215.7594\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 5ms/step - loss: 227.2036 - val_loss: 211.1476\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 5ms/step - loss: 213.2617 - val_loss: 206.4912\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 207.0726 - val_loss: 200.4100\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 198.7575 - val_loss: 195.1687\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 194.5626 - val_loss: 189.4138\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 187.0962 - val_loss: 185.5856\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 182.7684 - val_loss: 186.8081\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 7ms/step - loss: 177.6509 - val_loss: 179.2809\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 172.8764 - val_loss: 174.9510\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 168.1295 - val_loss: 170.0548\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 163.2587 - val_loss: 166.8244\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 160.6627 - val_loss: 163.0843\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 159.8855 - val_loss: 160.3626\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 151.4595 - val_loss: 158.0491\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 149.1062 - val_loss: 154.5862\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 5ms/step - loss: 144.5326 - val_loss: 153.1099\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 141.0430 - val_loss: 156.2696\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 140.2399 - val_loss: 148.0688\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 134.7248 - val_loss: 141.3754\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 7ms/step - loss: 131.6981 - val_loss: 139.6783\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 13ms/step - loss: 128.8991 - val_loss: 138.0588\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 125.5744 - val_loss: 135.1412\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 9ms/step - loss: 124.6579 - val_loss: 133.9792\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 10ms/step - loss: 122.9193 - val_loss: 131.4376\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.4934 - val_loss: 129.7953\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.4877 - val_loss: 130.1907\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 13ms/step - loss: 119.0973 - val_loss: 125.9594\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 7ms/step - loss: 115.5444 - val_loss: 124.5685\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 7ms/step - loss: 113.1114 - val_loss: 128.1534\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 12ms/step - loss: 111.4017 - val_loss: 121.4300\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 11ms/step - loss: 108.2214 - val_loss: 121.2599\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.4383 - val_loss: 118.4869\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 5ms/step - loss: 106.0933 - val_loss: 121.9311\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 104.1702 - val_loss: 115.2889\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 102.5572 - val_loss: 114.3489\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 100.6116 - val_loss: 112.9809\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 101.2792 - val_loss: 113.8321\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 95.0121 - val_loss: 105.8934\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 96.6824 - val_loss: 103.1418\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 96.2980 - val_loss: 100.0297\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 91.7810 - val_loss: 98.7471\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 5ms/step - loss: 89.7462 - val_loss: 96.8748\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 88.1600 - val_loss: 95.2561\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 5ms/step - loss: 88.0519 - val_loss: 94.0092\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 7ms/step - loss: 85.0584 - val_loss: 92.5144\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.8880 - val_loss: 92.1205\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 83.6191 - val_loss: 90.3159\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.9229 - val_loss: 89.9157\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.3994 - val_loss: 88.4069\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 81.0776 - val_loss: 87.6856\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 80.1005 - val_loss: 86.2926\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 80.4779 - val_loss: 85.6646\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.6649 - val_loss: 87.9349\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 78.7474 - val_loss: 85.3689\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 77.5642 - val_loss: 84.1121\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.8773 - val_loss: 82.4871\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 5ms/step - loss: 77.0612 - val_loss: 82.0176\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.2134 - val_loss: 83.5093\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.2874 - val_loss: 81.9379\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 5ms/step - loss: 74.6633 - val_loss: 81.7756\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.9400 - val_loss: 90.4492\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 76.4596 - val_loss: 83.2278\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.4524 - val_loss: 78.8822\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 71.8955 - val_loss: 78.9944\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.6291 - val_loss: 86.5393\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.7292 - val_loss: 77.0913\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 7ms/step - loss: 70.3559 - val_loss: 77.5414\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.0533 - val_loss: 77.5213\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 7ms/step - loss: 72.7700 - val_loss: 77.0378\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.8823 - val_loss: 75.8110\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.4985 - val_loss: 77.7727\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.3895 - val_loss: 74.9676\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.5572 - val_loss: 77.1219\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 69.8266 - val_loss: 76.2457\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.0792 - val_loss: 73.6124\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 5ms/step - loss: 67.7594 - val_loss: 74.6651\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 67.7919 - val_loss: 73.5136\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.4206 - val_loss: 72.3823\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.4504 - val_loss: 75.7277\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 67.5586 - val_loss: 79.1320\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 7ms/step - loss: 71.7027 - val_loss: 79.4909\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.8243 - val_loss: 72.9428\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 69.6998 - val_loss: 76.6097\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 65.9563 - val_loss: 73.2727\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 64.5093 - val_loss: 69.0950\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 5ms/step - loss: 63.1606 - val_loss: 68.0812\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 63.6648 - val_loss: 67.9501\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 64.1372 - val_loss: 69.5613\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 5ms/step - loss: 62.5716 - val_loss: 66.8427\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 62.0275 - val_loss: 66.1454\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 61.9423 - val_loss: 67.7541\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 64.0154 - val_loss: 68.1878\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 63.3755 - val_loss: 70.3870\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 62.7884 - val_loss: 65.6187\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 61.0335 - val_loss: 75.8401\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 7ms/step - loss: 64.2972 - val_loss: 67.8387\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 7ms/step - loss: 63.9119 - val_loss: 66.0979\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 60ms/step - loss: 3004.4011 - val_loss: 756.1520\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 10ms/step - loss: 454.3779 - val_loss: 242.8276\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 11ms/step - loss: 250.5240 - val_loss: 205.7751\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 13ms/step - loss: 217.7301 - val_loss: 181.9323\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 200.3815 - val_loss: 172.4196\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 193.5370 - val_loss: 167.1962\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 8ms/step - loss: 185.5243 - val_loss: 163.8009\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 11ms/step - loss: 179.1236 - val_loss: 159.5141\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 13ms/step - loss: 174.5717 - val_loss: 163.0709\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.9335 - val_loss: 155.4238\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 8ms/step - loss: 166.5403 - val_loss: 150.8444\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 7ms/step - loss: 161.7422 - val_loss: 147.0954\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.8735 - val_loss: 148.6680\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 156.1940 - val_loss: 142.5201\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.9522 - val_loss: 140.4122\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 153.1554 - val_loss: 138.4993\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 149.5157 - val_loss: 136.1510\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 147.9314 - val_loss: 138.5037\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 147.9999 - val_loss: 148.5009\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 146.1837 - val_loss: 135.3831\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 144.7146 - val_loss: 132.5727\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 141.7054 - val_loss: 133.4855\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 139.8166 - val_loss: 132.4574\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.2799 - val_loss: 131.5458\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 136.9134 - val_loss: 133.3826\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 136.1801 - val_loss: 134.4967\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 7ms/step - loss: 134.7287 - val_loss: 125.1916\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 5ms/step - loss: 135.4626 - val_loss: 123.1998\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 140.1949 - val_loss: 125.1222\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 7ms/step - loss: 135.2753 - val_loss: 121.3856\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 132.9053 - val_loss: 120.4256\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 5ms/step - loss: 131.8279 - val_loss: 125.4917\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 126.4128 - val_loss: 121.2129\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 7ms/step - loss: 126.0236 - val_loss: 119.4149\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 125.8329 - val_loss: 122.6478\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 123.7935 - val_loss: 117.7504\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.2915 - val_loss: 117.8321\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 122.3777 - val_loss: 116.2431\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 119.5068 - val_loss: 114.5539\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.7912 - val_loss: 122.3704\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 124.1780 - val_loss: 117.6882\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.1742 - val_loss: 113.0147\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 5ms/step - loss: 119.1626 - val_loss: 114.0097\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.7261 - val_loss: 112.2707\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.6995 - val_loss: 111.2316\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.1275 - val_loss: 110.9276\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.4809 - val_loss: 111.2579\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.6024 - val_loss: 111.5781\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.6202 - val_loss: 110.7433\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.9186 - val_loss: 112.5640\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.3824 - val_loss: 108.2246\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.6925 - val_loss: 111.1224\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.2442 - val_loss: 115.0842\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.1897 - val_loss: 107.4362\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.2161 - val_loss: 110.9413\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 107.0390 - val_loss: 106.6852\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 106.1040 - val_loss: 108.0050\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 108.7667 - val_loss: 109.1392\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 7ms/step - loss: 103.9238 - val_loss: 109.7193\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 104.6070 - val_loss: 99.6656\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 102.3733 - val_loss: 98.9749\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 98.8112 - val_loss: 97.1114\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 96.9810 - val_loss: 96.9036\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 7ms/step - loss: 100.6398 - val_loss: 94.7107\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 5ms/step - loss: 94.9555 - val_loss: 94.6373\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 95.8669 - val_loss: 94.1854\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 97.4942 - val_loss: 87.9499\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 90.5672 - val_loss: 87.0702\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 87.8049 - val_loss: 86.4848\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 88.1577 - val_loss: 86.8716\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 7ms/step - loss: 87.6485 - val_loss: 93.9760\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 83.4052 - val_loss: 83.4732\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.5614 - val_loss: 88.5359\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 85.6931 - val_loss: 81.6213\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 7ms/step - loss: 79.9988 - val_loss: 81.9007\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.7423 - val_loss: 80.2266\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 79.7671 - val_loss: 79.7954\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 76.9371 - val_loss: 80.0341\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.6117 - val_loss: 86.3220\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 75.7073 - val_loss: 82.6220\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.1920 - val_loss: 77.6085\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.9187 - val_loss: 78.3011\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.4999 - val_loss: 80.9304\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 7ms/step - loss: 72.5697 - val_loss: 82.9911\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 69.1039 - val_loss: 76.6929\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 69.4481 - val_loss: 75.9640\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.2904 - val_loss: 75.1007\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.1897 - val_loss: 75.3671\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.0239 - val_loss: 75.8123\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.8727 - val_loss: 76.2126\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 70.9299 - val_loss: 75.1740\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.1922 - val_loss: 74.8166\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.1208 - val_loss: 74.3062\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.0555 - val_loss: 74.2542\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.2483 - val_loss: 86.4451\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.4617 - val_loss: 88.1949\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 90.6555 - val_loss: 83.8235\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.6900 - val_loss: 77.7119\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 71.5965 - val_loss: 91.0708\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 7ms/step - loss: 72.2850 - val_loss: 72.5959\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 87ms/step - loss: 55753.3203 - val_loss: 23662.3828\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 15ms/step - loss: 13575.6084 - val_loss: 5360.9888\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 7ms/step - loss: 2543.8835 - val_loss: 616.8015\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 528.3425 - val_loss: 512.1666\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 477.5645 - val_loss: 430.6554\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 429.6503 - val_loss: 407.1338\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 408.1868 - val_loss: 392.5026\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 7ms/step - loss: 394.3863 - val_loss: 379.8612\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 383.4560 - val_loss: 369.2993\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 7ms/step - loss: 374.3140 - val_loss: 360.8087\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 365.7564 - val_loss: 353.4936\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 7ms/step - loss: 357.4227 - val_loss: 345.8105\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 350.0875 - val_loss: 339.5921\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 342.1205 - val_loss: 331.8534\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 335.7460 - val_loss: 325.4345\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 329.8304 - val_loss: 321.0616\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 325.0948 - val_loss: 314.1148\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 318.3552 - val_loss: 311.1897\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 312.4035 - val_loss: 304.0898\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 5ms/step - loss: 310.7431 - val_loss: 298.3120\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 301.5978 - val_loss: 295.4263\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 296.4750 - val_loss: 290.7997\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 292.7052 - val_loss: 286.5610\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 288.1408 - val_loss: 284.3747\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 284.2163 - val_loss: 278.5329\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 7ms/step - loss: 279.3378 - val_loss: 276.9356\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 275.3445 - val_loss: 272.5694\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 7ms/step - loss: 271.7758 - val_loss: 268.8967\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 268.1177 - val_loss: 264.9688\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 264.5715 - val_loss: 262.1605\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 260.8167 - val_loss: 258.4002\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 5ms/step - loss: 257.2704 - val_loss: 257.9138\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 253.5524 - val_loss: 253.4515\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 7ms/step - loss: 251.7452 - val_loss: 254.6996\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 247.1455 - val_loss: 246.1374\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 7ms/step - loss: 243.0259 - val_loss: 245.5553\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 5ms/step - loss: 239.6431 - val_loss: 239.6250\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 236.9899 - val_loss: 240.9612\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 233.9762 - val_loss: 235.6390\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 230.9955 - val_loss: 234.6156\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 228.9012 - val_loss: 227.8593\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 5ms/step - loss: 224.7107 - val_loss: 225.0306\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 221.6655 - val_loss: 222.9268\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 218.6530 - val_loss: 219.5272\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 215.0212 - val_loss: 217.4159\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 212.4327 - val_loss: 214.7178\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 209.7521 - val_loss: 213.7480\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 206.5523 - val_loss: 208.8341\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 204.6270 - val_loss: 211.6986\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 200.8338 - val_loss: 204.6185\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 198.5087 - val_loss: 202.2138\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 197.2922 - val_loss: 199.2394\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 5ms/step - loss: 195.7448 - val_loss: 203.0014\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 193.5561 - val_loss: 199.8881\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 188.8810 - val_loss: 193.1091\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 187.1340 - val_loss: 193.5221\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 184.3279 - val_loss: 189.0648\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 182.8747 - val_loss: 186.6593\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 181.4385 - val_loss: 187.6179\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 180.2694 - val_loss: 186.0031\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.3273 - val_loss: 180.6502\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 174.0097 - val_loss: 178.7525\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 174.5889 - val_loss: 176.8749\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 170.0695 - val_loss: 177.8916\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 170.3310 - val_loss: 179.2129\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 167.2598 - val_loss: 170.7517\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 5ms/step - loss: 164.5800 - val_loss: 179.4938\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 5ms/step - loss: 164.1409 - val_loss: 174.0996\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.3025 - val_loss: 165.1539\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 157.8826 - val_loss: 162.9697\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.6479 - val_loss: 163.6360\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 153.3156 - val_loss: 159.0218\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 152.2306 - val_loss: 157.8020\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 152.3172 - val_loss: 155.7492\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.6157 - val_loss: 153.5621\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 147.5247 - val_loss: 151.9788\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 145.7688 - val_loss: 149.8736\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 143.9833 - val_loss: 147.8737\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 141.1632 - val_loss: 146.0500\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 140.7574 - val_loss: 144.9194\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.0907 - val_loss: 144.6701\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 136.5074 - val_loss: 142.7256\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 7ms/step - loss: 135.0079 - val_loss: 140.5331\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 132.6736 - val_loss: 137.7927\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 7ms/step - loss: 130.8367 - val_loss: 138.2110\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 13ms/step - loss: 130.1172 - val_loss: 135.1771\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 128.8701 - val_loss: 133.3354\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 127.1641 - val_loss: 132.1278\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 13ms/step - loss: 128.2859 - val_loss: 131.4424\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 7ms/step - loss: 124.6001 - val_loss: 130.5588\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.7208 - val_loss: 130.4812\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.5988 - val_loss: 130.9601\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 8ms/step - loss: 121.1774 - val_loss: 126.2894\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 11ms/step - loss: 121.3273 - val_loss: 124.4185\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.3891 - val_loss: 123.6370\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 5ms/step - loss: 117.9184 - val_loss: 122.6157\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.1891 - val_loss: 126.1712\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.9509 - val_loss: 120.8145\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.3763 - val_loss: 119.7134\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.9214 - val_loss: 120.5630\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 58ms/step - loss: 16816.4180 - val_loss: 10779.9590\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 7362.5049 - val_loss: 5058.0830\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 5ms/step - loss: 3658.9775 - val_loss: 2793.4500\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 2149.8728 - val_loss: 1770.1808\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 1385.6664 - val_loss: 1143.7009\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 7ms/step - loss: 862.3105 - val_loss: 672.0161\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 525.8334 - val_loss: 447.3544\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 392.5121 - val_loss: 365.2666\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 344.2451 - val_loss: 332.0505\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 324.9059 - val_loss: 316.2419\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 315.5364 - val_loss: 307.5123\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 310.0719 - val_loss: 303.7322\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 305.6996 - val_loss: 299.5856\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 301.8700 - val_loss: 296.8614\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 298.4781 - val_loss: 293.1858\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 295.8026 - val_loss: 291.5953\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 293.1213 - val_loss: 286.4352\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 289.9209 - val_loss: 284.8253\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 286.8430 - val_loss: 282.4360\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 283.5233 - val_loss: 278.8917\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 280.0424 - val_loss: 276.6533\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 277.6601 - val_loss: 274.8872\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 274.8773 - val_loss: 272.8680\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 270.0683 - val_loss: 267.5218\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 266.5664 - val_loss: 266.0300\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 5ms/step - loss: 263.4701 - val_loss: 263.5215\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 7ms/step - loss: 259.6788 - val_loss: 259.5849\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 256.3351 - val_loss: 257.5871\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 253.4680 - val_loss: 255.7826\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 249.6305 - val_loss: 250.3177\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 245.4992 - val_loss: 248.0078\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 5ms/step - loss: 242.5336 - val_loss: 244.0326\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 240.6571 - val_loss: 243.4426\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 234.2446 - val_loss: 237.4340\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 7ms/step - loss: 230.3779 - val_loss: 235.8815\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 5ms/step - loss: 227.8121 - val_loss: 230.2257\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 223.1345 - val_loss: 227.6863\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 218.8690 - val_loss: 223.6240\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 7ms/step - loss: 215.0662 - val_loss: 222.0921\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 210.1096 - val_loss: 217.2199\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 206.7096 - val_loss: 214.4455\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 7ms/step - loss: 202.6584 - val_loss: 210.1061\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 199.8183 - val_loss: 206.4862\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 196.5915 - val_loss: 205.2328\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 191.7593 - val_loss: 202.4520\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 188.6783 - val_loss: 195.9789\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 184.2253 - val_loss: 195.8387\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 5ms/step - loss: 180.4963 - val_loss: 191.4505\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 176.9153 - val_loss: 187.9805\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 173.0770 - val_loss: 181.8895\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 169.5820 - val_loss: 179.2222\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.0937 - val_loss: 175.1362\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.8310 - val_loss: 172.4089\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 160.3854 - val_loss: 171.2539\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.5225 - val_loss: 166.0848\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 151.4644 - val_loss: 161.4657\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 148.6402 - val_loss: 162.9196\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 145.5523 - val_loss: 159.1883\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 142.4424 - val_loss: 151.7356\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 7ms/step - loss: 137.9360 - val_loss: 149.7068\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.6955 - val_loss: 144.9617\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 130.7631 - val_loss: 145.7012\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 128.4977 - val_loss: 138.8483\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 12ms/step - loss: 123.9593 - val_loss: 134.8463\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.3026 - val_loss: 132.4408\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 7ms/step - loss: 118.1658 - val_loss: 128.4099\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.5377 - val_loss: 125.9099\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 5ms/step - loss: 111.4262 - val_loss: 126.7170\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 5ms/step - loss: 109.0982 - val_loss: 119.3478\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 105.3956 - val_loss: 115.9341\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 7ms/step - loss: 102.1555 - val_loss: 116.5157\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 13ms/step - loss: 99.5873 - val_loss: 110.1804\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 97.1619 - val_loss: 107.2377\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 94.4693 - val_loss: 108.2090\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 92.9862 - val_loss: 101.3019\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 15ms/step - loss: 89.7796 - val_loss: 98.3951\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 87.7174 - val_loss: 96.8614\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 5ms/step - loss: 86.1470 - val_loss: 95.0851\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 5ms/step - loss: 83.3751 - val_loss: 92.8372\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 82.2328 - val_loss: 91.0276\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.4516 - val_loss: 93.6338\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.6576 - val_loss: 90.4996\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.5770 - val_loss: 88.1593\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 77.9093 - val_loss: 86.8712\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 7ms/step - loss: 75.7914 - val_loss: 86.9110\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 5ms/step - loss: 75.5992 - val_loss: 85.4449\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 74.5174 - val_loss: 84.5944\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 5ms/step - loss: 73.5063 - val_loss: 84.8166\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 7ms/step - loss: 72.5252 - val_loss: 83.7114\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 71.2875 - val_loss: 83.5925\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.7890 - val_loss: 82.2993\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 70.9132 - val_loss: 85.2987\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 5ms/step - loss: 70.1133 - val_loss: 80.9858\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 5ms/step - loss: 68.5501 - val_loss: 82.1421\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.3323 - val_loss: 80.6194\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 66.4766 - val_loss: 79.5188\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 66.0698 - val_loss: 78.8309\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 65.1459 - val_loss: 79.8206\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 64.1786 - val_loss: 78.2828\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 65.3158 - val_loss: 78.8236\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 56ms/step - loss: 257902.0938 - val_loss: 150321.8594\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 91694.4297 - val_loss: 30610.7793\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 5ms/step - loss: 10753.1445 - val_loss: 1570.8258\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 7ms/step - loss: 1782.4414 - val_loss: 1515.8929\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 5ms/step - loss: 1374.8180 - val_loss: 1209.3910\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 1252.8580 - val_loss: 1132.9325\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 1158.8374 - val_loss: 1049.6968\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1066.7887 - val_loss: 956.0120\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 961.0557 - val_loss: 857.4974\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 7ms/step - loss: 847.8195 - val_loss: 733.4880\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 739.1609 - val_loss: 619.9222\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 642.9948 - val_loss: 549.5248\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 568.2818 - val_loss: 477.4867\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 5ms/step - loss: 502.4251 - val_loss: 427.7732\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 5ms/step - loss: 449.1958 - val_loss: 378.3286\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 408.0976 - val_loss: 349.6619\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 366.4754 - val_loss: 309.8394\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 336.6874 - val_loss: 288.7355\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 312.9753 - val_loss: 273.1626\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 7ms/step - loss: 294.4229 - val_loss: 261.6733\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 280.6091 - val_loss: 251.3457\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 269.3934 - val_loss: 242.3593\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 260.4949 - val_loss: 238.0189\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 247.3240 - val_loss: 228.1613\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 239.9348 - val_loss: 224.6385\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 233.0166 - val_loss: 221.0015\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 225.1620 - val_loss: 209.9609\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 218.6725 - val_loss: 204.7552\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 5ms/step - loss: 214.4221 - val_loss: 198.1640\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 208.1883 - val_loss: 193.4686\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 200.5557 - val_loss: 195.8109\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 197.5422 - val_loss: 184.8571\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 192.3498 - val_loss: 185.1057\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 187.8632 - val_loss: 177.2516\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 184.2984 - val_loss: 180.9847\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 180.5746 - val_loss: 170.4729\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 5ms/step - loss: 179.0648 - val_loss: 170.5653\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 173.1865 - val_loss: 165.4614\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 170.2057 - val_loss: 161.7873\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 169.2837 - val_loss: 159.0180\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 7ms/step - loss: 166.2745 - val_loss: 157.9562\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 160.1837 - val_loss: 163.4682\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 161.9532 - val_loss: 159.9206\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.0846 - val_loss: 148.7302\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 7ms/step - loss: 153.3596 - val_loss: 147.2497\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 5ms/step - loss: 151.4165 - val_loss: 146.8199\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.0366 - val_loss: 142.5771\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 146.1926 - val_loss: 139.7788\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 148.3197 - val_loss: 141.0021\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 141.9088 - val_loss: 135.6084\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 140.8044 - val_loss: 132.4797\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 8ms/step - loss: 137.2441 - val_loss: 132.5014\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 5ms/step - loss: 135.8029 - val_loss: 128.0930\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.2468 - val_loss: 127.8531\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 130.9198 - val_loss: 131.0040\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 129.8308 - val_loss: 123.2734\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 7ms/step - loss: 127.0870 - val_loss: 121.6308\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 127.1043 - val_loss: 119.1015\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 7ms/step - loss: 123.8713 - val_loss: 118.9356\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 12ms/step - loss: 122.6948 - val_loss: 115.3212\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.5232 - val_loss: 117.2425\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 7ms/step - loss: 119.4750 - val_loss: 116.6302\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 8ms/step - loss: 117.3498 - val_loss: 111.2134\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 10ms/step - loss: 115.5328 - val_loss: 111.6307\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.3315 - val_loss: 113.3109\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.4432 - val_loss: 110.7305\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.3072 - val_loss: 107.9197\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.9317 - val_loss: 104.9074\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.0467 - val_loss: 107.1207\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.4963 - val_loss: 102.6931\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 108.4413 - val_loss: 106.1187\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 5ms/step - loss: 109.3920 - val_loss: 101.0450\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 107.5946 - val_loss: 102.4467\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 105.9283 - val_loss: 100.8569\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 102.9471 - val_loss: 97.4311\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 104.4468 - val_loss: 96.9511\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 103.2725 - val_loss: 100.6654\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 103.4413 - val_loss: 94.9167\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 100.7083 - val_loss: 95.8924\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 7ms/step - loss: 100.1698 - val_loss: 93.6646\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 5ms/step - loss: 98.5033 - val_loss: 92.7643\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 5ms/step - loss: 98.4325 - val_loss: 94.7586\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 95.8471 - val_loss: 92.0749\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 95.7458 - val_loss: 88.0157\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 93.6525 - val_loss: 89.1057\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 5ms/step - loss: 97.4408 - val_loss: 88.2579\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 7ms/step - loss: 94.5350 - val_loss: 88.5650\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 89.8206 - val_loss: 84.1389\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 89.9251 - val_loss: 84.2532\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 89.1816 - val_loss: 84.7943\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 89.4067 - val_loss: 82.5090\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 87.6751 - val_loss: 85.5170\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 87.9855 - val_loss: 84.5927\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 7ms/step - loss: 87.1021 - val_loss: 86.3288\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 87.1301 - val_loss: 81.0483\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 5ms/step - loss: 85.7122 - val_loss: 86.3829\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 85.7008 - val_loss: 84.3926\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 85.0251 - val_loss: 81.1104\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 83.9842 - val_loss: 85.6449\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 86.8833 - val_loss: 81.0675\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 58ms/step - loss: 18386.0371 - val_loss: 4260.3545\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 1661.3416 - val_loss: 635.9751\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 5ms/step - loss: 608.8148 - val_loss: 558.4969\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 510.0804 - val_loss: 483.2705\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 442.9002 - val_loss: 434.6431\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 398.8985 - val_loss: 395.6392\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 366.9464 - val_loss: 365.0578\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 336.8931 - val_loss: 346.5790\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 317.5349 - val_loss: 329.2964\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 301.5887 - val_loss: 316.4781\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 288.5361 - val_loss: 306.1167\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 278.0943 - val_loss: 296.1054\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 269.1185 - val_loss: 288.1365\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 260.4997 - val_loss: 279.3401\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 252.1237 - val_loss: 271.9041\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 244.4454 - val_loss: 264.0208\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 5ms/step - loss: 235.3325 - val_loss: 254.0289\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 218.0944 - val_loss: 231.0157\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 202.5318 - val_loss: 214.8705\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 5ms/step - loss: 195.6872 - val_loss: 209.1770\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 5ms/step - loss: 190.1531 - val_loss: 205.5825\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 188.0084 - val_loss: 205.5213\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 184.7609 - val_loss: 204.7847\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 7ms/step - loss: 181.6738 - val_loss: 202.0270\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 180.0706 - val_loss: 195.3183\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.8651 - val_loss: 193.7030\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 173.9707 - val_loss: 191.1119\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 172.2888 - val_loss: 189.7552\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 167.8191 - val_loss: 190.5417\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 168.1438 - val_loss: 185.1565\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 3ms/step - loss: 165.0799 - val_loss: 184.2172\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.3286 - val_loss: 182.5474\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 7ms/step - loss: 161.7744 - val_loss: 181.2371\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.9907 - val_loss: 178.4754\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.9210 - val_loss: 175.4100\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.7578 - val_loss: 173.6821\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 12ms/step - loss: 156.2697 - val_loss: 172.2091\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.3714 - val_loss: 170.7610\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 7ms/step - loss: 153.4251 - val_loss: 168.7209\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 151.5615 - val_loss: 167.3863\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 150.4623 - val_loss: 165.9995\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 8ms/step - loss: 148.9512 - val_loss: 164.5452\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 12ms/step - loss: 148.5641 - val_loss: 163.2450\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 13ms/step - loss: 147.4599 - val_loss: 161.2425\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 9ms/step - loss: 146.5897 - val_loss: 159.8443\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 9ms/step - loss: 144.4576 - val_loss: 157.9405\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 5ms/step - loss: 143.8774 - val_loss: 156.3455\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 8ms/step - loss: 141.7625 - val_loss: 154.3602\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 5ms/step - loss: 140.4145 - val_loss: 154.2330\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 5ms/step - loss: 137.8974 - val_loss: 149.9084\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 5ms/step - loss: 136.4932 - val_loss: 147.6277\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.6283 - val_loss: 145.3652\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 133.0941 - val_loss: 143.7822\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 7ms/step - loss: 131.5495 - val_loss: 144.6707\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 5ms/step - loss: 130.1422 - val_loss: 146.3069\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 7ms/step - loss: 130.4039 - val_loss: 138.9997\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 3ms/step - loss: 128.4066 - val_loss: 133.5990\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 124.1873 - val_loss: 135.0754\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.5364 - val_loss: 128.1492\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.9817 - val_loss: 126.9560\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 119.2919 - val_loss: 124.4749\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 7ms/step - loss: 118.7514 - val_loss: 124.0853\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 5ms/step - loss: 116.0083 - val_loss: 121.2090\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.0196 - val_loss: 121.2198\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.5143 - val_loss: 118.5642\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.2289 - val_loss: 117.7363\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.6061 - val_loss: 117.0623\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.4164 - val_loss: 117.0904\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.9972 - val_loss: 115.3770\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.9636 - val_loss: 113.9934\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 5ms/step - loss: 111.0633 - val_loss: 114.9573\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 5ms/step - loss: 108.3377 - val_loss: 113.1148\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 108.2656 - val_loss: 112.1551\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 5ms/step - loss: 106.1164 - val_loss: 110.6650\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.0299 - val_loss: 110.9180\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 104.7827 - val_loss: 108.0267\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 105.2042 - val_loss: 106.8363\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 103.7275 - val_loss: 106.1270\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 7ms/step - loss: 102.6353 - val_loss: 106.1419\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 5ms/step - loss: 101.6915 - val_loss: 107.4125\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 103.4916 - val_loss: 107.9769\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 99.5191 - val_loss: 102.8106\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 98.9128 - val_loss: 101.4713\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 98.2253 - val_loss: 100.2283\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 98.6654 - val_loss: 99.5949\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 97.4565 - val_loss: 99.5323\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 96.0978 - val_loss: 98.1445\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 95.1326 - val_loss: 96.5273\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 7ms/step - loss: 94.7226 - val_loss: 96.0911\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 94.4502 - val_loss: 94.3226\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 92.5981 - val_loss: 93.1382\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 91.5737 - val_loss: 93.5723\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 91.6359 - val_loss: 91.0073\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 89.8490 - val_loss: 90.2032\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 88.9410 - val_loss: 89.7165\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 88.5769 - val_loss: 88.9328\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 86.7769 - val_loss: 87.2451\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 86.7032 - val_loss: 87.6043\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 86.4740 - val_loss: 87.7983\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 86.1709 - val_loss: 84.7244\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 56ms/step - loss: 11936.5352 - val_loss: 3563.9438\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 1852.9481 - val_loss: 900.4898\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 633.4800 - val_loss: 448.8179\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 380.6534 - val_loss: 354.4907\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 351.4665 - val_loss: 339.4931\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 337.8313 - val_loss: 327.3024\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 327.0144 - val_loss: 316.8564\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 316.7898 - val_loss: 306.0478\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 5ms/step - loss: 306.6339 - val_loss: 297.7891\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 296.2814 - val_loss: 286.5967\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 287.2477 - val_loss: 275.9286\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 276.5653 - val_loss: 264.5413\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 7ms/step - loss: 264.2347 - val_loss: 251.2029\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 7ms/step - loss: 250.7155 - val_loss: 235.8082\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 235.0548 - val_loss: 224.8396\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 225.8641 - val_loss: 218.1071\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 218.5986 - val_loss: 213.2572\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 12ms/step - loss: 211.7208 - val_loss: 211.5823\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 206.9717 - val_loss: 203.3725\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 201.4957 - val_loss: 199.1076\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 7ms/step - loss: 196.3272 - val_loss: 195.6502\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 7ms/step - loss: 192.8561 - val_loss: 194.7696\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 187.4596 - val_loss: 188.6571\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 182.7338 - val_loss: 185.2401\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 178.6650 - val_loss: 183.2381\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 175.2526 - val_loss: 185.3499\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 173.2646 - val_loss: 182.6269\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 14ms/step - loss: 171.2631 - val_loss: 177.6336\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 11ms/step - loss: 166.2526 - val_loss: 171.9149\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 164.0479 - val_loss: 174.7130\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.3149 - val_loss: 168.0124\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.8328 - val_loss: 166.8202\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 7ms/step - loss: 156.3040 - val_loss: 167.0077\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 5ms/step - loss: 157.4203 - val_loss: 163.9649\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.0378 - val_loss: 161.4803\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 150.9297 - val_loss: 159.7351\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 151.6062 - val_loss: 158.0367\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.9982 - val_loss: 157.6803\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 151.3817 - val_loss: 157.6257\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 146.3835 - val_loss: 154.5668\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 7ms/step - loss: 145.8365 - val_loss: 154.7047\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 5ms/step - loss: 143.8864 - val_loss: 152.4769\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 142.7550 - val_loss: 151.2908\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 141.4455 - val_loss: 150.4031\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 140.8518 - val_loss: 149.4643\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 140.0975 - val_loss: 149.0431\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 140.0540 - val_loss: 149.3479\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 140.1416 - val_loss: 148.7870\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 7ms/step - loss: 138.0208 - val_loss: 147.1527\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 136.9286 - val_loss: 148.6624\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 137.1703 - val_loss: 146.5004\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 136.3675 - val_loss: 151.6271\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.4083 - val_loss: 145.9951\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 138.1373 - val_loss: 143.1944\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.4497 - val_loss: 143.1529\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 133.3348 - val_loss: 141.9607\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 5ms/step - loss: 133.3433 - val_loss: 143.4540\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 136.2085 - val_loss: 143.2335\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 133.0399 - val_loss: 141.7971\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 131.9223 - val_loss: 142.5195\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 132.7043 - val_loss: 139.1490\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 131.1935 - val_loss: 138.1555\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 129.0068 - val_loss: 136.2506\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 129.2255 - val_loss: 135.7648\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 5ms/step - loss: 128.2076 - val_loss: 135.3368\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 127.1157 - val_loss: 134.0224\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 126.1451 - val_loss: 135.5258\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 128.1118 - val_loss: 134.4878\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 127.6992 - val_loss: 133.7830\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 123.3413 - val_loss: 132.0518\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 124.3935 - val_loss: 133.5483\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.6533 - val_loss: 129.4090\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 7ms/step - loss: 121.6344 - val_loss: 127.7875\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 5ms/step - loss: 120.9775 - val_loss: 127.1482\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.2531 - val_loss: 126.7429\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.7613 - val_loss: 126.9444\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 7ms/step - loss: 122.1277 - val_loss: 134.3493\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 120.7621 - val_loss: 124.8317\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.2078 - val_loss: 130.2005\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.9181 - val_loss: 122.5391\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.4021 - val_loss: 122.8072\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.4863 - val_loss: 121.5154\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.4374 - val_loss: 118.9771\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.1026 - val_loss: 117.8868\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.4438 - val_loss: 115.6934\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.2846 - val_loss: 113.7998\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.3089 - val_loss: 119.1472\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 108.3095 - val_loss: 110.3958\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 5ms/step - loss: 106.7691 - val_loss: 108.7070\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 104.0105 - val_loss: 108.5218\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 103.1195 - val_loss: 107.7976\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 103.0880 - val_loss: 105.6175\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 7ms/step - loss: 101.0618 - val_loss: 103.6823\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 99.7384 - val_loss: 103.0633\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 99.0181 - val_loss: 112.2805\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 105.3485 - val_loss: 102.5212\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 100.7059 - val_loss: 103.5951\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 99.4482 - val_loss: 101.7691\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 98.4974 - val_loss: 100.7611\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 97.4467 - val_loss: 100.9674\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 74ms/step - loss: 3897.4216 - val_loss: 2095.1245\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 19ms/step - loss: 1805.3219 - val_loss: 1680.2346\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 13ms/step - loss: 1593.3046 - val_loss: 1627.8158\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 8ms/step - loss: 1559.4813 - val_loss: 1614.1315\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 7ms/step - loss: 1542.8993 - val_loss: 1606.2085\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 12ms/step - loss: 1531.3784 - val_loss: 1600.2833\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 1522.9622 - val_loss: 1594.9226\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1516.4232 - val_loss: 1589.8993\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 1511.2051 - val_loss: 1585.0853\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 1506.0227 - val_loss: 1580.2305\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 5ms/step - loss: 1501.0034 - val_loss: 1575.2129\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 3ms/step - loss: 1495.7268 - val_loss: 1570.0333\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 1490.5826 - val_loss: 1564.6091\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 1485.0919 - val_loss: 1559.0060\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 1479.5626 - val_loss: 1553.1730\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 7ms/step - loss: 1473.8557 - val_loss: 1547.1401\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 1467.9188 - val_loss: 1540.9691\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 1461.8276 - val_loss: 1534.6414\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 1455.5466 - val_loss: 1528.0875\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1449.0808 - val_loss: 1521.3083\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 7ms/step - loss: 1442.4062 - val_loss: 1514.3400\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 1435.5884 - val_loss: 1507.1901\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 1428.5151 - val_loss: 1499.9059\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 1421.3047 - val_loss: 1492.4083\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 1413.9083 - val_loss: 1484.7263\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 1406.3093 - val_loss: 1476.9205\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 1398.6104 - val_loss: 1468.7981\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 1390.6934 - val_loss: 1460.5171\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 3ms/step - loss: 1382.5992 - val_loss: 1452.1124\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 7ms/step - loss: 1374.3730 - val_loss: 1443.4915\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 1365.9343 - val_loss: 1434.6962\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 1357.3323 - val_loss: 1425.7229\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 1348.6105 - val_loss: 1416.4846\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 1339.5593 - val_loss: 1407.2689\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 1330.5216 - val_loss: 1397.6591\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 1321.2213 - val_loss: 1387.9879\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 1311.7286 - val_loss: 1378.1489\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 1302.0404 - val_loss: 1368.1010\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 1292.2380 - val_loss: 1357.8240\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 1282.2124 - val_loss: 1347.4626\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 5ms/step - loss: 1272.1404 - val_loss: 1336.7727\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 1261.8165 - val_loss: 1326.1083\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 1251.3798 - val_loss: 1315.1821\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 1240.7283 - val_loss: 1304.1515\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 5ms/step - loss: 1230.0001 - val_loss: 1292.8087\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 1218.9956 - val_loss: 1281.4336\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 1207.8698 - val_loss: 1269.9216\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 5ms/step - loss: 1196.7273 - val_loss: 1257.9943\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 5ms/step - loss: 1185.2404 - val_loss: 1246.1254\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 1173.6930 - val_loss: 1234.1207\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 1162.0587 - val_loss: 1221.9531\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 1150.2017 - val_loss: 1209.6932\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 1138.2435 - val_loss: 1197.2821\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 1126.2074 - val_loss: 1184.6306\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 1113.9885 - val_loss: 1171.7267\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 1101.5358 - val_loss: 1158.9601\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 1089.1018 - val_loss: 1146.1371\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 1076.6212 - val_loss: 1132.9761\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 1064.0212 - val_loss: 1119.8075\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 7ms/step - loss: 1051.3053 - val_loss: 1106.5393\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 7ms/step - loss: 1038.4900 - val_loss: 1093.2493\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 1025.6649 - val_loss: 1079.7544\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 1012.6984 - val_loss: 1066.0592\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 999.5571 - val_loss: 1052.5315\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 986.4329 - val_loss: 1038.9685\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 973.3548 - val_loss: 1025.1737\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 960.0829 - val_loss: 1011.3867\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 946.9424 - val_loss: 997.3536\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 933.5298 - val_loss: 983.8539\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 920.4163 - val_loss: 969.9381\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 907.1796 - val_loss: 955.9579\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 893.7951 - val_loss: 942.1589\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 880.5856 - val_loss: 928.2726\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 867.2751 - val_loss: 914.4985\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 854.0899 - val_loss: 900.7366\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 840.8994 - val_loss: 887.0254\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 827.8398 - val_loss: 873.1896\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 814.6957 - val_loss: 859.4042\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 801.5735 - val_loss: 845.9161\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 788.6747 - val_loss: 832.3426\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 775.7615 - val_loss: 818.7726\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 762.8892 - val_loss: 805.3403\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 750.0871 - val_loss: 792.1111\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 7ms/step - loss: 737.4726 - val_loss: 778.7401\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 724.9003 - val_loss: 765.5041\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 7ms/step - loss: 712.3854 - val_loss: 752.4816\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 699.9913 - val_loss: 739.5543\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 687.7330 - val_loss: 726.7398\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 675.6959 - val_loss: 713.9807\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 663.6140 - val_loss: 701.6906\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 7ms/step - loss: 652.0112 - val_loss: 689.0807\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 640.2535 - val_loss: 676.9406\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 628.8455 - val_loss: 664.8642\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 617.5017 - val_loss: 652.9345\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 606.2744 - val_loss: 641.1503\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 595.2991 - val_loss: 629.3666\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 584.3856 - val_loss: 618.0344\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 573.7012 - val_loss: 606.8138\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 13ms/step - loss: 563.2357 - val_loss: 595.7668\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 7ms/step - loss: 552.8416 - val_loss: 585.0358\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 99ms/step - loss: 120243.2969 - val_loss: 10264.0684\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 3342.2139 - val_loss: 2344.9009\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 1857.3264 - val_loss: 1085.9019\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 1214.7528 - val_loss: 1001.0881\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 1097.3621 - val_loss: 894.4039\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 996.2589 - val_loss: 797.4857\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 7ms/step - loss: 905.2813 - val_loss: 738.2802\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 841.9620 - val_loss: 694.1526\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 781.7677 - val_loss: 651.9597\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 724.8361 - val_loss: 611.4800\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 671.0140 - val_loss: 566.6853\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 612.2845 - val_loss: 526.9027\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 7ms/step - loss: 563.9614 - val_loss: 493.2422\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 522.0905 - val_loss: 465.5631\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 483.7264 - val_loss: 437.7821\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 452.0221 - val_loss: 412.5521\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 7ms/step - loss: 421.4299 - val_loss: 394.2126\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 397.8087 - val_loss: 373.2595\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 374.9864 - val_loss: 357.9157\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 7ms/step - loss: 355.6632 - val_loss: 344.0886\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 339.1690 - val_loss: 329.5595\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 5ms/step - loss: 323.7822 - val_loss: 321.1782\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 314.1874 - val_loss: 312.4283\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 304.6027 - val_loss: 301.5217\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 294.9601 - val_loss: 297.9380\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 7ms/step - loss: 286.0984 - val_loss: 290.3287\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 280.5563 - val_loss: 281.1504\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 271.8489 - val_loss: 275.6490\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 266.0350 - val_loss: 270.6274\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 259.7216 - val_loss: 272.1577\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 7ms/step - loss: 255.5963 - val_loss: 268.2268\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 254.4690 - val_loss: 258.8857\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 249.5918 - val_loss: 256.0955\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 244.7787 - val_loss: 252.2445\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 241.6908 - val_loss: 249.6479\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 238.4349 - val_loss: 247.3639\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 235.9210 - val_loss: 244.4124\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 232.1803 - val_loss: 244.3790\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 7ms/step - loss: 229.2466 - val_loss: 239.3033\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 226.5242 - val_loss: 242.0565\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 226.8630 - val_loss: 238.1971\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 223.2070 - val_loss: 232.6177\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 222.2849 - val_loss: 230.1382\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 219.7234 - val_loss: 227.9424\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 216.7376 - val_loss: 226.3866\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 215.9032 - val_loss: 223.5144\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 211.9303 - val_loss: 227.4791\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 5ms/step - loss: 209.5096 - val_loss: 221.8739\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 209.1713 - val_loss: 219.3248\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 205.8546 - val_loss: 217.6589\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 205.8035 - val_loss: 215.2122\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 202.8768 - val_loss: 212.5617\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 201.7282 - val_loss: 210.0063\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 198.3400 - val_loss: 208.0300\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 198.4486 - val_loss: 206.3047\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 195.1679 - val_loss: 204.4854\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 7ms/step - loss: 193.2836 - val_loss: 203.0488\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 192.6285 - val_loss: 205.1559\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 193.5889 - val_loss: 199.1420\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 187.6495 - val_loss: 197.9307\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 186.7416 - val_loss: 197.6787\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 184.9778 - val_loss: 195.8288\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 181.2067 - val_loss: 194.5126\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 184.6611 - val_loss: 190.5213\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 7ms/step - loss: 178.7874 - val_loss: 193.3472\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 5ms/step - loss: 178.9770 - val_loss: 187.2474\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 175.5311 - val_loss: 191.7932\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 177.6621 - val_loss: 188.1957\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 173.6572 - val_loss: 182.9170\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.4068 - val_loss: 181.1840\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 169.4639 - val_loss: 197.6651\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 173.9012 - val_loss: 187.3393\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 7ms/step - loss: 167.0947 - val_loss: 177.9333\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.3814 - val_loss: 178.3559\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 7ms/step - loss: 164.8976 - val_loss: 175.6307\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.2681 - val_loss: 172.9608\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.7417 - val_loss: 172.3674\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.6241 - val_loss: 175.9638\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.6799 - val_loss: 170.4975\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 7ms/step - loss: 158.0424 - val_loss: 173.1841\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 12ms/step - loss: 156.7945 - val_loss: 168.6466\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.7035 - val_loss: 165.0005\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 155.1340 - val_loss: 165.0892\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.4310 - val_loss: 162.4514\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 14ms/step - loss: 150.8179 - val_loss: 161.7357\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 12ms/step - loss: 150.3489 - val_loss: 164.0896\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.2510 - val_loss: 162.9196\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 13ms/step - loss: 146.8288 - val_loss: 157.6438\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 5ms/step - loss: 149.3565 - val_loss: 165.2618\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 146.7459 - val_loss: 163.7767\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 5ms/step - loss: 146.1177 - val_loss: 160.6427\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 142.8049 - val_loss: 154.0754\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 141.9501 - val_loss: 157.5263\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 143.2149 - val_loss: 150.5620\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 140.5957 - val_loss: 149.9770\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.6189 - val_loss: 148.9995\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 139.6740 - val_loss: 152.3204\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 136.7991 - val_loss: 147.6155\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 5ms/step - loss: 136.9002 - val_loss: 158.9285\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 135.2228 - val_loss: 156.0523\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 59ms/step - loss: 1158.8141 - val_loss: 678.5776\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 583.9033 - val_loss: 490.1993\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 481.5333 - val_loss: 423.9181\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 411.4184 - val_loss: 363.7131\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 353.4412 - val_loss: 322.9871\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 317.1464 - val_loss: 300.4394\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 291.0854 - val_loss: 279.9134\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 274.6108 - val_loss: 260.9337\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 255.5779 - val_loss: 246.8337\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 7ms/step - loss: 238.9931 - val_loss: 238.2125\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 5ms/step - loss: 227.0647 - val_loss: 235.0559\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 5ms/step - loss: 220.1853 - val_loss: 220.1054\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 207.0872 - val_loss: 206.0326\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 196.2118 - val_loss: 197.2409\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 187.5914 - val_loss: 188.7275\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 179.3726 - val_loss: 186.9718\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 7ms/step - loss: 172.3495 - val_loss: 175.6574\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 7ms/step - loss: 166.8371 - val_loss: 169.5742\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 5ms/step - loss: 160.9966 - val_loss: 163.6719\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.9533 - val_loss: 159.4226\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.9891 - val_loss: 157.7411\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 145.7054 - val_loss: 149.9455\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 142.8959 - val_loss: 146.4714\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 7ms/step - loss: 137.8797 - val_loss: 146.3484\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 135.5137 - val_loss: 140.6289\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 7ms/step - loss: 131.3874 - val_loss: 136.8717\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 129.3544 - val_loss: 134.5786\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 7ms/step - loss: 128.1473 - val_loss: 132.6030\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 5ms/step - loss: 125.2919 - val_loss: 130.1014\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 123.8302 - val_loss: 128.0809\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.4689 - val_loss: 125.8718\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 121.3080 - val_loss: 128.4643\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.0542 - val_loss: 125.0208\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 5ms/step - loss: 118.2331 - val_loss: 122.3846\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.5134 - val_loss: 119.8012\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 5ms/step - loss: 114.0204 - val_loss: 118.9669\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 7ms/step - loss: 111.4954 - val_loss: 126.1769\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.7043 - val_loss: 122.0017\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.4160 - val_loss: 121.0560\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.9053 - val_loss: 114.6743\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.0582 - val_loss: 113.0342\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 106.5125 - val_loss: 114.1031\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 7ms/step - loss: 105.1910 - val_loss: 110.9684\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 106.2203 - val_loss: 111.3444\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.2980 - val_loss: 108.2794\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 5ms/step - loss: 103.5959 - val_loss: 109.9575\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 100.8942 - val_loss: 106.0388\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 100.4476 - val_loss: 106.9480\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 99.6634 - val_loss: 105.0926\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 100.5892 - val_loss: 108.2858\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 101.4308 - val_loss: 105.6093\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 99.6888 - val_loss: 103.6062\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 95.4018 - val_loss: 101.2549\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 97.3589 - val_loss: 101.3508\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 93.2829 - val_loss: 103.9114\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 94.9664 - val_loss: 98.4230\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 93.2848 - val_loss: 98.0683\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 8ms/step - loss: 93.1889 - val_loss: 97.5367\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 13ms/step - loss: 92.0477 - val_loss: 98.5220\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 92.1263 - val_loss: 95.9628\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 13ms/step - loss: 91.6572 - val_loss: 96.9743\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 89.9455 - val_loss: 101.8076\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 88.7279 - val_loss: 92.9160\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 8ms/step - loss: 87.7189 - val_loss: 92.3682\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 11ms/step - loss: 86.4319 - val_loss: 91.1041\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 7ms/step - loss: 85.9061 - val_loss: 90.9609\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 13ms/step - loss: 85.0279 - val_loss: 90.4321\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 8ms/step - loss: 84.0221 - val_loss: 89.5654\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 10ms/step - loss: 85.5561 - val_loss: 90.1261\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.3315 - val_loss: 92.8334\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.0189 - val_loss: 87.2636\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 5ms/step - loss: 81.8455 - val_loss: 85.9357\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.6872 - val_loss: 87.3639\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 80.4712 - val_loss: 84.7500\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 79.9609 - val_loss: 85.8579\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 79.8378 - val_loss: 85.8671\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 79.0669 - val_loss: 83.6074\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.1287 - val_loss: 82.8093\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 78.8973 - val_loss: 89.1819\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 5ms/step - loss: 78.9200 - val_loss: 82.7383\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.0251 - val_loss: 82.2344\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 7ms/step - loss: 77.0253 - val_loss: 81.4598\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.9357 - val_loss: 91.9921\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.4034 - val_loss: 83.3376\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 76.8285 - val_loss: 79.3753\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 7ms/step - loss: 78.1258 - val_loss: 78.4990\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.0768 - val_loss: 79.0540\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.9913 - val_loss: 78.7890\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 74.6161 - val_loss: 80.6934\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 7ms/step - loss: 74.1872 - val_loss: 78.7721\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 5ms/step - loss: 73.5216 - val_loss: 78.3715\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.7216 - val_loss: 79.9677\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 5ms/step - loss: 71.3409 - val_loss: 79.5617\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.4092 - val_loss: 76.0857\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 7ms/step - loss: 71.6179 - val_loss: 83.0685\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 5ms/step - loss: 70.9468 - val_loss: 75.6451\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 71.6300 - val_loss: 82.2187\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 7ms/step - loss: 70.3700 - val_loss: 75.4189\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.4884 - val_loss: 75.2064\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 70.0725 - val_loss: 76.5909\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 59ms/step - loss: 1109.4357 - val_loss: 451.0554\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 416.9139 - val_loss: 272.5461\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 213.0553 - val_loss: 175.4545\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 165.9069 - val_loss: 167.8846\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 161.1069 - val_loss: 158.5461\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 151.7807 - val_loss: 155.5140\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 145.0766 - val_loss: 147.1437\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 139.7951 - val_loss: 142.3610\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 135.2967 - val_loss: 142.2289\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 5ms/step - loss: 131.9641 - val_loss: 136.8760\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 5ms/step - loss: 129.1565 - val_loss: 133.0143\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 125.6149 - val_loss: 129.5527\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 122.1426 - val_loss: 127.0281\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 120.6321 - val_loss: 131.3537\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.2715 - val_loss: 122.6616\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.3076 - val_loss: 123.7399\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.1264 - val_loss: 120.3556\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 5ms/step - loss: 111.6068 - val_loss: 117.1250\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 5ms/step - loss: 109.0810 - val_loss: 115.8184\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 107.5007 - val_loss: 117.1636\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 105.9204 - val_loss: 112.8711\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 103.9422 - val_loss: 111.2477\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 7ms/step - loss: 101.4686 - val_loss: 111.9708\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 100.2207 - val_loss: 108.7523\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 102.5286 - val_loss: 112.4733\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 98.6089 - val_loss: 108.3655\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 96.6960 - val_loss: 107.4351\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 98.5361 - val_loss: 104.1309\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 94.6250 - val_loss: 102.3087\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 92.6329 - val_loss: 100.4187\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 7ms/step - loss: 93.7354 - val_loss: 104.8183\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 93.6648 - val_loss: 99.8507\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 93.8561 - val_loss: 97.3333\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 88.5125 - val_loss: 101.8202\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 89.8887 - val_loss: 95.8977\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 8ms/step - loss: 87.2988 - val_loss: 95.2707\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 86.0691 - val_loss: 94.7812\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.9718 - val_loss: 93.1192\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.1679 - val_loss: 94.0984\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 13ms/step - loss: 84.4548 - val_loss: 92.5146\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.9740 - val_loss: 92.0210\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 83.0520 - val_loss: 91.8066\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.8688 - val_loss: 93.8514\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 80.9482 - val_loss: 91.0956\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 7ms/step - loss: 80.8542 - val_loss: 89.8322\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 13ms/step - loss: 81.6133 - val_loss: 92.8512\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 13ms/step - loss: 79.2299 - val_loss: 90.7222\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 15ms/step - loss: 78.9256 - val_loss: 88.6961\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 9ms/step - loss: 77.5928 - val_loss: 86.5058\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 78.2131 - val_loss: 87.5973\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.5054 - val_loss: 88.4238\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 75.3881 - val_loss: 85.1230\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.6452 - val_loss: 90.8637\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.7077 - val_loss: 84.6933\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 75.5491 - val_loss: 90.1300\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 77.9376 - val_loss: 90.8621\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 5ms/step - loss: 76.0230 - val_loss: 90.4168\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 75.1361 - val_loss: 85.8938\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.7622 - val_loss: 82.7225\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 70.4386 - val_loss: 86.5302\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 71.0396 - val_loss: 78.9399\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.0653 - val_loss: 77.9862\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 7ms/step - loss: 69.2875 - val_loss: 77.7882\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.5042 - val_loss: 76.6654\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 5ms/step - loss: 66.8807 - val_loss: 77.4098\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 5ms/step - loss: 67.0583 - val_loss: 74.4657\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 65.6124 - val_loss: 76.3328\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 65.6358 - val_loss: 75.4890\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 66.9937 - val_loss: 77.1545\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.3859 - val_loss: 78.7181\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 65.5746 - val_loss: 72.1654\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 64.4350 - val_loss: 76.3147\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 63.7832 - val_loss: 71.8853\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 64.2888 - val_loss: 75.9140\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 5ms/step - loss: 64.4172 - val_loss: 77.2052\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 63.9285 - val_loss: 68.9259\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 61.0855 - val_loss: 68.4286\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 64.1875 - val_loss: 69.9069\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 64.5199 - val_loss: 78.9054\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 63.9364 - val_loss: 67.3976\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 59.6433 - val_loss: 68.1833\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 7ms/step - loss: 59.2464 - val_loss: 67.3642\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 59.3996 - val_loss: 66.2871\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 59.6276 - val_loss: 65.9756\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 60.7847 - val_loss: 75.6105\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 59.8798 - val_loss: 65.7169\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 58.5259 - val_loss: 79.0148\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 61.1068 - val_loss: 66.1687\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 61.6692 - val_loss: 64.3150\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 57.7792 - val_loss: 63.7531\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 7ms/step - loss: 58.8402 - val_loss: 67.1050\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 5ms/step - loss: 59.4100 - val_loss: 65.0615\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 57.1375 - val_loss: 62.0526\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 7ms/step - loss: 55.5768 - val_loss: 63.8874\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 5ms/step - loss: 55.3289 - val_loss: 64.7773\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 59.3480 - val_loss: 62.6469\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 59.0385 - val_loss: 64.0072\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 58.9833 - val_loss: 60.4763\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 7ms/step - loss: 53.4397 - val_loss: 59.5881\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 54.6163 - val_loss: 61.1600\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 57ms/step - loss: 6237.2651 - val_loss: 3446.6929\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 2203.3770 - val_loss: 1260.5503\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 753.5194 - val_loss: 547.1733\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 520.0430 - val_loss: 499.0855\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 481.8463 - val_loss: 474.1406\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 454.4512 - val_loss: 447.1787\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 433.9932 - val_loss: 426.6838\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 415.3597 - val_loss: 411.7037\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 399.8490 - val_loss: 395.2661\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 386.4046 - val_loss: 382.9514\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 373.8198 - val_loss: 370.1496\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 5ms/step - loss: 357.7228 - val_loss: 318.8328\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 276.8004 - val_loss: 233.4619\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 218.9901 - val_loss: 202.8830\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 177.2995 - val_loss: 151.9656\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.0117 - val_loss: 123.2823\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.8229 - val_loss: 118.4115\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 7ms/step - loss: 108.6441 - val_loss: 117.1210\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 7ms/step - loss: 107.6757 - val_loss: 105.8373\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 7ms/step - loss: 100.2935 - val_loss: 99.7046\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 13ms/step - loss: 102.6941 - val_loss: 97.2620\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 7ms/step - loss: 96.4853 - val_loss: 95.4466\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 13ms/step - loss: 95.8882 - val_loss: 107.7693\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 13ms/step - loss: 95.3225 - val_loss: 97.2274\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 92.4846 - val_loss: 92.8534\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 7ms/step - loss: 91.2246 - val_loss: 92.1872\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 7ms/step - loss: 88.9618 - val_loss: 89.6387\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 11ms/step - loss: 89.2609 - val_loss: 89.6014\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 7ms/step - loss: 90.9604 - val_loss: 90.0386\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 87.7549 - val_loss: 91.6582\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 90.5561 - val_loss: 88.9282\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 11ms/step - loss: 87.0841 - val_loss: 88.8736\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.0772 - val_loss: 87.4601\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 5ms/step - loss: 86.0559 - val_loss: 85.4291\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 84.6481 - val_loss: 85.4334\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.8319 - val_loss: 85.8516\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.6535 - val_loss: 96.8934\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 82.9911 - val_loss: 85.3476\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 7ms/step - loss: 85.8855 - val_loss: 90.3918\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 83.6427 - val_loss: 88.2092\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 85.1376 - val_loss: 83.8494\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.6037 - val_loss: 90.8320\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 80.7403 - val_loss: 88.8993\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 80.4494 - val_loss: 87.8243\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 83.9330 - val_loss: 84.1780\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 80.4503 - val_loss: 92.5080\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 83.5826 - val_loss: 83.7266\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 80.6659 - val_loss: 84.2129\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 80.2061 - val_loss: 83.1278\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.4170 - val_loss: 91.2015\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 77.9341 - val_loss: 82.2513\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.6593 - val_loss: 82.7964\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 5ms/step - loss: 78.1965 - val_loss: 81.5989\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 5ms/step - loss: 77.3805 - val_loss: 82.2631\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 77.1289 - val_loss: 80.9411\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 5ms/step - loss: 77.2503 - val_loss: 80.4682\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.1424 - val_loss: 86.6266\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 5ms/step - loss: 75.3998 - val_loss: 80.8023\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 5ms/step - loss: 77.5741 - val_loss: 79.9166\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 7ms/step - loss: 75.3941 - val_loss: 80.7767\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 75.4349 - val_loss: 80.1137\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.8958 - val_loss: 82.3252\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 78.3473 - val_loss: 90.8566\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.0359 - val_loss: 78.9224\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 74.1442 - val_loss: 77.5058\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 72.2577 - val_loss: 84.9412\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 77.3646 - val_loss: 83.1251\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 80.8927 - val_loss: 76.9394\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.8135 - val_loss: 76.5234\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.6224 - val_loss: 75.8162\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.8560 - val_loss: 77.7647\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 71.3062 - val_loss: 75.5892\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 72.2800 - val_loss: 75.1022\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.9420 - val_loss: 76.0489\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 70.8137 - val_loss: 75.1802\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.1758 - val_loss: 77.2092\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 69.6367 - val_loss: 75.1539\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.6965 - val_loss: 74.8239\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.5232 - val_loss: 82.0839\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 69.7112 - val_loss: 76.4094\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.5709 - val_loss: 74.5311\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 67.2273 - val_loss: 75.4239\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.2355 - val_loss: 73.6240\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 67.7330 - val_loss: 73.5776\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.1557 - val_loss: 73.5947\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 66.3230 - val_loss: 73.7737\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 5ms/step - loss: 66.3214 - val_loss: 73.1011\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 67.8201 - val_loss: 75.5782\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.0712 - val_loss: 72.7714\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.7503 - val_loss: 74.6864\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 66.9162 - val_loss: 75.6832\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 65.7193 - val_loss: 72.6225\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 7ms/step - loss: 67.5398 - val_loss: 80.7493\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 66.2182 - val_loss: 72.6523\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 64.7351 - val_loss: 73.1271\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 7ms/step - loss: 64.6924 - val_loss: 73.0062\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 64.9115 - val_loss: 73.2086\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 65.2399 - val_loss: 80.4632\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 68.6450 - val_loss: 73.8096\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 63.9361 - val_loss: 71.7933\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 67ms/step - loss: 608.8794 - val_loss: 290.9598\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 6ms/step - loss: 237.3753 - val_loss: 222.1685\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 206.2759 - val_loss: 203.6159\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 188.6793 - val_loss: 191.5766\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.9289 - val_loss: 178.5840\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 169.7517 - val_loss: 169.9106\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 163.6515 - val_loss: 162.7088\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 8ms/step - loss: 154.7327 - val_loss: 155.4173\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 11ms/step - loss: 147.0116 - val_loss: 148.5698\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 13ms/step - loss: 140.5101 - val_loss: 147.0628\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 13ms/step - loss: 134.6974 - val_loss: 137.3348\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 11ms/step - loss: 128.6189 - val_loss: 129.6245\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 123.1554 - val_loss: 121.6795\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.9802 - val_loss: 115.7510\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 7ms/step - loss: 112.2899 - val_loss: 111.7771\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 108.7393 - val_loss: 110.4552\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 7ms/step - loss: 104.4791 - val_loss: 106.2158\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 103.6432 - val_loss: 111.6212\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 99.9851 - val_loss: 115.4088\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 102.1362 - val_loss: 98.7274\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 94.7822 - val_loss: 96.5090\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 95.5795 - val_loss: 99.3673\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 92.2205 - val_loss: 94.5190\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 89.7180 - val_loss: 97.6479\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 87.7869 - val_loss: 96.9359\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 89.7328 - val_loss: 89.3796\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 5ms/step - loss: 87.0571 - val_loss: 88.3672\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 84.8450 - val_loss: 87.5677\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 84.2133 - val_loss: 87.3554\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.8708 - val_loss: 85.3996\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 82.8558 - val_loss: 89.6664\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 7ms/step - loss: 82.8450 - val_loss: 84.3870\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 83.0901 - val_loss: 83.2650\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 81.2683 - val_loss: 85.5262\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 7ms/step - loss: 79.9415 - val_loss: 81.7688\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 78.4803 - val_loss: 81.5601\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.2013 - val_loss: 80.5057\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 76.3812 - val_loss: 79.6150\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.8886 - val_loss: 79.9006\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.3804 - val_loss: 78.7271\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 7ms/step - loss: 77.3727 - val_loss: 78.9706\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 81.8636 - val_loss: 78.6995\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.2774 - val_loss: 76.4272\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.3932 - val_loss: 78.1746\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.1432 - val_loss: 77.5465\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 72.4655 - val_loss: 74.9698\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 72.3310 - val_loss: 75.0513\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.0382 - val_loss: 75.1595\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.1146 - val_loss: 73.8513\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 71.3365 - val_loss: 84.3450\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 72.7153 - val_loss: 87.3875\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.1722 - val_loss: 73.8472\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 72.8952 - val_loss: 73.0033\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.6837 - val_loss: 77.3810\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 74.6851 - val_loss: 75.4195\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.0557 - val_loss: 72.8127\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.3710 - val_loss: 73.5285\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.5026 - val_loss: 72.2279\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 7ms/step - loss: 69.4389 - val_loss: 70.9628\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 5ms/step - loss: 67.7788 - val_loss: 71.3197\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 67.7392 - val_loss: 87.4994\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.4561 - val_loss: 71.6817\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 7ms/step - loss: 68.3014 - val_loss: 74.9976\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 69.1251 - val_loss: 72.2718\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 7ms/step - loss: 68.6116 - val_loss: 70.6291\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 67.7598 - val_loss: 77.9526\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.2947 - val_loss: 76.9339\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 5ms/step - loss: 68.0112 - val_loss: 74.1740\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 7ms/step - loss: 68.6965 - val_loss: 70.4620\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 5ms/step - loss: 66.7210 - val_loss: 71.7186\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 68.6938 - val_loss: 76.6008\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.1509 - val_loss: 78.3039\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 66.1879 - val_loss: 74.3678\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 7ms/step - loss: 65.2495 - val_loss: 71.0203\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 65.5799 - val_loss: 69.4161\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 65.8513 - val_loss: 69.1341\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 65.1706 - val_loss: 70.5174\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 64.6311 - val_loss: 70.4708\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.0905 - val_loss: 76.8881\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 65.8042 - val_loss: 69.6064\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 64.4273 - val_loss: 68.2880\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 65.5732 - val_loss: 69.3127\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 65.7821 - val_loss: 69.0257\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 5ms/step - loss: 65.5857 - val_loss: 72.4071\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.3866 - val_loss: 73.6993\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 64.3434 - val_loss: 69.2952\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 64.5349 - val_loss: 68.4604\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 65.0843 - val_loss: 70.5770\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 64.7107 - val_loss: 67.7309\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 63.8382 - val_loss: 68.7854\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 63.9098 - val_loss: 67.7993\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 7ms/step - loss: 63.7139 - val_loss: 68.8985\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 5ms/step - loss: 64.3879 - val_loss: 68.5855\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 7ms/step - loss: 62.9878 - val_loss: 68.9828\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 7ms/step - loss: 65.6129 - val_loss: 68.2659\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 13ms/step - loss: 63.5544 - val_loss: 68.5847\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 65.9332 - val_loss: 69.1699\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 7ms/step - loss: 64.6910 - val_loss: 73.8750\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 64.9511 - val_loss: 68.7984\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 64.2509 - val_loss: 71.4140\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 81ms/step - loss: 352.3504 - val_loss: 305.4058\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 271.9482 - val_loss: 240.8345\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 228.9534 - val_loss: 220.0118\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 216.1609 - val_loss: 207.9077\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 202.2749 - val_loss: 189.4038\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 194.6316 - val_loss: 173.6608\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 173.9476 - val_loss: 172.2965\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.1238 - val_loss: 159.1739\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.6337 - val_loss: 151.1428\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 148.2973 - val_loss: 147.2988\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 7ms/step - loss: 140.9559 - val_loss: 133.8515\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 136.0992 - val_loss: 129.3603\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 130.6888 - val_loss: 123.2605\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 129.3968 - val_loss: 120.0818\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 124.7321 - val_loss: 116.3235\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.0013 - val_loss: 118.3828\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.2768 - val_loss: 115.8564\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.0491 - val_loss: 107.8281\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 107.5597 - val_loss: 103.3703\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 7ms/step - loss: 105.7890 - val_loss: 101.5207\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 103.0737 - val_loss: 98.1466\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 99.1813 - val_loss: 95.7251\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 99.0216 - val_loss: 94.7374\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 96.8461 - val_loss: 93.6844\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 5ms/step - loss: 95.7718 - val_loss: 93.7834\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 99.1284 - val_loss: 89.1567\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 88.5368 - val_loss: 86.0648\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 88.1611 - val_loss: 83.9832\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 83.7211 - val_loss: 86.2388\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 85.8895 - val_loss: 100.0539\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 89.2998 - val_loss: 80.2108\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.4674 - val_loss: 79.2860\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.7369 - val_loss: 78.2051\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.6517 - val_loss: 77.8884\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 76.9319 - val_loss: 88.1065\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 7ms/step - loss: 79.3316 - val_loss: 76.6236\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 5ms/step - loss: 76.2209 - val_loss: 74.4817\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 75.2225 - val_loss: 73.3832\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.6426 - val_loss: 72.8593\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.1244 - val_loss: 72.4051\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 74.1467 - val_loss: 72.3125\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 71.4259 - val_loss: 79.7636\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.2107 - val_loss: 73.2525\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.7201 - val_loss: 79.9695\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 7ms/step - loss: 77.2988 - val_loss: 72.0888\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.3297 - val_loss: 73.6038\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.0516 - val_loss: 69.0024\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 68.0488 - val_loss: 68.3181\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.3015 - val_loss: 67.5820\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 66.0645 - val_loss: 71.2393\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.3598 - val_loss: 67.3397\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 69.2918 - val_loss: 65.4468\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 63.8296 - val_loss: 64.3003\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 63.0229 - val_loss: 63.0505\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 7ms/step - loss: 62.9668 - val_loss: 66.3698\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 62.5913 - val_loss: 64.4807\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 64.0057 - val_loss: 64.2369\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 60.6407 - val_loss: 66.7707\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 61.9537 - val_loss: 61.7808\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 61.4152 - val_loss: 67.2077\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 59.9082 - val_loss: 63.2118\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 5ms/step - loss: 59.1918 - val_loss: 64.4047\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 5ms/step - loss: 59.3925 - val_loss: 60.5813\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 61.1630 - val_loss: 60.3825\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 5ms/step - loss: 58.8246 - val_loss: 62.0482\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 5ms/step - loss: 60.2196 - val_loss: 61.9777\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 60.5948 - val_loss: 60.0499\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 59.1840 - val_loss: 61.3049\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 57.8692 - val_loss: 59.6630\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 7ms/step - loss: 58.2086 - val_loss: 65.8801\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 5ms/step - loss: 58.2326 - val_loss: 61.1145\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 58.1612 - val_loss: 59.6433\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 56.0087 - val_loss: 62.6178\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 5ms/step - loss: 56.8784 - val_loss: 58.7755\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 56.7507 - val_loss: 58.9537\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 62.0040 - val_loss: 67.5964\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 56.8076 - val_loss: 58.6880\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 54.6839 - val_loss: 61.4610\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 57.8078 - val_loss: 58.1450\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 53.7585 - val_loss: 57.9649\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 55.8082 - val_loss: 60.2905\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 5ms/step - loss: 56.9146 - val_loss: 58.9497\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 54.9235 - val_loss: 57.8354\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 55.5492 - val_loss: 59.9196\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 53.9889 - val_loss: 57.3234\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 8ms/step - loss: 64.4202 - val_loss: 56.8670\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 10ms/step - loss: 57.6016 - val_loss: 62.9809\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 52.5177 - val_loss: 57.0855\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 53.4447 - val_loss: 59.6073\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 13ms/step - loss: 52.3158 - val_loss: 60.7568\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 53.1451 - val_loss: 58.0236\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 13ms/step - loss: 53.1038 - val_loss: 65.1600\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 12ms/step - loss: 54.6194 - val_loss: 56.1392\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 10ms/step - loss: 50.6222 - val_loss: 57.7453\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 7ms/step - loss: 51.2283 - val_loss: 56.4620\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 10ms/step - loss: 51.4344 - val_loss: 58.4521\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 50.6754 - val_loss: 55.9512\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 51.6754 - val_loss: 55.4257\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 52.3789 - val_loss: 56.4808\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 50.9949 - val_loss: 56.6520\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 58ms/step - loss: 14621.2861 - val_loss: 741.2834\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 1230.7695 - val_loss: 793.0931\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 5ms/step - loss: 690.6525 - val_loss: 578.0948\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 592.6122 - val_loss: 506.9167\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 515.0145 - val_loss: 439.7067\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 7ms/step - loss: 457.2368 - val_loss: 404.0794\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 403.0071 - val_loss: 355.5064\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 345.7094 - val_loss: 300.1664\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 300.0060 - val_loss: 272.2645\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 268.5351 - val_loss: 243.9990\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 7ms/step - loss: 246.3892 - val_loss: 226.1457\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 230.3667 - val_loss: 221.7709\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 218.1334 - val_loss: 207.0963\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 7ms/step - loss: 208.0110 - val_loss: 198.8072\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 199.9174 - val_loss: 188.2482\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 7ms/step - loss: 192.4103 - val_loss: 185.2359\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 5ms/step - loss: 186.3115 - val_loss: 178.3544\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 180.8256 - val_loss: 173.0063\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 178.7026 - val_loss: 173.8170\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.6006 - val_loss: 179.9316\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 171.7635 - val_loss: 169.8197\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 162.8639 - val_loss: 170.9852\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 159.8900 - val_loss: 159.8357\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.1983 - val_loss: 153.0867\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 5ms/step - loss: 152.2526 - val_loss: 149.7709\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 147.3425 - val_loss: 155.7186\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 145.6285 - val_loss: 148.3439\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 7ms/step - loss: 142.5264 - val_loss: 159.3240\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 138.6865 - val_loss: 137.8949\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 136.2856 - val_loss: 142.4757\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 132.8421 - val_loss: 153.7053\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 131.8062 - val_loss: 129.9035\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 125.5772 - val_loss: 133.6988\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.5194 - val_loss: 125.5419\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.7744 - val_loss: 123.7625\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.3744 - val_loss: 124.7914\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 5ms/step - loss: 116.6576 - val_loss: 117.5237\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.7364 - val_loss: 115.6378\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 7ms/step - loss: 111.0616 - val_loss: 116.8053\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.8610 - val_loss: 116.9659\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.7661 - val_loss: 113.1172\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.3077 - val_loss: 118.6934\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 106.0849 - val_loss: 107.5003\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 104.4836 - val_loss: 106.8551\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 5ms/step - loss: 102.3048 - val_loss: 104.4526\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 101.1857 - val_loss: 102.7964\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 100.2319 - val_loss: 101.7691\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 5ms/step - loss: 98.1861 - val_loss: 103.3901\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 98.3768 - val_loss: 100.1927\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 95.0475 - val_loss: 102.9068\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 7ms/step - loss: 93.4675 - val_loss: 98.3017\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 92.2748 - val_loss: 95.3845\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 91.2779 - val_loss: 97.5957\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 90.4357 - val_loss: 92.1741\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 89.4138 - val_loss: 91.3255\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 88.5411 - val_loss: 90.1963\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 89.0014 - val_loss: 97.4893\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 90.3848 - val_loss: 88.9546\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 87.5061 - val_loss: 87.5877\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 86.2354 - val_loss: 89.6154\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 7ms/step - loss: 84.7342 - val_loss: 86.9250\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 85.0681 - val_loss: 88.3227\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 7ms/step - loss: 83.0520 - val_loss: 85.5557\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 5ms/step - loss: 85.9637 - val_loss: 83.9959\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 7ms/step - loss: 85.6897 - val_loss: 83.1459\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 12ms/step - loss: 84.6080 - val_loss: 84.9291\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 83.8253 - val_loss: 86.9292\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 80.6932 - val_loss: 82.2312\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 13ms/step - loss: 80.3192 - val_loss: 80.8714\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 80.0108 - val_loss: 84.3659\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 7ms/step - loss: 82.4099 - val_loss: 79.8171\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.2540 - val_loss: 92.0613\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 13ms/step - loss: 80.2609 - val_loss: 79.5409\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 13ms/step - loss: 78.0500 - val_loss: 81.4369\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 8ms/step - loss: 81.3179 - val_loss: 91.7042\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 11ms/step - loss: 80.5608 - val_loss: 77.6187\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 76.8127 - val_loss: 78.8973\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 80.7450 - val_loss: 78.6460\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.7884 - val_loss: 86.2038\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 79.2946 - val_loss: 82.7595\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.2426 - val_loss: 76.2450\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 7ms/step - loss: 77.2067 - val_loss: 75.6141\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.3455 - val_loss: 77.2673\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 75.4571 - val_loss: 79.3919\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.1442 - val_loss: 76.0185\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 7ms/step - loss: 75.2065 - val_loss: 74.1028\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.0136 - val_loss: 75.8658\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 75.0365 - val_loss: 74.2460\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.8256 - val_loss: 72.5262\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.8697 - val_loss: 72.6750\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 75.0244 - val_loss: 73.5114\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.8859 - val_loss: 73.8801\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 71.6307 - val_loss: 73.8352\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 71.3359 - val_loss: 70.8188\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 7ms/step - loss: 70.7813 - val_loss: 70.6690\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.2662 - val_loss: 71.3433\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.7879 - val_loss: 69.8526\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 71.2610 - val_loss: 83.4459\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.5148 - val_loss: 69.0741\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.7595 - val_loss: 70.0951\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 59ms/step - loss: 5893.2305 - val_loss: 2055.2227\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 1268.8019 - val_loss: 624.9968\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 527.3732 - val_loss: 396.5390\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 390.5934 - val_loss: 348.8291\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 349.8081 - val_loss: 320.6165\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 322.0436 - val_loss: 298.3914\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 7ms/step - loss: 298.2708 - val_loss: 284.4284\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 5ms/step - loss: 280.2093 - val_loss: 270.3507\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 265.8327 - val_loss: 261.0647\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 255.1516 - val_loss: 250.5988\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 246.5577 - val_loss: 243.7019\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 238.2628 - val_loss: 237.3941\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 231.5787 - val_loss: 230.4945\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 225.2676 - val_loss: 227.1837\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 220.1471 - val_loss: 219.9100\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 215.5073 - val_loss: 214.3139\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 210.6626 - val_loss: 212.4569\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 207.0318 - val_loss: 204.8811\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 200.9642 - val_loss: 203.8798\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 196.9534 - val_loss: 199.4651\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 193.2806 - val_loss: 197.0929\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 3ms/step - loss: 189.1535 - val_loss: 195.6439\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 186.0918 - val_loss: 191.2012\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 3ms/step - loss: 183.7757 - val_loss: 191.0040\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 8ms/step - loss: 180.1350 - val_loss: 186.8125\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 5ms/step - loss: 176.5667 - val_loss: 184.3450\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 174.1673 - val_loss: 181.3799\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 171.2409 - val_loss: 178.9148\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.5070 - val_loss: 179.9220\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 166.9352 - val_loss: 173.8897\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 165.8437 - val_loss: 173.3162\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 162.1779 - val_loss: 171.2164\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.1559 - val_loss: 167.5459\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 5ms/step - loss: 158.6414 - val_loss: 167.2480\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.9798 - val_loss: 164.4616\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 154.7628 - val_loss: 164.0163\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 153.2332 - val_loss: 160.2501\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 150.1658 - val_loss: 159.9397\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.4479 - val_loss: 155.2479\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 146.5173 - val_loss: 152.3159\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 7ms/step - loss: 143.2567 - val_loss: 150.0608\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 140.2416 - val_loss: 147.6341\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.1768 - val_loss: 146.4741\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 136.4669 - val_loss: 144.3205\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 136.1217 - val_loss: 144.8663\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 8ms/step - loss: 135.9098 - val_loss: 141.2138\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 133.6392 - val_loss: 143.4342\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 130.5676 - val_loss: 140.6306\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 7ms/step - loss: 129.0021 - val_loss: 138.4559\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 11ms/step - loss: 127.7256 - val_loss: 138.0572\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 126.5970 - val_loss: 137.3048\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 125.4781 - val_loss: 141.2981\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 125.7733 - val_loss: 137.2567\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 14ms/step - loss: 123.7152 - val_loss: 135.5728\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.3228 - val_loss: 135.1928\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.0726 - val_loss: 134.8323\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.0744 - val_loss: 132.9348\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 13ms/step - loss: 120.7315 - val_loss: 131.6962\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 13ms/step - loss: 119.7718 - val_loss: 131.1048\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 5ms/step - loss: 120.1197 - val_loss: 131.0997\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.6751 - val_loss: 129.4105\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.6483 - val_loss: 129.3597\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.6400 - val_loss: 126.5764\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.4299 - val_loss: 125.3567\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.5972 - val_loss: 124.8454\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.2250 - val_loss: 124.4806\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.6956 - val_loss: 122.8648\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.1236 - val_loss: 122.1273\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 108.6184 - val_loss: 121.0522\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.9164 - val_loss: 119.9525\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 108.8202 - val_loss: 120.7183\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 106.7730 - val_loss: 117.8193\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 104.4560 - val_loss: 122.7650\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 104.1320 - val_loss: 116.5329\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 102.8568 - val_loss: 115.5571\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 102.3765 - val_loss: 115.2457\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 100.8836 - val_loss: 113.5312\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 100.4576 - val_loss: 114.8605\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 100.2900 - val_loss: 114.4628\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 100.4044 - val_loss: 115.7564\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 99.3947 - val_loss: 110.6854\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 97.1216 - val_loss: 111.8493\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 99.5505 - val_loss: 117.7166\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 97.5246 - val_loss: 110.4392\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 98.2989 - val_loss: 107.6982\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 96.7057 - val_loss: 106.3864\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 95.7645 - val_loss: 107.2450\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 95.9903 - val_loss: 105.7388\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 95.5963 - val_loss: 104.4924\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 92.9196 - val_loss: 104.6870\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 5ms/step - loss: 91.2560 - val_loss: 103.4061\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 90.5007 - val_loss: 102.7971\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 90.8112 - val_loss: 102.1492\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 89.4704 - val_loss: 101.5895\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 89.2709 - val_loss: 101.1517\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 88.6125 - val_loss: 99.9006\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 87.2119 - val_loss: 100.9052\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 87.1640 - val_loss: 102.6455\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 91.6933 - val_loss: 99.2113\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 85.1160 - val_loss: 97.7736\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 58ms/step - loss: 6798.4756 - val_loss: 525.6805\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 668.4284 - val_loss: 545.0164\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 435.3199 - val_loss: 386.7070\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 400.0077 - val_loss: 376.6007\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 385.8418 - val_loss: 366.4714\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 372.6073 - val_loss: 354.9642\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 362.1274 - val_loss: 346.2024\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 7ms/step - loss: 351.1978 - val_loss: 337.2619\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 341.4072 - val_loss: 325.6194\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 329.5334 - val_loss: 315.6582\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 319.8663 - val_loss: 305.2667\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 310.6905 - val_loss: 296.1506\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 301.8737 - val_loss: 290.8710\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 292.2563 - val_loss: 278.9460\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 284.2402 - val_loss: 271.2233\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 274.9951 - val_loss: 265.1845\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 266.7234 - val_loss: 256.8848\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 260.4219 - val_loss: 252.8326\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 252.4297 - val_loss: 245.8107\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 246.9694 - val_loss: 238.3225\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 238.4213 - val_loss: 235.5586\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 232.7864 - val_loss: 228.1225\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 7ms/step - loss: 227.0134 - val_loss: 222.9192\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 221.8729 - val_loss: 222.9676\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 3ms/step - loss: 217.9306 - val_loss: 213.0443\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 212.0553 - val_loss: 212.7658\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 206.8457 - val_loss: 205.2897\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 202.0206 - val_loss: 200.9241\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 198.5615 - val_loss: 195.7070\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 194.0338 - val_loss: 191.7840\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 190.1889 - val_loss: 189.1865\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 7ms/step - loss: 186.2677 - val_loss: 184.0453\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 181.8473 - val_loss: 180.5347\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.0374 - val_loss: 180.7865\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 5ms/step - loss: 175.3658 - val_loss: 178.3556\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 170.1128 - val_loss: 170.1818\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 167.3421 - val_loss: 170.6042\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 165.1985 - val_loss: 166.4992\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 161.4494 - val_loss: 162.8072\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 13ms/step - loss: 157.8363 - val_loss: 170.6239\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 157.6282 - val_loss: 159.9041\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 13ms/step - loss: 158.8011 - val_loss: 160.0354\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 12ms/step - loss: 152.5663 - val_loss: 155.2816\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 13ms/step - loss: 150.3457 - val_loss: 154.3804\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.9337 - val_loss: 152.4751\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 5ms/step - loss: 145.5579 - val_loss: 159.9052\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 145.3382 - val_loss: 150.8004\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 144.3350 - val_loss: 149.5420\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 144.2146 - val_loss: 148.8098\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 141.8335 - val_loss: 145.3511\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 139.5164 - val_loss: 147.1333\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.1785 - val_loss: 141.9897\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 7ms/step - loss: 137.9656 - val_loss: 146.0069\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 135.7386 - val_loss: 158.0677\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 137.3855 - val_loss: 143.9840\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 132.7765 - val_loss: 136.6026\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 129.5686 - val_loss: 134.9401\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 127.2834 - val_loss: 141.7297\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 5ms/step - loss: 126.2819 - val_loss: 130.1399\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 5ms/step - loss: 124.7912 - val_loss: 127.0239\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 123.4737 - val_loss: 120.4027\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 5ms/step - loss: 120.4719 - val_loss: 120.0949\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.4741 - val_loss: 141.3516\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.2192 - val_loss: 123.7892\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.1193 - val_loss: 122.7549\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 124.1907 - val_loss: 122.2694\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.7802 - val_loss: 133.6380\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 7ms/step - loss: 115.6456 - val_loss: 120.2946\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.8402 - val_loss: 119.0655\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.4737 - val_loss: 118.1167\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.4635 - val_loss: 116.1594\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.3390 - val_loss: 119.6540\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.7286 - val_loss: 119.0661\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.9370 - val_loss: 115.9530\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.7771 - val_loss: 118.9885\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.3434 - val_loss: 125.6478\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.4325 - val_loss: 117.1229\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.3582 - val_loss: 115.1843\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.1215 - val_loss: 115.6153\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.7043 - val_loss: 114.9664\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.9321 - val_loss: 116.3641\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.7360 - val_loss: 114.9603\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.3593 - val_loss: 115.9708\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 5ms/step - loss: 115.4684 - val_loss: 122.6768\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.5488 - val_loss: 118.3293\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.0469 - val_loss: 114.3688\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.8285 - val_loss: 114.9448\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 7ms/step - loss: 112.3911 - val_loss: 121.2027\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.5705 - val_loss: 116.6950\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.3566 - val_loss: 116.8466\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.2903 - val_loss: 124.8464\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 114.8271 - val_loss: 115.4194\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.6566 - val_loss: 117.7393\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 7ms/step - loss: 113.5192 - val_loss: 113.5638\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.1098 - val_loss: 117.5612\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 5ms/step - loss: 112.0249 - val_loss: 114.7737\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.3545 - val_loss: 113.5302\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.4410 - val_loss: 119.6743\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.5148 - val_loss: 115.8970\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.6854 - val_loss: 117.0905\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 57ms/step - loss: 4396.2607 - val_loss: 1889.1071\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 858.5037 - val_loss: 421.2685\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 382.2493 - val_loss: 326.8074\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 312.2069 - val_loss: 286.7987\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 281.2558 - val_loss: 264.1207\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 256.6518 - val_loss: 243.6090\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 238.0480 - val_loss: 228.8333\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 223.7574 - val_loss: 211.3479\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 205.5258 - val_loss: 197.8371\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 191.1581 - val_loss: 189.1272\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 176.5448 - val_loss: 171.2657\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 7ms/step - loss: 166.2480 - val_loss: 162.1903\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.8039 - val_loss: 156.0325\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 151.2148 - val_loss: 151.0122\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 7ms/step - loss: 145.4024 - val_loss: 143.1280\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 142.0618 - val_loss: 138.5538\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 135.8013 - val_loss: 136.0934\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.7187 - val_loss: 134.5587\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 132.8330 - val_loss: 129.5048\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 127.8392 - val_loss: 128.1107\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 13ms/step - loss: 124.7088 - val_loss: 124.7930\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.2600 - val_loss: 122.7084\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.2506 - val_loss: 124.6323\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.3882 - val_loss: 117.0002\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.4173 - val_loss: 114.4972\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 8ms/step - loss: 110.7568 - val_loss: 111.8325\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 7ms/step - loss: 109.3148 - val_loss: 112.0496\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 105.2181 - val_loss: 112.4076\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 13ms/step - loss: 104.2319 - val_loss: 105.6832\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 7ms/step - loss: 102.5549 - val_loss: 105.0572\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 7ms/step - loss: 99.9489 - val_loss: 108.2729\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 98.8610 - val_loss: 103.9780\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 5ms/step - loss: 97.2537 - val_loss: 107.4126\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 96.4283 - val_loss: 102.5417\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 94.0835 - val_loss: 95.5636\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 7ms/step - loss: 92.3202 - val_loss: 93.9844\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 93.4971 - val_loss: 99.3512\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 92.6761 - val_loss: 91.7734\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 88.6648 - val_loss: 89.7994\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 7ms/step - loss: 87.7197 - val_loss: 88.7342\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 89.0747 - val_loss: 87.4731\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 87.4716 - val_loss: 87.5037\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.2102 - val_loss: 85.7356\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.5098 - val_loss: 83.5701\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 82.9338 - val_loss: 82.3013\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.4598 - val_loss: 82.0717\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 7ms/step - loss: 81.0009 - val_loss: 81.7861\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 5ms/step - loss: 80.7154 - val_loss: 80.3310\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.3806 - val_loss: 84.4820\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 80.8648 - val_loss: 79.2445\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.9488 - val_loss: 78.8516\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 77.7417 - val_loss: 78.9853\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 77.5852 - val_loss: 77.6783\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 78.7926 - val_loss: 77.8445\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 7ms/step - loss: 76.5337 - val_loss: 77.6754\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.3246 - val_loss: 76.6242\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.3135 - val_loss: 79.7546\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 75.5347 - val_loss: 76.0890\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.0236 - val_loss: 77.0462\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 75.3039 - val_loss: 75.8790\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.8493 - val_loss: 77.5007\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 75.2758 - val_loss: 75.1927\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 74.1322 - val_loss: 76.4730\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.6112 - val_loss: 74.8586\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.6304 - val_loss: 74.4343\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.4839 - val_loss: 74.3343\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.5699 - val_loss: 74.1307\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.2917 - val_loss: 73.9003\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.3557 - val_loss: 76.1039\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.7833 - val_loss: 73.5832\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.7244 - val_loss: 73.9927\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.8629 - val_loss: 75.0780\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 5ms/step - loss: 71.7837 - val_loss: 73.2554\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.9458 - val_loss: 75.1648\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 71.7115 - val_loss: 74.4283\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.6531 - val_loss: 72.7181\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.3359 - val_loss: 75.4938\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 74.5572 - val_loss: 73.5982\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 74.7220 - val_loss: 72.3688\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 70.9887 - val_loss: 75.1211\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.7431 - val_loss: 73.1780\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 71.7136 - val_loss: 73.4293\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 70.2629 - val_loss: 71.9653\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 5ms/step - loss: 69.5242 - val_loss: 71.7104\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.9791 - val_loss: 80.6359\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.0589 - val_loss: 73.1451\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.3727 - val_loss: 75.3746\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.3887 - val_loss: 71.3975\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 7ms/step - loss: 68.9591 - val_loss: 79.7613\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 70.7555 - val_loss: 72.8781\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 69.0136 - val_loss: 76.2450\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.2243 - val_loss: 71.0050\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.3679 - val_loss: 71.6847\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.6548 - val_loss: 75.8953\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 7ms/step - loss: 69.5020 - val_loss: 74.1568\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.2579 - val_loss: 71.1187\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 69.2719 - val_loss: 81.7290\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 5ms/step - loss: 70.8859 - val_loss: 70.9962\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 7ms/step - loss: 69.5032 - val_loss: 72.2467\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 70.4285 - val_loss: 74.0433\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 63ms/step - loss: 24221.4609 - val_loss: 4247.9028\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 2320.2263 - val_loss: 1628.5321\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 5ms/step - loss: 1428.1174 - val_loss: 1158.2932\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1098.9731 - val_loss: 1004.7823\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 943.8694 - val_loss: 880.8613\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 824.4813 - val_loss: 778.4155\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 721.7421 - val_loss: 686.9748\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 634.3633 - val_loss: 613.3019\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 7ms/step - loss: 564.9109 - val_loss: 551.8088\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 503.7218 - val_loss: 490.5473\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 15ms/step - loss: 449.3795 - val_loss: 441.9956\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 11ms/step - loss: 403.7914 - val_loss: 400.1034\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 7ms/step - loss: 362.3369 - val_loss: 361.3343\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 12ms/step - loss: 325.8048 - val_loss: 325.2809\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 295.6977 - val_loss: 298.7470\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 273.7310 - val_loss: 279.3693\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 257.1879 - val_loss: 262.9475\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 250.0484 - val_loss: 256.5289\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 237.5319 - val_loss: 242.6737\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 229.8763 - val_loss: 236.7728\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 7ms/step - loss: 224.6082 - val_loss: 229.6308\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 220.8000 - val_loss: 225.2001\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 216.9196 - val_loss: 224.4260\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 213.4307 - val_loss: 217.3572\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 211.7305 - val_loss: 214.6531\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 7ms/step - loss: 206.8870 - val_loss: 212.5915\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 204.3722 - val_loss: 209.8326\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 202.1348 - val_loss: 206.1161\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 200.8437 - val_loss: 206.8077\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 197.3852 - val_loss: 201.5615\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 195.7912 - val_loss: 199.7007\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 7ms/step - loss: 192.7399 - val_loss: 199.3378\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 191.3544 - val_loss: 195.2338\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 188.7403 - val_loss: 194.3826\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 5ms/step - loss: 187.1234 - val_loss: 191.9651\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 185.2616 - val_loss: 189.2704\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.2137 - val_loss: 187.6464\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 182.4654 - val_loss: 185.6933\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 185.2315 - val_loss: 203.4821\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 179.3118 - val_loss: 182.1965\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 175.8883 - val_loss: 182.5201\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 173.6433 - val_loss: 178.9118\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 175.1518 - val_loss: 179.6457\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 171.8367 - val_loss: 179.6517\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 170.9425 - val_loss: 176.7988\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 167.1247 - val_loss: 172.6660\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 7ms/step - loss: 168.6047 - val_loss: 170.6531\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 165.1557 - val_loss: 171.6104\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 164.5987 - val_loss: 168.6558\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 163.4829 - val_loss: 166.5684\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 7ms/step - loss: 161.8968 - val_loss: 165.3405\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 5ms/step - loss: 159.6125 - val_loss: 163.4528\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 5ms/step - loss: 157.3036 - val_loss: 162.2300\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.3846 - val_loss: 162.8110\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.3942 - val_loss: 160.3315\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 5ms/step - loss: 153.8828 - val_loss: 159.3038\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 151.0953 - val_loss: 157.3665\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 5ms/step - loss: 149.8280 - val_loss: 155.0367\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 149.4464 - val_loss: 155.9297\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 148.2345 - val_loss: 153.1635\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 5ms/step - loss: 146.5106 - val_loss: 150.3657\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 147.2018 - val_loss: 150.7959\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 7ms/step - loss: 143.3321 - val_loss: 148.3349\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 5ms/step - loss: 141.1993 - val_loss: 149.4852\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 141.4260 - val_loss: 147.1355\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 5ms/step - loss: 140.3071 - val_loss: 144.3490\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 5ms/step - loss: 137.9287 - val_loss: 142.3942\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 5ms/step - loss: 135.9731 - val_loss: 141.9478\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 135.3881 - val_loss: 142.6171\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.7807 - val_loss: 141.7747\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 5ms/step - loss: 132.5682 - val_loss: 137.4571\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 130.6576 - val_loss: 137.2687\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 130.3488 - val_loss: 134.8605\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 128.8374 - val_loss: 133.5578\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 5ms/step - loss: 128.1239 - val_loss: 135.5003\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 127.6093 - val_loss: 133.7602\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 126.5331 - val_loss: 129.7061\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 123.6702 - val_loss: 130.1906\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 7ms/step - loss: 122.7644 - val_loss: 127.3937\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 5ms/step - loss: 121.0682 - val_loss: 128.2371\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 5ms/step - loss: 122.4649 - val_loss: 125.4014\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.7796 - val_loss: 126.7085\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 5ms/step - loss: 119.3066 - val_loss: 123.2650\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.5862 - val_loss: 128.7125\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 9ms/step - loss: 116.8062 - val_loss: 121.3881\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 8ms/step - loss: 114.3273 - val_loss: 121.7824\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 7ms/step - loss: 112.8970 - val_loss: 119.1370\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 12ms/step - loss: 113.8226 - val_loss: 117.4628\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 13ms/step - loss: 111.2386 - val_loss: 116.7726\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 13ms/step - loss: 111.0791 - val_loss: 115.4036\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 12ms/step - loss: 110.2055 - val_loss: 118.6156\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 13ms/step - loss: 110.1861 - val_loss: 114.1402\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 7ms/step - loss: 106.8176 - val_loss: 112.4532\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 7ms/step - loss: 105.7052 - val_loss: 111.2114\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 13ms/step - loss: 105.2302 - val_loss: 110.9972\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 15ms/step - loss: 103.1581 - val_loss: 109.0604\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 14ms/step - loss: 108.9235 - val_loss: 110.5091\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 9ms/step - loss: 106.8043 - val_loss: 113.4688\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 12ms/step - loss: 103.1171 - val_loss: 109.9334\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 13ms/step - loss: 102.0734 - val_loss: 108.2466\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 3s - 109ms/step - loss: 2495.5298 - val_loss: 328.4205\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 6ms/step - loss: 350.2177 - val_loss: 279.8372\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 260.9467 - val_loss: 257.3045\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 242.1800 - val_loss: 239.1160\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 230.7873 - val_loss: 231.0969\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 220.7781 - val_loss: 220.9732\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 212.3310 - val_loss: 213.0615\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 205.1710 - val_loss: 204.9294\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 5ms/step - loss: 197.5469 - val_loss: 199.0729\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 191.4256 - val_loss: 191.8668\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 185.3658 - val_loss: 184.6718\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.7623 - val_loss: 178.5527\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 175.1648 - val_loss: 173.0141\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 5ms/step - loss: 168.9010 - val_loss: 170.2914\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 5ms/step - loss: 163.9104 - val_loss: 163.3680\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 159.3335 - val_loss: 160.1847\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.1054 - val_loss: 156.1050\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 5ms/step - loss: 150.8615 - val_loss: 154.2704\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 148.4081 - val_loss: 148.3067\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 143.8341 - val_loss: 144.8461\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 140.1941 - val_loss: 140.7883\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 5ms/step - loss: 138.1005 - val_loss: 138.1015\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.6707 - val_loss: 134.5717\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 131.0796 - val_loss: 132.0065\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 130.0783 - val_loss: 132.0300\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 124.6221 - val_loss: 125.8219\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.3981 - val_loss: 123.8973\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.6450 - val_loss: 126.5501\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 119.6694 - val_loss: 125.7642\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 7ms/step - loss: 116.9016 - val_loss: 120.9584\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.8272 - val_loss: 116.5226\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.2825 - val_loss: 114.9784\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 108.4495 - val_loss: 117.2562\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 107.7341 - val_loss: 117.6667\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 108.5708 - val_loss: 114.1694\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 5ms/step - loss: 106.0515 - val_loss: 116.9647\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 5ms/step - loss: 103.4890 - val_loss: 107.2516\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 99.9030 - val_loss: 103.9296\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 100.3271 - val_loss: 111.6566\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 96.4377 - val_loss: 102.8950\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 97.0668 - val_loss: 97.0447\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 7ms/step - loss: 94.2442 - val_loss: 96.7094\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 92.4563 - val_loss: 97.4339\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 5ms/step - loss: 91.4308 - val_loss: 93.8743\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 5ms/step - loss: 90.2474 - val_loss: 96.4939\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 87.6043 - val_loss: 90.0282\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 85.5947 - val_loss: 89.0683\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 83.7334 - val_loss: 87.8591\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.8061 - val_loss: 86.5416\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 7ms/step - loss: 81.1602 - val_loss: 85.4539\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 80.2451 - val_loss: 88.9249\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 5ms/step - loss: 81.5768 - val_loss: 85.1122\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 5ms/step - loss: 81.0782 - val_loss: 82.1315\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.8636 - val_loss: 81.5623\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 77.3087 - val_loss: 85.4671\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.2050 - val_loss: 85.9895\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.1322 - val_loss: 79.3495\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 75.5854 - val_loss: 77.7342\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 7ms/step - loss: 74.2071 - val_loss: 77.9753\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 5ms/step - loss: 73.1004 - val_loss: 79.2854\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 72.4403 - val_loss: 83.1287\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.4979 - val_loss: 75.9376\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 7ms/step - loss: 71.3318 - val_loss: 81.3269\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 12ms/step - loss: 71.2943 - val_loss: 75.1184\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 13ms/step - loss: 72.0633 - val_loss: 87.5237\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 13ms/step - loss: 72.7814 - val_loss: 76.6649\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 70.1093 - val_loss: 74.4626\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 14ms/step - loss: 69.6473 - val_loss: 72.6471\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.1100 - val_loss: 73.8997\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 7ms/step - loss: 67.7782 - val_loss: 73.2146\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 13ms/step - loss: 67.4739 - val_loss: 72.1980\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 14ms/step - loss: 67.9579 - val_loss: 70.7233\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 8ms/step - loss: 65.8170 - val_loss: 69.7687\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 11ms/step - loss: 64.9812 - val_loss: 71.0053\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 5ms/step - loss: 64.5238 - val_loss: 69.9458\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 64.1609 - val_loss: 71.6187\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 65.3025 - val_loss: 70.3484\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 5ms/step - loss: 63.0323 - val_loss: 70.6529\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 61.5064 - val_loss: 68.7217\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 62.4986 - val_loss: 68.6633\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 63.8022 - val_loss: 67.8821\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 66.9001 - val_loss: 78.3633\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 7ms/step - loss: 64.6044 - val_loss: 68.2131\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 5ms/step - loss: 63.3165 - val_loss: 69.3269\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 61.2350 - val_loss: 66.6741\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 58.9641 - val_loss: 64.8993\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 5ms/step - loss: 61.0012 - val_loss: 68.3640\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 60.4588 - val_loss: 77.2084\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 63.4026 - val_loss: 64.1651\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 59.8099 - val_loss: 66.5454\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 59.5256 - val_loss: 64.7412\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 57.7440 - val_loss: 63.2773\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 58.3441 - val_loss: 64.1123\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 7ms/step - loss: 57.6933 - val_loss: 64.1155\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 56.0217 - val_loss: 62.7473\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 55.8532 - val_loss: 61.9748\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 55.6633 - val_loss: 63.4338\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 55.2288 - val_loss: 62.7085\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 55.9660 - val_loss: 61.1523\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 55.1520 - val_loss: 61.5496\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 63ms/step - loss: 73515.3203 - val_loss: 24104.7266\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 10804.8857 - val_loss: 2705.8142\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 1147.8588 - val_loss: 473.0091\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 434.2912 - val_loss: 416.5638\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 5ms/step - loss: 377.3604 - val_loss: 340.7269\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 318.8604 - val_loss: 299.7194\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 292.9287 - val_loss: 277.1454\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 276.4717 - val_loss: 264.0618\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 265.8642 - val_loss: 255.1880\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 258.8072 - val_loss: 250.1189\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 253.6219 - val_loss: 247.0205\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 251.5060 - val_loss: 245.6277\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 248.6228 - val_loss: 241.4367\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 5ms/step - loss: 244.7264 - val_loss: 238.9433\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 241.6543 - val_loss: 236.2629\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 238.7364 - val_loss: 234.7481\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 236.4285 - val_loss: 233.3224\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 234.1279 - val_loss: 231.6026\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 232.0573 - val_loss: 229.0726\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 230.2708 - val_loss: 228.2209\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 229.0131 - val_loss: 225.1646\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 5ms/step - loss: 225.8739 - val_loss: 223.6071\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 5ms/step - loss: 224.2514 - val_loss: 224.3460\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 222.2409 - val_loss: 220.3673\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 221.1662 - val_loss: 218.4180\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 218.4511 - val_loss: 217.6238\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 7ms/step - loss: 217.1269 - val_loss: 215.4754\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 215.1318 - val_loss: 214.5331\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 212.7585 - val_loss: 212.3378\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 7ms/step - loss: 213.0229 - val_loss: 215.7679\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 5ms/step - loss: 210.8641 - val_loss: 209.4567\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 208.1431 - val_loss: 209.7790\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 206.2431 - val_loss: 208.0893\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 7ms/step - loss: 204.8331 - val_loss: 205.1837\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 5ms/step - loss: 203.7027 - val_loss: 206.5496\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 201.2684 - val_loss: 202.8605\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 199.8560 - val_loss: 200.9590\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 199.7254 - val_loss: 203.1333\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 13ms/step - loss: 196.5999 - val_loss: 198.4185\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 194.9669 - val_loss: 197.5983\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 7ms/step - loss: 194.0568 - val_loss: 196.6486\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 13ms/step - loss: 191.5404 - val_loss: 196.5381\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 13ms/step - loss: 190.5559 - val_loss: 193.2214\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 188.6768 - val_loss: 193.7798\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 14ms/step - loss: 187.2671 - val_loss: 192.8078\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 12ms/step - loss: 185.6417 - val_loss: 188.8108\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 13ms/step - loss: 183.2031 - val_loss: 188.8832\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 7ms/step - loss: 182.0848 - val_loss: 185.4023\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 180.4011 - val_loss: 185.4289\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 7ms/step - loss: 179.1051 - val_loss: 183.2279\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 5ms/step - loss: 178.6935 - val_loss: 182.2682\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 5ms/step - loss: 176.7471 - val_loss: 180.4840\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 173.6017 - val_loss: 180.0414\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 172.2398 - val_loss: 176.2548\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 169.8148 - val_loss: 175.2798\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 168.6652 - val_loss: 173.3520\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 7ms/step - loss: 166.6247 - val_loss: 171.9246\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 5ms/step - loss: 165.2188 - val_loss: 171.2704\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 163.0996 - val_loss: 168.4930\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 5ms/step - loss: 161.7800 - val_loss: 167.3062\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.8190 - val_loss: 168.0990\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 159.1828 - val_loss: 166.7119\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 157.7979 - val_loss: 166.9117\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.8068 - val_loss: 161.2963\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 152.8119 - val_loss: 158.5272\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 153.4216 - val_loss: 157.5217\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 5ms/step - loss: 151.8901 - val_loss: 155.9640\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 148.3409 - val_loss: 154.9445\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 5ms/step - loss: 146.2534 - val_loss: 156.6558\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 145.6880 - val_loss: 153.0821\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 144.4401 - val_loss: 151.2257\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 5ms/step - loss: 144.4158 - val_loss: 147.3425\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 141.0664 - val_loss: 145.2699\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 137.5561 - val_loss: 146.1157\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 7ms/step - loss: 136.4619 - val_loss: 143.5163\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 5ms/step - loss: 135.2356 - val_loss: 141.5079\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 5ms/step - loss: 134.8764 - val_loss: 152.9829\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 5ms/step - loss: 133.2455 - val_loss: 143.4082\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 130.8585 - val_loss: 142.7846\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 129.3935 - val_loss: 138.2013\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 129.1013 - val_loss: 132.6606\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 126.1981 - val_loss: 131.3333\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 124.0166 - val_loss: 129.1379\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 122.2854 - val_loss: 128.9015\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 5ms/step - loss: 122.8813 - val_loss: 129.8705\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 5ms/step - loss: 120.9016 - val_loss: 128.5059\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.0761 - val_loss: 130.4432\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.8407 - val_loss: 122.2241\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.4357 - val_loss: 121.6794\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.4969 - val_loss: 125.4484\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 7ms/step - loss: 118.4926 - val_loss: 118.9299\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.8376 - val_loss: 121.2251\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 7ms/step - loss: 110.3487 - val_loss: 114.7591\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.6276 - val_loss: 113.1977\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.8249 - val_loss: 111.9201\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.2690 - val_loss: 113.7377\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.6365 - val_loss: 115.3090\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 107.2754 - val_loss: 112.6558\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 105.6997 - val_loss: 113.8411\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 104.6135 - val_loss: 109.9357\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 60ms/step - loss: 3194.2568 - val_loss: 1081.9767\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 653.2695 - val_loss: 513.8557\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 425.9769 - val_loss: 421.6693\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 7ms/step - loss: 376.3870 - val_loss: 370.9501\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 5ms/step - loss: 334.5963 - val_loss: 337.4165\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 5ms/step - loss: 303.4002 - val_loss: 309.5778\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 277.0561 - val_loss: 286.4659\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 256.4480 - val_loss: 270.6382\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 242.2416 - val_loss: 250.5716\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 7ms/step - loss: 224.1678 - val_loss: 236.8607\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 210.2749 - val_loss: 221.8611\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 198.2881 - val_loss: 214.3500\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 189.6265 - val_loss: 199.6158\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 179.0025 - val_loss: 189.8759\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 168.9473 - val_loss: 183.1089\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 161.8957 - val_loss: 175.2727\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 8ms/step - loss: 154.4376 - val_loss: 161.6178\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 146.1903 - val_loss: 164.5442\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 13ms/step - loss: 140.5213 - val_loss: 147.6111\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 132.7531 - val_loss: 139.3757\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 13ms/step - loss: 126.8933 - val_loss: 134.3267\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.1316 - val_loss: 130.9937\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 123.3513 - val_loss: 127.1992\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 7ms/step - loss: 118.7425 - val_loss: 124.6137\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 13ms/step - loss: 113.3939 - val_loss: 118.4397\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.9773 - val_loss: 116.4775\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 13ms/step - loss: 108.3998 - val_loss: 112.8966\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 15ms/step - loss: 106.0794 - val_loss: 111.7947\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 104.6410 - val_loss: 108.8398\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 102.7230 - val_loss: 107.7644\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 102.8458 - val_loss: 106.0390\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 101.9606 - val_loss: 104.6428\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 7ms/step - loss: 99.8897 - val_loss: 104.7284\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 98.9030 - val_loss: 102.4898\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 95.9870 - val_loss: 101.8607\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 5ms/step - loss: 95.9580 - val_loss: 101.9584\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 96.4159 - val_loss: 101.9219\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 95.3924 - val_loss: 99.6518\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 93.7948 - val_loss: 98.3073\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 93.0992 - val_loss: 98.9064\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 92.7098 - val_loss: 101.2966\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 7ms/step - loss: 97.2152 - val_loss: 96.5783\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 92.1774 - val_loss: 96.5576\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 90.5866 - val_loss: 95.9512\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 89.8845 - val_loss: 95.2188\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 90.7020 - val_loss: 98.9100\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 89.8779 - val_loss: 96.7617\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 7ms/step - loss: 88.9919 - val_loss: 94.5427\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 89.7030 - val_loss: 93.4557\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 7ms/step - loss: 87.3988 - val_loss: 93.4016\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 5ms/step - loss: 86.0854 - val_loss: 92.8454\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 87.1966 - val_loss: 93.6304\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 86.3348 - val_loss: 93.1244\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 86.3822 - val_loss: 94.9376\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.6761 - val_loss: 92.5144\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.5643 - val_loss: 94.0554\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 87.2873 - val_loss: 92.1472\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 84.0812 - val_loss: 91.2238\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.1159 - val_loss: 90.6514\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 5ms/step - loss: 86.5641 - val_loss: 91.3456\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 83.0276 - val_loss: 90.8774\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.6458 - val_loss: 95.2775\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 86.1595 - val_loss: 90.4180\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 80.7790 - val_loss: 91.9304\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 82.0655 - val_loss: 88.2060\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 5ms/step - loss: 79.4092 - val_loss: 87.8594\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 79.8252 - val_loss: 87.5910\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 5ms/step - loss: 80.4139 - val_loss: 87.2480\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 7ms/step - loss: 79.2532 - val_loss: 87.6411\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 5ms/step - loss: 78.4606 - val_loss: 85.9237\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 76.5240 - val_loss: 86.3067\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 7ms/step - loss: 80.7271 - val_loss: 86.9546\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.3527 - val_loss: 85.7313\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 7ms/step - loss: 75.6786 - val_loss: 84.9111\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.0472 - val_loss: 85.2712\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.0679 - val_loss: 89.2549\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.3239 - val_loss: 93.5196\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 74.5155 - val_loss: 85.6677\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.0240 - val_loss: 83.0357\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 75.0589 - val_loss: 82.9960\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 74.4581 - val_loss: 83.2010\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 7ms/step - loss: 73.7220 - val_loss: 81.9579\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 74.0201 - val_loss: 83.8943\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 74.0640 - val_loss: 82.8581\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.1680 - val_loss: 84.1455\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 71.2601 - val_loss: 81.6582\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.6019 - val_loss: 82.0102\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.0877 - val_loss: 88.1113\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.4800 - val_loss: 81.7111\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 72.1932 - val_loss: 80.3327\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 5ms/step - loss: 70.7989 - val_loss: 81.3059\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 5ms/step - loss: 69.3534 - val_loss: 80.5226\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 68.7786 - val_loss: 79.4565\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 69.5214 - val_loss: 80.4763\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 5ms/step - loss: 69.2416 - val_loss: 79.1917\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.6984 - val_loss: 79.8285\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.9508 - val_loss: 80.6918\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.2246 - val_loss: 78.8624\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 7ms/step - loss: 67.5106 - val_loss: 98.3371\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.6767 - val_loss: 81.2064\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 73ms/step - loss: 903.1104 - val_loss: 640.0064\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 6ms/step - loss: 538.4715 - val_loss: 478.4225\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 474.3210 - val_loss: 439.2552\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 13ms/step - loss: 436.6653 - val_loss: 410.9230\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 407.5678 - val_loss: 388.7157\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 13ms/step - loss: 386.8757 - val_loss: 371.0835\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 365.2358 - val_loss: 351.9806\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 14ms/step - loss: 349.1467 - val_loss: 338.3079\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 12ms/step - loss: 327.3042 - val_loss: 321.0329\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 310.3865 - val_loss: 308.8904\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 7ms/step - loss: 293.9950 - val_loss: 289.9948\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 5ms/step - loss: 277.1441 - val_loss: 281.6010\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 263.7079 - val_loss: 272.9632\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 252.0526 - val_loss: 259.3564\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 233.5045 - val_loss: 246.4788\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 223.2802 - val_loss: 232.9131\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 7ms/step - loss: 213.7119 - val_loss: 223.9911\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 201.2816 - val_loss: 214.7869\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 196.9725 - val_loss: 205.3831\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 185.9099 - val_loss: 198.1610\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 181.4750 - val_loss: 193.1103\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 174.5851 - val_loss: 185.2522\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 169.5239 - val_loss: 180.0624\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 164.3489 - val_loss: 179.4339\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 162.8147 - val_loss: 174.2769\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 5ms/step - loss: 158.2741 - val_loss: 168.4921\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 156.2479 - val_loss: 167.7431\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 151.9059 - val_loss: 163.4877\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 7ms/step - loss: 150.7237 - val_loss: 161.9214\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 148.1172 - val_loss: 158.5195\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 146.5099 - val_loss: 158.6962\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 145.0908 - val_loss: 154.9624\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 144.4258 - val_loss: 154.9366\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 142.7553 - val_loss: 156.8657\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 145.6526 - val_loss: 157.9372\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 141.9364 - val_loss: 153.1218\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.7835 - val_loss: 147.9187\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 138.5486 - val_loss: 147.5036\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 137.3553 - val_loss: 147.4193\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 7ms/step - loss: 135.7209 - val_loss: 145.5304\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.8570 - val_loss: 149.0768\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 5ms/step - loss: 134.6065 - val_loss: 143.3530\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 5ms/step - loss: 132.5495 - val_loss: 140.7062\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 129.8815 - val_loss: 139.6812\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 128.3196 - val_loss: 144.7982\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 125.8281 - val_loss: 136.7901\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 7ms/step - loss: 124.0472 - val_loss: 135.1086\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 8ms/step - loss: 125.4803 - val_loss: 134.6685\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 13ms/step - loss: 122.4325 - val_loss: 136.3215\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 13ms/step - loss: 122.5957 - val_loss: 142.0343\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 9ms/step - loss: 120.8522 - val_loss: 132.2462\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 12ms/step - loss: 119.8430 - val_loss: 130.0357\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 7ms/step - loss: 119.1839 - val_loss: 130.3818\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 6ms/step - loss: 118.3403 - val_loss: 131.2159\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 7ms/step - loss: 119.1923 - val_loss: 128.0177\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 12ms/step - loss: 119.5957 - val_loss: 127.5511\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 5ms/step - loss: 117.9018 - val_loss: 129.2192\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.8053 - val_loss: 127.2440\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 5ms/step - loss: 117.8759 - val_loss: 126.6450\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.4517 - val_loss: 125.1800\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.3555 - val_loss: 128.7558\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 118.2159 - val_loss: 128.3754\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 5ms/step - loss: 113.9775 - val_loss: 124.5088\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.0776 - val_loss: 123.3209\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.2110 - val_loss: 123.1779\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.3756 - val_loss: 123.0106\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 5ms/step - loss: 111.5435 - val_loss: 122.6670\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 5ms/step - loss: 110.4802 - val_loss: 123.4834\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.1180 - val_loss: 124.6273\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.5637 - val_loss: 121.8841\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.0809 - val_loss: 121.6673\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.5547 - val_loss: 121.2328\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.0533 - val_loss: 121.5751\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 7ms/step - loss: 109.5543 - val_loss: 123.8640\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.2963 - val_loss: 127.3451\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 108.5157 - val_loss: 126.0367\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 113.3281 - val_loss: 120.1072\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.0167 - val_loss: 125.4461\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 107.2411 - val_loss: 126.2963\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 109.1863 - val_loss: 121.4505\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 106.9339 - val_loss: 121.9722\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 106.9074 - val_loss: 124.2019\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.3526 - val_loss: 131.9824\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 8ms/step - loss: 111.6853 - val_loss: 119.0149\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 13ms/step - loss: 106.5644 - val_loss: 118.2862\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 106.3031 - val_loss: 118.3199\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 13ms/step - loss: 105.2679 - val_loss: 118.3042\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 7ms/step - loss: 106.2611 - val_loss: 118.7656\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 7ms/step - loss: 108.5527 - val_loss: 121.3191\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 13ms/step - loss: 105.7033 - val_loss: 123.7268\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 13ms/step - loss: 105.5194 - val_loss: 117.9435\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 13ms/step - loss: 104.4767 - val_loss: 118.0242\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 13ms/step - loss: 104.3684 - val_loss: 117.4343\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 11ms/step - loss: 103.7997 - val_loss: 123.8842\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 105.4271 - val_loss: 117.1869\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 103.7685 - val_loss: 118.3215\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 104.5692 - val_loss: 116.8842\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 6ms/step - loss: 103.6276 - val_loss: 117.7265\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 103.8340 - val_loss: 116.3390\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 7ms/step - loss: 103.6521 - val_loss: 119.0842\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 61ms/step - loss: 578.8975 - val_loss: 382.1104\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 6ms/step - loss: 362.4791 - val_loss: 317.8554\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 301.3064 - val_loss: 276.7756\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 272.5647 - val_loss: 260.8304\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 5ms/step - loss: 256.3355 - val_loss: 250.0187\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 245.4228 - val_loss: 241.4933\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 236.5489 - val_loss: 235.0340\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 230.4670 - val_loss: 229.1660\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 5ms/step - loss: 225.3571 - val_loss: 225.2414\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 5ms/step - loss: 221.8282 - val_loss: 222.0385\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 218.3692 - val_loss: 218.7316\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 215.6377 - val_loss: 213.1017\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 213.0941 - val_loss: 214.3716\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 210.5362 - val_loss: 209.4438\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 209.4770 - val_loss: 206.1449\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 206.9378 - val_loss: 206.2101\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 5ms/step - loss: 205.0762 - val_loss: 204.9252\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 204.1963 - val_loss: 201.2044\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 202.0507 - val_loss: 200.0931\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 200.1513 - val_loss: 198.1761\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 198.4134 - val_loss: 199.1003\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 197.0935 - val_loss: 196.9903\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 197.1546 - val_loss: 195.3568\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 196.8941 - val_loss: 200.4238\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 5ms/step - loss: 195.0548 - val_loss: 192.9712\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 193.6790 - val_loss: 190.0607\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 5ms/step - loss: 191.5146 - val_loss: 189.2924\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 188.7103 - val_loss: 188.5093\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 187.5551 - val_loss: 186.7663\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 189.5943 - val_loss: 187.3391\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 186.1169 - val_loss: 188.1464\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.9125 - val_loss: 183.0127\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 183.4901 - val_loss: 181.3828\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 181.7924 - val_loss: 179.9977\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 181.2940 - val_loss: 178.5497\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 179.0968 - val_loss: 177.3003\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 179.6481 - val_loss: 178.7717\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 176.7615 - val_loss: 176.9646\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.6226 - val_loss: 173.2657\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 176.0496 - val_loss: 172.6173\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 7ms/step - loss: 172.0368 - val_loss: 174.7298\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 4ms/step - loss: 173.6098 - val_loss: 169.9832\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 7ms/step - loss: 170.2045 - val_loss: 169.7563\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 5ms/step - loss: 169.3109 - val_loss: 168.1150\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 168.7807 - val_loss: 169.3720\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 166.7643 - val_loss: 168.4755\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 165.5979 - val_loss: 164.8374\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 168.5465 - val_loss: 172.6756\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.1985 - val_loss: 167.7467\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 5ms/step - loss: 164.8100 - val_loss: 161.9636\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 5ms/step - loss: 161.5519 - val_loss: 161.8476\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 160.9005 - val_loss: 160.6689\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.4865 - val_loss: 159.3438\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 7ms/step - loss: 157.8201 - val_loss: 160.1732\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 156.2818 - val_loss: 157.3320\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 155.9455 - val_loss: 156.1905\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.3763 - val_loss: 157.3747\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 5ms/step - loss: 153.2583 - val_loss: 155.1712\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.9267 - val_loss: 155.9663\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.3496 - val_loss: 152.2536\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 8ms/step - loss: 151.0783 - val_loss: 151.7884\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 12ms/step - loss: 149.2335 - val_loss: 152.8001\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 7ms/step - loss: 148.7867 - val_loss: 149.6443\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 13ms/step - loss: 147.6553 - val_loss: 154.6126\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 12ms/step - loss: 147.6572 - val_loss: 148.1397\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 146.6223 - val_loss: 148.8249\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 144.6915 - val_loss: 145.7064\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 7ms/step - loss: 144.0408 - val_loss: 146.2189\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 15ms/step - loss: 142.3345 - val_loss: 144.9696\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 11ms/step - loss: 142.6652 - val_loss: 143.4209\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 13ms/step - loss: 141.6316 - val_loss: 142.3172\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 5ms/step - loss: 141.1717 - val_loss: 141.4680\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 4ms/step - loss: 139.8787 - val_loss: 145.2012\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 139.1078 - val_loss: 146.0189\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 7ms/step - loss: 138.5254 - val_loss: 138.6185\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 136.4073 - val_loss: 138.3265\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 136.1150 - val_loss: 136.7765\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.9104 - val_loss: 135.7485\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 134.1021 - val_loss: 135.2249\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 5ms/step - loss: 132.2283 - val_loss: 134.7337\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 132.1830 - val_loss: 133.7333\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 131.2576 - val_loss: 133.5672\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 130.0188 - val_loss: 132.3149\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 128.9463 - val_loss: 132.5715\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 128.5128 - val_loss: 130.5575\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 127.5115 - val_loss: 130.7693\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 126.4504 - val_loss: 130.0126\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 7ms/step - loss: 127.5439 - val_loss: 129.0988\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 5ms/step - loss: 125.7626 - val_loss: 128.0721\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 124.3782 - val_loss: 128.5658\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 124.7219 - val_loss: 130.7935\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 124.3026 - val_loss: 125.8441\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.0122 - val_loss: 126.4089\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 122.2734 - val_loss: 125.1154\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 5ms/step - loss: 125.1657 - val_loss: 125.4144\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 5ms/step - loss: 121.0088 - val_loss: 123.3558\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 5ms/step - loss: 118.8732 - val_loss: 123.3935\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.3326 - val_loss: 126.0523\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 116.5871 - val_loss: 121.7141\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.8687 - val_loss: 120.8971\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 58ms/step - loss: 478.6583 - val_loss: 303.4160\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 278.1461 - val_loss: 270.2851\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 253.0364 - val_loss: 248.4256\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 238.0594 - val_loss: 225.3809\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 221.4591 - val_loss: 216.3904\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 212.7760 - val_loss: 210.9934\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 203.7303 - val_loss: 204.4212\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 5ms/step - loss: 197.0466 - val_loss: 197.3777\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 195.5231 - val_loss: 195.7643\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 188.6917 - val_loss: 191.9533\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 7ms/step - loss: 187.2015 - val_loss: 184.9957\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 178.5979 - val_loss: 191.1658\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 175.6735 - val_loss: 180.5840\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 171.2381 - val_loss: 178.2070\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.7913 - val_loss: 171.3568\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 164.4435 - val_loss: 169.9263\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 5ms/step - loss: 160.2487 - val_loss: 165.9790\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 158.1454 - val_loss: 161.9198\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 156.6814 - val_loss: 161.9426\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 153.5630 - val_loss: 157.1249\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 7ms/step - loss: 148.7350 - val_loss: 157.3790\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 147.7574 - val_loss: 159.9846\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 144.0988 - val_loss: 153.3490\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 4ms/step - loss: 140.5897 - val_loss: 149.7548\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 5ms/step - loss: 137.5338 - val_loss: 161.6161\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 5ms/step - loss: 141.9858 - val_loss: 148.5995\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 133.6424 - val_loss: 142.5410\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 130.9660 - val_loss: 139.3103\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 128.7111 - val_loss: 137.2901\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 126.5550 - val_loss: 138.7212\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 125.4810 - val_loss: 133.7512\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.7380 - val_loss: 136.7651\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 120.4077 - val_loss: 130.2931\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.8261 - val_loss: 128.6788\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 117.1061 - val_loss: 129.7504\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.8992 - val_loss: 125.4138\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.4710 - val_loss: 127.7290\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.8516 - val_loss: 123.3234\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 110.2788 - val_loss: 120.4927\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 108.2902 - val_loss: 119.1585\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 7ms/step - loss: 107.2755 - val_loss: 117.8705\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 7ms/step - loss: 109.0597 - val_loss: 120.2731\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 11ms/step - loss: 106.5101 - val_loss: 115.4941\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 104.5268 - val_loss: 118.4554\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 7ms/step - loss: 100.8633 - val_loss: 112.4394\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 101.6632 - val_loss: 115.7677\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 6ms/step - loss: 100.7081 - val_loss: 111.9149\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 13ms/step - loss: 102.6736 - val_loss: 112.5552\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 13ms/step - loss: 104.5472 - val_loss: 109.3729\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 12ms/step - loss: 96.7315 - val_loss: 108.6749\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 13ms/step - loss: 96.5326 - val_loss: 106.0178\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 12ms/step - loss: 94.5620 - val_loss: 107.3858\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 94.1784 - val_loss: 105.6270\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 93.0657 - val_loss: 114.3211\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 94.4857 - val_loss: 109.4269\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 93.3205 - val_loss: 105.0730\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 92.8986 - val_loss: 100.4649\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 89.8983 - val_loss: 99.2448\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 88.5897 - val_loss: 100.7861\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 88.0650 - val_loss: 98.0249\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 7ms/step - loss: 87.4978 - val_loss: 101.7719\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 88.3200 - val_loss: 95.8885\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 5ms/step - loss: 87.0984 - val_loss: 94.9220\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.0543 - val_loss: 95.5336\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.6654 - val_loss: 94.4980\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 88.0192 - val_loss: 93.6285\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 84.2014 - val_loss: 92.3000\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 82.0046 - val_loss: 92.1485\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 82.1387 - val_loss: 92.2568\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 7ms/step - loss: 80.7646 - val_loss: 91.1013\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 80.4069 - val_loss: 90.4431\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 80.2823 - val_loss: 89.7251\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 5ms/step - loss: 79.3001 - val_loss: 89.2300\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 79.3977 - val_loss: 91.2259\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 78.9333 - val_loss: 89.8725\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 79.3525 - val_loss: 93.8724\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 78.7815 - val_loss: 87.2690\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 76.5178 - val_loss: 86.4477\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 76.7192 - val_loss: 85.8214\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 5ms/step - loss: 77.8212 - val_loss: 87.2043\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.3669 - val_loss: 86.1388\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 76.7552 - val_loss: 84.5269\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.8504 - val_loss: 83.8649\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.0107 - val_loss: 83.5527\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.1632 - val_loss: 92.4258\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.5927 - val_loss: 97.6523\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 7ms/step - loss: 74.3591 - val_loss: 83.5411\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 7ms/step - loss: 73.3972 - val_loss: 82.3475\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 5ms/step - loss: 74.1934 - val_loss: 84.4192\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.3182 - val_loss: 88.0760\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.4390 - val_loss: 82.0751\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.2925 - val_loss: 81.3455\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.1427 - val_loss: 83.2486\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.8148 - val_loss: 83.7249\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.4581 - val_loss: 81.6299\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 72.1202 - val_loss: 80.8700\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 5ms/step - loss: 71.5566 - val_loss: 81.9890\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.4723 - val_loss: 80.7400\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 5ms/step - loss: 71.0418 - val_loss: 79.0586\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 70.6604 - val_loss: 79.0005\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 60ms/step - loss: 11462.2441 - val_loss: 3313.7021\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 1434.8799 - val_loss: 601.1813\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 567.5970 - val_loss: 457.3670\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 462.6411 - val_loss: 406.4020\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 397.5242 - val_loss: 387.6753\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 5ms/step - loss: 360.0227 - val_loss: 335.4921\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 322.9182 - val_loss: 303.8752\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 291.6978 - val_loss: 269.1824\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 5ms/step - loss: 269.4152 - val_loss: 247.8561\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 249.8862 - val_loss: 231.3827\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 229.9614 - val_loss: 216.7251\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 215.5729 - val_loss: 223.3723\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 208.5332 - val_loss: 203.9128\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 190.6841 - val_loss: 183.3865\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 187.5167 - val_loss: 200.2244\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 178.6482 - val_loss: 188.5409\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 169.7533 - val_loss: 164.6963\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 169.1370 - val_loss: 160.9473\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 7ms/step - loss: 161.2948 - val_loss: 167.5416\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 156.6599 - val_loss: 155.4049\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 157.5893 - val_loss: 164.6729\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 151.0363 - val_loss: 150.3843\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 14ms/step - loss: 146.3313 - val_loss: 169.2759\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 12ms/step - loss: 147.0994 - val_loss: 154.3338\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 7ms/step - loss: 145.1217 - val_loss: 149.8519\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 143.9521 - val_loss: 142.5281\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 139.6414 - val_loss: 141.6846\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 142.0213 - val_loss: 142.4366\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 13ms/step - loss: 136.1527 - val_loss: 138.3296\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 137.7725 - val_loss: 138.7555\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 13ms/step - loss: 137.5286 - val_loss: 144.9532\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 14ms/step - loss: 131.6326 - val_loss: 134.2654\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 11ms/step - loss: 132.4561 - val_loss: 131.0737\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 131.2531 - val_loss: 129.8915\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 126.9034 - val_loss: 128.4796\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 127.2869 - val_loss: 126.2917\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 124.9171 - val_loss: 123.2871\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 7ms/step - loss: 120.9367 - val_loss: 120.6227\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.1730 - val_loss: 130.7830\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 120.3298 - val_loss: 117.1905\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.7650 - val_loss: 115.3554\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 5ms/step - loss: 113.3248 - val_loss: 112.1701\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.4141 - val_loss: 112.3334\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.7006 - val_loss: 109.4848\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.6253 - val_loss: 115.3611\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 6ms/step - loss: 114.0333 - val_loss: 113.7483\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 115.0408 - val_loss: 102.9844\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 5ms/step - loss: 102.3043 - val_loss: 112.2290\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 5ms/step - loss: 103.6632 - val_loss: 101.4499\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 100.3058 - val_loss: 98.4621\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 98.6299 - val_loss: 96.4737\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 96.5677 - val_loss: 96.1653\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 7ms/step - loss: 96.2813 - val_loss: 96.0480\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 95.0588 - val_loss: 93.5622\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 5ms/step - loss: 93.2763 - val_loss: 92.4684\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 91.0221 - val_loss: 91.8863\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 5ms/step - loss: 90.8751 - val_loss: 90.0248\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 5ms/step - loss: 91.0732 - val_loss: 111.7863\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 89.4175 - val_loss: 88.3755\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 88.8549 - val_loss: 89.0130\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 87.2774 - val_loss: 85.9555\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 89.4272 - val_loss: 87.6097\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 5ms/step - loss: 88.2366 - val_loss: 93.2583\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 84.6258 - val_loss: 84.5679\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 5ms/step - loss: 83.6685 - val_loss: 82.6352\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 85.7525 - val_loss: 83.2248\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.4483 - val_loss: 82.8912\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 80.6617 - val_loss: 80.7349\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 80.3650 - val_loss: 81.0309\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 82.1840 - val_loss: 97.6048\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 86.3425 - val_loss: 78.9049\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.2496 - val_loss: 78.3893\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 80.9572 - val_loss: 77.1606\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 77.3228 - val_loss: 80.9365\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.9815 - val_loss: 84.8680\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 81.4516 - val_loss: 84.8352\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 78.6889 - val_loss: 76.4140\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 77.8733 - val_loss: 78.6186\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.7737 - val_loss: 79.8714\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.4603 - val_loss: 77.1930\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 4ms/step - loss: 84.2820 - val_loss: 88.6755\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 86.8754 - val_loss: 91.0539\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.5546 - val_loss: 84.5414\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 7ms/step - loss: 75.7288 - val_loss: 84.9137\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.1853 - val_loss: 79.9589\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.0372 - val_loss: 76.9846\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 76.9068 - val_loss: 81.3532\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.3653 - val_loss: 72.3412\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.1777 - val_loss: 75.8732\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.5396 - val_loss: 71.5646\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 5ms/step - loss: 71.3297 - val_loss: 71.5938\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.1450 - val_loss: 72.1351\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 74.3511 - val_loss: 79.0413\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 76.0435 - val_loss: 75.6666\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.0745 - val_loss: 70.8285\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 4ms/step - loss: 68.8458 - val_loss: 71.4013\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 75.5641 - val_loss: 69.8565\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.1770 - val_loss: 76.3490\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.1633 - val_loss: 87.0737\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 68.1582 - val_loss: 70.4091\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 58ms/step - loss: 2664.4587 - val_loss: 1632.1923\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 9ms/step - loss: 1543.7463 - val_loss: 1614.0215\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 9ms/step - loss: 1534.6527 - val_loss: 1612.3788\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 1533.0841 - val_loss: 1610.8788\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 1531.6069 - val_loss: 1609.3193\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 6ms/step - loss: 1530.0853 - val_loss: 1607.7534\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 1528.5594 - val_loss: 1606.1659\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 1527.0251 - val_loss: 1604.5729\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 13ms/step - loss: 1525.4733 - val_loss: 1602.9890\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 13ms/step - loss: 1523.9347 - val_loss: 1601.3639\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 13ms/step - loss: 1522.3652 - val_loss: 1599.7638\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 12ms/step - loss: 1520.8058 - val_loss: 1598.1663\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 7ms/step - loss: 1519.2451 - val_loss: 1596.5386\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 14ms/step - loss: 1517.6715 - val_loss: 1594.9161\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 9ms/step - loss: 1516.1082 - val_loss: 1593.2937\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 1514.5327 - val_loss: 1591.6819\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 1512.9702 - val_loss: 1590.0616\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 1511.3916 - val_loss: 1588.4579\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 7ms/step - loss: 1509.8234 - val_loss: 1586.8301\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 1508.2454 - val_loss: 1585.2081\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 1506.6742 - val_loss: 1583.5669\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 7ms/step - loss: 1505.0887 - val_loss: 1581.9384\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 1503.5135 - val_loss: 1580.3246\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 1501.9456 - val_loss: 1578.6893\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 1500.3660 - val_loss: 1577.0681\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 1498.8029 - val_loss: 1575.4454\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 7ms/step - loss: 1497.2224 - val_loss: 1573.8413\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 1495.6649 - val_loss: 1572.2219\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 1494.0986 - val_loss: 1570.6099\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 1492.5334 - val_loss: 1568.9982\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 1490.9609 - val_loss: 1567.3916\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 1489.3973 - val_loss: 1565.7574\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 1487.8230 - val_loss: 1564.1414\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 1486.2585 - val_loss: 1562.5179\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 1484.6901 - val_loss: 1560.9059\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 1483.1262 - val_loss: 1559.2898\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 7ms/step - loss: 1481.5665 - val_loss: 1557.6827\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 5ms/step - loss: 1480.0071 - val_loss: 1556.0698\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 1478.4397 - val_loss: 1554.4705\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 1476.8865 - val_loss: 1552.8531\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 1475.3284 - val_loss: 1551.2294\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 7ms/step - loss: 1473.7571 - val_loss: 1549.6287\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 1472.2001 - val_loss: 1548.0272\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 1470.6415 - val_loss: 1546.4254\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 5ms/step - loss: 1469.0892 - val_loss: 1544.8062\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 7ms/step - loss: 1467.5265 - val_loss: 1543.2074\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 1465.9806 - val_loss: 1541.5955\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 1464.4196 - val_loss: 1540.0061\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 1462.8734 - val_loss: 1538.3958\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 5ms/step - loss: 1461.3163 - val_loss: 1536.7970\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 6ms/step - loss: 1459.7664 - val_loss: 1535.1968\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 7ms/step - loss: 1458.2167 - val_loss: 1533.5885\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 5ms/step - loss: 1456.6620 - val_loss: 1531.9967\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 1455.1179 - val_loss: 1530.4174\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 4ms/step - loss: 1453.5829 - val_loss: 1528.8060\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 1452.0311 - val_loss: 1527.2152\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 1450.4867 - val_loss: 1525.6334\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 7ms/step - loss: 1448.9540 - val_loss: 1524.0491\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 6ms/step - loss: 1447.4167 - val_loss: 1522.4513\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 1445.8729 - val_loss: 1520.8738\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 1444.3453 - val_loss: 1519.2933\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 1442.8112 - val_loss: 1517.7108\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 1441.2854 - val_loss: 1516.1118\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 1439.7405 - val_loss: 1514.5563\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 1438.2235 - val_loss: 1512.9625\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 5ms/step - loss: 1436.6885 - val_loss: 1511.3878\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 1435.1608 - val_loss: 1509.8081\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 7ms/step - loss: 1433.6311 - val_loss: 1508.2334\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 4ms/step - loss: 1432.1057 - val_loss: 1506.6542\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 1430.5764 - val_loss: 1505.0809\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 1429.0527 - val_loss: 1503.5022\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 1427.5295 - val_loss: 1501.9271\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 7ms/step - loss: 1426.0045 - val_loss: 1500.3674\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 6ms/step - loss: 1424.4962 - val_loss: 1498.7927\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 1422.9688 - val_loss: 1497.2391\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 7ms/step - loss: 1421.4645 - val_loss: 1495.6564\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 1419.9415 - val_loss: 1494.0983\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 1418.4247 - val_loss: 1492.5457\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 1416.9116 - val_loss: 1490.9778\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 1415.3940 - val_loss: 1489.4078\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 1413.8810 - val_loss: 1487.8412\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 1412.3652 - val_loss: 1486.2839\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 1410.8582 - val_loss: 1484.7236\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 1409.3475 - val_loss: 1483.1605\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 1407.8380 - val_loss: 1481.6075\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 1406.3340 - val_loss: 1480.0557\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 7ms/step - loss: 1404.8270 - val_loss: 1478.5071\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 1403.3260 - val_loss: 1476.9495\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 1401.8273 - val_loss: 1475.3837\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 1400.3182 - val_loss: 1473.8409\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 5ms/step - loss: 1398.8226 - val_loss: 1472.2927\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 1397.3260 - val_loss: 1470.7521\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 1395.8259 - val_loss: 1469.2048\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 1394.3279 - val_loss: 1467.6548\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 13ms/step - loss: 1392.8326 - val_loss: 1466.1018\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 13ms/step - loss: 1391.3351 - val_loss: 1464.5656\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 14ms/step - loss: 1389.8395 - val_loss: 1463.0287\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 13ms/step - loss: 1388.3539 - val_loss: 1461.4686\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 7ms/step - loss: 1386.8501 - val_loss: 1459.9469\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 8ms/step - loss: 1385.3726 - val_loss: 1458.3954\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 62ms/step - loss: 1965.2740 - val_loss: 854.5081\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 556.5156 - val_loss: 398.4313\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 392.4484 - val_loss: 331.0229\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 329.9196 - val_loss: 298.6562\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 297.2414 - val_loss: 274.2610\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 274.8034 - val_loss: 257.2314\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 255.2480 - val_loss: 249.5033\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 4ms/step - loss: 239.9575 - val_loss: 229.0192\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 222.3212 - val_loss: 217.4729\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 205.1281 - val_loss: 203.3931\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 5ms/step - loss: 190.9780 - val_loss: 191.2488\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.9092 - val_loss: 179.4319\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 4ms/step - loss: 163.7379 - val_loss: 168.4875\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 150.8248 - val_loss: 160.7486\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 139.8998 - val_loss: 153.2684\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 131.1525 - val_loss: 142.3752\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 122.8458 - val_loss: 135.2964\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.1096 - val_loss: 131.0197\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.2945 - val_loss: 125.4698\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 6ms/step - loss: 106.4673 - val_loss: 121.6594\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 103.0104 - val_loss: 119.4458\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 5ms/step - loss: 100.3453 - val_loss: 115.7313\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 98.8061 - val_loss: 114.0280\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 96.7765 - val_loss: 112.3232\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 4ms/step - loss: 93.8324 - val_loss: 110.7434\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 7ms/step - loss: 93.2290 - val_loss: 108.8099\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 5ms/step - loss: 95.9279 - val_loss: 108.3548\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 6ms/step - loss: 90.9003 - val_loss: 106.4765\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 90.6425 - val_loss: 105.1515\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 4ms/step - loss: 89.0591 - val_loss: 103.8531\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 88.3652 - val_loss: 103.4085\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 88.2798 - val_loss: 102.0259\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 86.8051 - val_loss: 100.6082\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 85.8652 - val_loss: 106.9377\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 86.0246 - val_loss: 101.6704\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.4298 - val_loss: 97.7937\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.5932 - val_loss: 97.5042\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 82.3304 - val_loss: 98.2708\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 7ms/step - loss: 81.8070 - val_loss: 96.6030\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 82.3858 - val_loss: 94.9356\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 81.5980 - val_loss: 94.8708\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 7ms/step - loss: 80.4418 - val_loss: 93.7872\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 5ms/step - loss: 80.5657 - val_loss: 94.4444\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 4ms/step - loss: 80.7529 - val_loss: 92.6817\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 79.1772 - val_loss: 92.3766\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 79.0573 - val_loss: 91.7733\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 79.7768 - val_loss: 91.3967\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 81.7053 - val_loss: 92.2844\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 77.1852 - val_loss: 90.0049\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 7ms/step - loss: 78.0300 - val_loss: 90.1493\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 5ms/step - loss: 76.9995 - val_loss: 90.2811\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 4ms/step - loss: 74.6065 - val_loss: 88.0771\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.8770 - val_loss: 87.6100\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.4324 - val_loss: 87.4434\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.6512 - val_loss: 89.7504\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.4394 - val_loss: 87.1047\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 7ms/step - loss: 75.5567 - val_loss: 89.4751\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 5ms/step - loss: 74.4837 - val_loss: 84.5507\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 7ms/step - loss: 72.9452 - val_loss: 88.1069\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 5ms/step - loss: 71.9094 - val_loss: 82.8844\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 5ms/step - loss: 71.4241 - val_loss: 82.3621\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 5ms/step - loss: 69.6491 - val_loss: 91.5309\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 5ms/step - loss: 70.8652 - val_loss: 82.5157\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.8959 - val_loss: 81.1554\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 69.3763 - val_loss: 81.5631\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.9149 - val_loss: 79.5333\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 5ms/step - loss: 69.0690 - val_loss: 80.0321\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 5ms/step - loss: 68.5221 - val_loss: 78.2671\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.3031 - val_loss: 79.8043\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.8058 - val_loss: 78.9315\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.0887 - val_loss: 76.9722\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 69.1490 - val_loss: 77.2092\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 8ms/step - loss: 66.6407 - val_loss: 78.8773\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 13ms/step - loss: 68.1818 - val_loss: 76.6126\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 13ms/step - loss: 65.6916 - val_loss: 74.1524\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 64.5359 - val_loss: 79.9583\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 5ms/step - loss: 64.7157 - val_loss: 75.1435\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 63.9183 - val_loss: 73.8258\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 7ms/step - loss: 63.8745 - val_loss: 84.2518\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 8ms/step - loss: 65.8996 - val_loss: 71.8641\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 12ms/step - loss: 62.8494 - val_loss: 73.3906\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 7ms/step - loss: 62.7808 - val_loss: 72.1731\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 62.6915 - val_loss: 71.2645\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 7ms/step - loss: 64.9469 - val_loss: 69.3639\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 10ms/step - loss: 59.9934 - val_loss: 73.2743\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 10ms/step - loss: 62.3105 - val_loss: 68.8581\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 5ms/step - loss: 63.6721 - val_loss: 74.7719\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 60.0259 - val_loss: 67.0654\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 58.9104 - val_loss: 65.7510\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 59.6658 - val_loss: 65.7539\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 7ms/step - loss: 57.3115 - val_loss: 66.9001\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 57.6264 - val_loss: 63.8780\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 56.1364 - val_loss: 63.8180\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 55.8793 - val_loss: 63.8040\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 4ms/step - loss: 58.8402 - val_loss: 64.7291\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 58.0567 - val_loss: 66.7973\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 59.1068 - val_loss: 64.3527\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 57.7041 - val_loss: 61.5703\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 5ms/step - loss: 53.0715 - val_loss: 60.2332\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 53.3558 - val_loss: 60.0405\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 60ms/step - loss: 4080.6348 - val_loss: 760.6476\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 8ms/step - loss: 647.2589 - val_loss: 453.6280\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 436.4026 - val_loss: 407.7967\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 7ms/step - loss: 381.8116 - val_loss: 367.9499\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 5ms/step - loss: 333.0452 - val_loss: 318.8182\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 5ms/step - loss: 277.5948 - val_loss: 245.7928\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 223.8145 - val_loss: 205.3813\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 197.6742 - val_loss: 193.6190\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 187.2801 - val_loss: 191.0057\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 180.6081 - val_loss: 186.9031\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 174.2897 - val_loss: 183.9457\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.4717 - val_loss: 172.4114\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 164.2089 - val_loss: 165.2680\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 4ms/step - loss: 160.4596 - val_loss: 161.4806\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 156.6207 - val_loss: 158.6164\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 152.0891 - val_loss: 155.2015\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 149.6353 - val_loss: 152.2936\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 5ms/step - loss: 146.4216 - val_loss: 149.9529\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 143.1006 - val_loss: 152.0907\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 7ms/step - loss: 145.2324 - val_loss: 145.9894\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 140.8002 - val_loss: 144.8244\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 137.2951 - val_loss: 143.2800\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 6ms/step - loss: 135.8374 - val_loss: 141.5728\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 6ms/step - loss: 132.9052 - val_loss: 143.0010\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 131.5668 - val_loss: 137.2859\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 5ms/step - loss: 130.3710 - val_loss: 134.9367\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 5ms/step - loss: 133.7143 - val_loss: 140.2553\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 129.2464 - val_loss: 133.0139\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 130.4336 - val_loss: 129.2718\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 125.0551 - val_loss: 126.3336\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 121.1680 - val_loss: 126.2597\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.7496 - val_loss: 122.5708\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 7ms/step - loss: 119.7449 - val_loss: 122.4868\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 119.8412 - val_loss: 119.3894\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.2314 - val_loss: 119.0756\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.3380 - val_loss: 115.9934\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 7ms/step - loss: 114.3294 - val_loss: 115.1571\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 112.1971 - val_loss: 117.3692\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 110.4742 - val_loss: 112.2271\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 108.0007 - val_loss: 110.8724\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.3366 - val_loss: 108.9250\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 5ms/step - loss: 106.5362 - val_loss: 107.9117\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 103.9528 - val_loss: 108.4510\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 104.9910 - val_loss: 111.9532\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 102.9927 - val_loss: 109.0088\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 101.4988 - val_loss: 105.1307\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 105.8238 - val_loss: 105.9651\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 102.3222 - val_loss: 101.8993\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 6ms/step - loss: 99.8437 - val_loss: 100.7309\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 97.9240 - val_loss: 100.0303\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 5ms/step - loss: 96.5743 - val_loss: 104.3544\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 7ms/step - loss: 95.3816 - val_loss: 106.2970\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 7ms/step - loss: 96.4116 - val_loss: 98.8830\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 5ms/step - loss: 93.6718 - val_loss: 97.8277\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 96.7348 - val_loss: 96.6261\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 14ms/step - loss: 93.3901 - val_loss: 93.9185\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 6ms/step - loss: 95.4837 - val_loss: 94.8216\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 13ms/step - loss: 92.6726 - val_loss: 94.3354\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 13ms/step - loss: 91.6310 - val_loss: 92.9267\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 13ms/step - loss: 89.7176 - val_loss: 90.5279\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 86.7400 - val_loss: 90.6915\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 14ms/step - loss: 88.8685 - val_loss: 94.0393\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 88.4715 - val_loss: 90.0323\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 7ms/step - loss: 85.2866 - val_loss: 86.1749\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 11ms/step - loss: 83.9272 - val_loss: 85.3413\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 84.8354 - val_loss: 89.9274\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 84.3224 - val_loss: 93.5165\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 83.9872 - val_loss: 86.6285\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 5ms/step - loss: 85.9364 - val_loss: 81.7777\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 81.4185 - val_loss: 80.6839\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.2351 - val_loss: 83.1704\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 5ms/step - loss: 82.3284 - val_loss: 80.9658\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.8102 - val_loss: 84.5151\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 5ms/step - loss: 80.9275 - val_loss: 79.3828\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 4ms/step - loss: 78.2562 - val_loss: 79.2114\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.0471 - val_loss: 80.1257\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.7550 - val_loss: 77.7225\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 76.9408 - val_loss: 78.7740\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 5ms/step - loss: 75.1874 - val_loss: 76.9938\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 80.4665 - val_loss: 78.5327\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 76.1379 - val_loss: 76.4923\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 74.2393 - val_loss: 78.1465\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 74.0183 - val_loss: 77.5695\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 73.4621 - val_loss: 75.5345\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.9754 - val_loss: 75.2808\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.1036 - val_loss: 85.5548\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.4798 - val_loss: 74.9884\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.4250 - val_loss: 75.9618\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.8096 - val_loss: 73.8797\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.7045 - val_loss: 73.3719\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 70.9616 - val_loss: 78.7526\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.4687 - val_loss: 78.7895\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.5883 - val_loss: 72.0201\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 70.7961 - val_loss: 82.6995\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.7533 - val_loss: 70.7190\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.8038 - val_loss: 71.6235\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.3534 - val_loss: 71.8738\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 69.1041 - val_loss: 72.8088\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.9473 - val_loss: 70.8079\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 69.4224 - val_loss: 71.6852\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 58ms/step - loss: 588.5857 - val_loss: 376.2361\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 345.4920 - val_loss: 301.3130\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 4ms/step - loss: 289.1343 - val_loss: 259.2894\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 252.5578 - val_loss: 227.4442\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 4ms/step - loss: 211.0597 - val_loss: 193.0533\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 182.5914 - val_loss: 171.4129\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 171.4309 - val_loss: 155.0945\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 154.0238 - val_loss: 149.8642\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.1347 - val_loss: 134.2284\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 140.8465 - val_loss: 127.7524\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 128.8040 - val_loss: 130.9580\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 4ms/step - loss: 121.7925 - val_loss: 124.8890\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 7ms/step - loss: 120.6032 - val_loss: 115.9419\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.7849 - val_loss: 109.8487\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.5679 - val_loss: 107.3955\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 5ms/step - loss: 110.4778 - val_loss: 104.3146\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 107.6017 - val_loss: 99.4485\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 103.7278 - val_loss: 97.2290\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 100.2587 - val_loss: 104.5457\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 7ms/step - loss: 96.1728 - val_loss: 93.2085\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 95.5556 - val_loss: 90.2574\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 4ms/step - loss: 93.7800 - val_loss: 91.5168\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 4ms/step - loss: 92.3073 - val_loss: 88.8791\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 7ms/step - loss: 87.6989 - val_loss: 88.4054\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 5ms/step - loss: 87.2120 - val_loss: 85.5721\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 4ms/step - loss: 84.5918 - val_loss: 82.4312\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.3120 - val_loss: 80.9544\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 80.8579 - val_loss: 81.2027\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 86.3072 - val_loss: 98.9564\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.7917 - val_loss: 76.6758\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 76.7353 - val_loss: 92.1269\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.1983 - val_loss: 78.3970\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 7ms/step - loss: 78.5959 - val_loss: 76.3152\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 13ms/step - loss: 73.4098 - val_loss: 74.3899\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 72.2321 - val_loss: 73.3400\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 71.8018 - val_loss: 72.0367\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 71.8905 - val_loss: 70.7302\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 7ms/step - loss: 69.8391 - val_loss: 76.6696\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.3800 - val_loss: 70.7174\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 13ms/step - loss: 72.6391 - val_loss: 69.6862\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 7ms/step - loss: 69.4046 - val_loss: 69.0220\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 13ms/step - loss: 70.0767 - val_loss: 67.6606\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 12ms/step - loss: 73.1976 - val_loss: 79.6908\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 13ms/step - loss: 67.9988 - val_loss: 71.4211\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 11ms/step - loss: 68.1247 - val_loss: 68.6550\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 5ms/step - loss: 67.4429 - val_loss: 69.4748\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 66.2513 - val_loss: 64.8830\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 65.9469 - val_loss: 64.4894\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 64.5711 - val_loss: 65.9613\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 63.6351 - val_loss: 64.0112\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 62.6057 - val_loss: 71.9353\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.0255 - val_loss: 62.8520\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 4ms/step - loss: 61.2906 - val_loss: 62.6024\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 61.3569 - val_loss: 66.2284\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 58.4093 - val_loss: 62.2519\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 5ms/step - loss: 59.8926 - val_loss: 66.2100\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 4ms/step - loss: 62.4420 - val_loss: 64.0075\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 6ms/step - loss: 60.4772 - val_loss: 61.8056\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 5ms/step - loss: 59.3588 - val_loss: 61.0047\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 7ms/step - loss: 55.8241 - val_loss: 63.6316\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 4ms/step - loss: 57.9047 - val_loss: 58.8677\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 56.4712 - val_loss: 58.6323\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 5ms/step - loss: 56.8630 - val_loss: 58.8181\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 5ms/step - loss: 54.1530 - val_loss: 58.3980\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 6ms/step - loss: 54.7379 - val_loss: 65.8027\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 54.1572 - val_loss: 72.3686\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 6ms/step - loss: 54.2716 - val_loss: 56.5042\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 52.5271 - val_loss: 58.8111\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 55.0283 - val_loss: 62.8081\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 53.3491 - val_loss: 57.2888\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 6ms/step - loss: 51.7161 - val_loss: 62.1685\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 4ms/step - loss: 52.2507 - val_loss: 59.5864\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 6ms/step - loss: 55.1029 - val_loss: 63.7404\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 54.9148 - val_loss: 60.8044\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 51.0247 - val_loss: 54.0484\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 49.3954 - val_loss: 53.4984\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 50.8358 - val_loss: 57.1644\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 4ms/step - loss: 50.5838 - val_loss: 54.8259\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 50.6756 - val_loss: 54.2332\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 4ms/step - loss: 50.3210 - val_loss: 53.2974\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 48.7624 - val_loss: 51.3973\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 50.1458 - val_loss: 53.0938\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 50.0575 - val_loss: 52.7922\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 49.7901 - val_loss: 57.6027\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 49.7523 - val_loss: 53.1062\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 49.0683 - val_loss: 55.6035\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 5ms/step - loss: 47.5252 - val_loss: 52.4372\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 4ms/step - loss: 48.6313 - val_loss: 52.0851\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 6ms/step - loss: 46.5986 - val_loss: 57.9589\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 4ms/step - loss: 52.1672 - val_loss: 68.4361\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 5ms/step - loss: 51.4897 - val_loss: 52.7572\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 49.6481 - val_loss: 60.4089\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 51.2903 - val_loss: 56.9835\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 48.0382 - val_loss: 54.0684\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 5ms/step - loss: 49.5418 - val_loss: 51.5639\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 5ms/step - loss: 48.1616 - val_loss: 53.6163\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 50.5282 - val_loss: 54.4663\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 45.9364 - val_loss: 49.6996\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 6ms/step - loss: 46.6394 - val_loss: 49.9229\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 4ms/step - loss: 46.4708 - val_loss: 61.6204\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 1s - 59ms/step - loss: 848.2573 - val_loss: 379.9598\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 7ms/step - loss: 284.1324 - val_loss: 268.3669\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 6ms/step - loss: 257.4644 - val_loss: 247.6305\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 4ms/step - loss: 231.1867 - val_loss: 223.7933\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 209.1107 - val_loss: 205.4043\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 4ms/step - loss: 193.7209 - val_loss: 192.9596\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 7ms/step - loss: 181.7766 - val_loss: 180.7353\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 6ms/step - loss: 169.5519 - val_loss: 172.9252\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 4ms/step - loss: 162.1459 - val_loss: 168.7202\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 152.7227 - val_loss: 156.8456\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 6ms/step - loss: 144.9171 - val_loss: 147.8155\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 142.1661 - val_loss: 142.4287\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 9ms/step - loss: 137.8854 - val_loss: 137.4701\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 7ms/step - loss: 133.0831 - val_loss: 133.9584\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 14ms/step - loss: 131.0891 - val_loss: 131.4823\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 12ms/step - loss: 126.7518 - val_loss: 129.2285\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 125.3720 - val_loss: 127.7561\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 7ms/step - loss: 125.1004 - val_loss: 129.4202\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 7ms/step - loss: 124.6378 - val_loss: 126.4764\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 14ms/step - loss: 119.9971 - val_loss: 127.4015\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 6ms/step - loss: 119.9623 - val_loss: 121.9720\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 120.6791 - val_loss: 122.7040\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 8ms/step - loss: 117.0202 - val_loss: 117.7929\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 11ms/step - loss: 114.8772 - val_loss: 119.6036\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 115.1573 - val_loss: 114.6876\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.8348 - val_loss: 113.8450\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 5ms/step - loss: 113.6854 - val_loss: 115.8521\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 7ms/step - loss: 110.9230 - val_loss: 110.4401\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 6ms/step - loss: 112.3835 - val_loss: 108.0466\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 109.4716 - val_loss: 109.4252\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 6ms/step - loss: 107.8327 - val_loss: 105.4310\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 4ms/step - loss: 105.0802 - val_loss: 102.8078\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 102.7905 - val_loss: 100.8804\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 4ms/step - loss: 100.7355 - val_loss: 99.6296\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 4ms/step - loss: 99.4603 - val_loss: 98.0250\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 97.2493 - val_loss: 97.9102\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 6ms/step - loss: 100.4464 - val_loss: 97.2804\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 5ms/step - loss: 95.4057 - val_loss: 94.2774\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 93.6110 - val_loss: 92.3606\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 92.2622 - val_loss: 94.4461\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 4ms/step - loss: 92.9386 - val_loss: 88.4479\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 88.5750 - val_loss: 86.5196\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 87.4107 - val_loss: 85.1385\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 86.0877 - val_loss: 83.8920\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.6682 - val_loss: 90.9968\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 5ms/step - loss: 83.9665 - val_loss: 82.0136\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 5ms/step - loss: 81.9326 - val_loss: 81.8947\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 4ms/step - loss: 82.4549 - val_loss: 80.5334\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 80.1042 - val_loss: 76.5799\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 4ms/step - loss: 77.4787 - val_loss: 81.1073\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 77.4749 - val_loss: 72.6229\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.2376 - val_loss: 73.6453\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.2942 - val_loss: 72.9557\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.3907 - val_loss: 70.9394\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 70.2677 - val_loss: 67.4078\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.4291 - val_loss: 72.0484\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 7ms/step - loss: 69.8730 - val_loss: 68.8483\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 4ms/step - loss: 66.4483 - val_loss: 65.9497\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 67.2058 - val_loss: 63.5344\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 4ms/step - loss: 66.2998 - val_loss: 63.4575\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 66.7672 - val_loss: 62.1607\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 65.2596 - val_loss: 61.2396\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 6ms/step - loss: 61.7743 - val_loss: 61.1993\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 4ms/step - loss: 60.3331 - val_loss: 65.8496\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 4ms/step - loss: 62.0654 - val_loss: 61.2419\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 4ms/step - loss: 63.4480 - val_loss: 59.6223\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 4ms/step - loss: 59.6407 - val_loss: 59.0031\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 6ms/step - loss: 58.7649 - val_loss: 60.4020\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 5ms/step - loss: 58.6014 - val_loss: 59.7542\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 5ms/step - loss: 58.3658 - val_loss: 57.8484\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 58.0703 - val_loss: 59.3678\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 5ms/step - loss: 56.5284 - val_loss: 57.6239\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 5ms/step - loss: 55.8500 - val_loss: 56.0124\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 55.0199 - val_loss: 58.7493\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 7ms/step - loss: 55.9065 - val_loss: 56.1880\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 6ms/step - loss: 54.8603 - val_loss: 56.4365\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 4ms/step - loss: 53.8551 - val_loss: 54.4856\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 53.0607 - val_loss: 57.4107\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 4ms/step - loss: 52.8600 - val_loss: 54.0467\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 5ms/step - loss: 52.3580 - val_loss: 59.0398\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 5ms/step - loss: 55.6329 - val_loss: 55.0676\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 52.1708 - val_loss: 56.3392\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 4ms/step - loss: 51.9582 - val_loss: 53.9886\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 7ms/step - loss: 54.1646 - val_loss: 61.7782\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 6ms/step - loss: 54.3821 - val_loss: 56.5896\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 4ms/step - loss: 51.9837 - val_loss: 53.3222\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 5ms/step - loss: 49.9363 - val_loss: 54.3024\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 7ms/step - loss: 52.6623 - val_loss: 54.6339\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 4ms/step - loss: 54.5163 - val_loss: 52.9414\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 6ms/step - loss: 54.3415 - val_loss: 54.6095\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 4ms/step - loss: 51.6815 - val_loss: 53.9217\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 4ms/step - loss: 48.5237 - val_loss: 54.0790\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 4ms/step - loss: 48.3971 - val_loss: 51.7133\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 48.2633 - val_loss: 55.5048\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 5ms/step - loss: 48.1866 - val_loss: 54.8874\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 5ms/step - loss: 47.4032 - val_loss: 51.5805\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 5ms/step - loss: 47.4828 - val_loss: 53.7174\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 4ms/step - loss: 48.3620 - val_loss: 51.9289\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 47.5783 - val_loss: 52.8239\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 48.5862 - val_loss: 51.5395\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 73ms/step - loss: 4657.8164 - val_loss: 1854.4662\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 19ms/step - loss: 1112.0569 - val_loss: 614.1720\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 7ms/step - loss: 474.9704 - val_loss: 397.0833\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 12ms/step - loss: 338.9207 - val_loss: 302.5338\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 13ms/step - loss: 269.9210 - val_loss: 256.2679\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 8ms/step - loss: 233.7151 - val_loss: 225.4851\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 6ms/step - loss: 211.3380 - val_loss: 203.9455\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 12ms/step - loss: 197.4574 - val_loss: 189.7659\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 183.8140 - val_loss: 177.2998\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 6ms/step - loss: 172.7034 - val_loss: 165.9911\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 4ms/step - loss: 164.9417 - val_loss: 156.7382\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 5ms/step - loss: 149.6357 - val_loss: 144.2766\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 6ms/step - loss: 138.2522 - val_loss: 136.2696\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 7ms/step - loss: 131.2647 - val_loss: 129.7126\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 5ms/step - loss: 125.1483 - val_loss: 125.9187\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 4ms/step - loss: 123.2586 - val_loss: 126.2931\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 4ms/step - loss: 117.3358 - val_loss: 115.9901\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 7ms/step - loss: 114.7147 - val_loss: 115.6545\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 111.4116 - val_loss: 119.7745\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 4ms/step - loss: 107.7943 - val_loss: 102.5760\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 4ms/step - loss: 104.2929 - val_loss: 114.3202\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 6ms/step - loss: 104.1222 - val_loss: 102.9492\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 7ms/step - loss: 102.2127 - val_loss: 107.3022\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 5ms/step - loss: 99.1681 - val_loss: 95.4257\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 6ms/step - loss: 95.0626 - val_loss: 92.7450\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 6ms/step - loss: 93.6131 - val_loss: 90.9376\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 4ms/step - loss: 93.0953 - val_loss: 89.4095\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 4ms/step - loss: 91.6794 - val_loss: 90.1972\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 4ms/step - loss: 92.0434 - val_loss: 94.1558\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 6ms/step - loss: 89.4519 - val_loss: 86.4008\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 4ms/step - loss: 88.4827 - val_loss: 85.5592\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 5ms/step - loss: 87.4795 - val_loss: 84.3521\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 4ms/step - loss: 84.3378 - val_loss: 82.2255\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 6ms/step - loss: 85.5929 - val_loss: 84.0602\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 87.0110 - val_loss: 87.3914\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 4ms/step - loss: 83.3924 - val_loss: 87.7844\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 4ms/step - loss: 82.3857 - val_loss: 80.7200\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 81.9884 - val_loss: 80.8664\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 4ms/step - loss: 79.9180 - val_loss: 78.5404\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 4ms/step - loss: 79.0454 - val_loss: 77.4698\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.6428 - val_loss: 78.8079\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.6326 - val_loss: 78.5280\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 82.0805 - val_loss: 76.2113\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 7ms/step - loss: 78.4789 - val_loss: 77.2479\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 4ms/step - loss: 78.6624 - val_loss: 80.7466\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 4ms/step - loss: 78.4275 - val_loss: 75.2816\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 4ms/step - loss: 76.4868 - val_loss: 77.2123\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 7ms/step - loss: 75.6530 - val_loss: 76.4152\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 4ms/step - loss: 74.6976 - val_loss: 74.7583\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.1219 - val_loss: 74.4687\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 4ms/step - loss: 74.5398 - val_loss: 74.3279\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 79.2156 - val_loss: 74.9032\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 5ms/step - loss: 75.5246 - val_loss: 74.0620\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 4ms/step - loss: 72.7619 - val_loss: 77.6822\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 6ms/step - loss: 74.7026 - val_loss: 75.1795\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 4ms/step - loss: 74.9275 - val_loss: 83.2701\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 5ms/step - loss: 73.8595 - val_loss: 72.2637\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 5ms/step - loss: 71.2969 - val_loss: 73.0434\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 4ms/step - loss: 77.3271 - val_loss: 72.6474\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 72.0902 - val_loss: 73.2985\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 70.4689 - val_loss: 72.5433\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 4ms/step - loss: 69.7644 - val_loss: 71.6500\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 4ms/step - loss: 71.5062 - val_loss: 71.4447\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 7ms/step - loss: 73.0634 - val_loss: 71.1054\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 5ms/step - loss: 70.5214 - val_loss: 72.8499\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 6ms/step - loss: 70.9913 - val_loss: 71.5822\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 5ms/step - loss: 70.8456 - val_loss: 72.8123\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 4ms/step - loss: 73.7634 - val_loss: 71.6190\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 6ms/step - loss: 69.5781 - val_loss: 70.8676\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 4ms/step - loss: 68.3460 - val_loss: 69.8582\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 4ms/step - loss: 68.6620 - val_loss: 71.2058\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.9206 - val_loss: 71.5006\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 5ms/step - loss: 73.8225 - val_loss: 69.7687\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 4ms/step - loss: 69.8849 - val_loss: 70.5820\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.8637 - val_loss: 69.4252\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 4ms/step - loss: 68.4540 - val_loss: 69.0201\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.5494 - val_loss: 77.6111\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 7ms/step - loss: 67.6989 - val_loss: 70.3402\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.1529 - val_loss: 72.0691\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.0471 - val_loss: 70.9036\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 5ms/step - loss: 65.5701 - val_loss: 70.1033\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 4ms/step - loss: 66.6900 - val_loss: 68.0374\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.6599 - val_loss: 70.4740\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 4ms/step - loss: 67.4550 - val_loss: 71.7917\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 4ms/step - loss: 69.1493 - val_loss: 68.7937\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.3541 - val_loss: 67.8826\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 6ms/step - loss: 65.5477 - val_loss: 68.1981\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 7ms/step - loss: 66.3254 - val_loss: 68.1169\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 5ms/step - loss: 68.0014 - val_loss: 67.9972\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 67.0254 - val_loss: 74.9933\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 7ms/step - loss: 67.2889 - val_loss: 67.4817\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 12ms/step - loss: 67.2456 - val_loss: 67.3409\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.4902 - val_loss: 67.1083\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 6ms/step - loss: 66.0036 - val_loss: 67.1180\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 6ms/step - loss: 64.9850 - val_loss: 67.9095\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 14ms/step - loss: 64.7564 - val_loss: 66.8386\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 7ms/step - loss: 65.2577 - val_loss: 68.4371\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 13ms/step - loss: 67.4002 - val_loss: 70.4759\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 7ms/step - loss: 67.1669 - val_loss: 69.9384\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 12ms/step - loss: 65.5506 - val_loss: 74.3439\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 - 2s - 98ms/step - loss: 661.8088 - val_loss: 345.5419\n",
            "Epoch 2/100\n",
            "23/23 - 0s - 4ms/step - loss: 302.4890 - val_loss: 239.9191\n",
            "Epoch 3/100\n",
            "23/23 - 0s - 5ms/step - loss: 202.1776 - val_loss: 193.7781\n",
            "Epoch 4/100\n",
            "23/23 - 0s - 6ms/step - loss: 176.9762 - val_loss: 180.6462\n",
            "Epoch 5/100\n",
            "23/23 - 0s - 6ms/step - loss: 166.9816 - val_loss: 169.5667\n",
            "Epoch 6/100\n",
            "23/23 - 0s - 5ms/step - loss: 160.3801 - val_loss: 163.7636\n",
            "Epoch 7/100\n",
            "23/23 - 0s - 4ms/step - loss: 155.4536 - val_loss: 161.1960\n",
            "Epoch 8/100\n",
            "23/23 - 0s - 7ms/step - loss: 151.4165 - val_loss: 155.2417\n",
            "Epoch 9/100\n",
            "23/23 - 0s - 6ms/step - loss: 144.1787 - val_loss: 154.2190\n",
            "Epoch 10/100\n",
            "23/23 - 0s - 4ms/step - loss: 141.3118 - val_loss: 150.5017\n",
            "Epoch 11/100\n",
            "23/23 - 0s - 5ms/step - loss: 136.0043 - val_loss: 141.7204\n",
            "Epoch 12/100\n",
            "23/23 - 0s - 6ms/step - loss: 137.0674 - val_loss: 139.1871\n",
            "Epoch 13/100\n",
            "23/23 - 0s - 5ms/step - loss: 128.3317 - val_loss: 131.7215\n",
            "Epoch 14/100\n",
            "23/23 - 0s - 5ms/step - loss: 124.6943 - val_loss: 127.4415\n",
            "Epoch 15/100\n",
            "23/23 - 0s - 4ms/step - loss: 120.7820 - val_loss: 124.0492\n",
            "Epoch 16/100\n",
            "23/23 - 0s - 6ms/step - loss: 116.2312 - val_loss: 120.0931\n",
            "Epoch 17/100\n",
            "23/23 - 0s - 6ms/step - loss: 113.6461 - val_loss: 117.1223\n",
            "Epoch 18/100\n",
            "23/23 - 0s - 6ms/step - loss: 111.2184 - val_loss: 116.8780\n",
            "Epoch 19/100\n",
            "23/23 - 0s - 4ms/step - loss: 108.0242 - val_loss: 110.4912\n",
            "Epoch 20/100\n",
            "23/23 - 0s - 5ms/step - loss: 102.8540 - val_loss: 105.2419\n",
            "Epoch 21/100\n",
            "23/23 - 0s - 5ms/step - loss: 100.1120 - val_loss: 100.8909\n",
            "Epoch 22/100\n",
            "23/23 - 0s - 5ms/step - loss: 94.2644 - val_loss: 97.0782\n",
            "Epoch 23/100\n",
            "23/23 - 0s - 5ms/step - loss: 93.1729 - val_loss: 93.5218\n",
            "Epoch 24/100\n",
            "23/23 - 0s - 5ms/step - loss: 91.0810 - val_loss: 92.9542\n",
            "Epoch 25/100\n",
            "23/23 - 0s - 7ms/step - loss: 91.2925 - val_loss: 88.6796\n",
            "Epoch 26/100\n",
            "23/23 - 0s - 5ms/step - loss: 88.0841 - val_loss: 85.6050\n",
            "Epoch 27/100\n",
            "23/23 - 0s - 6ms/step - loss: 87.8550 - val_loss: 84.0394\n",
            "Epoch 28/100\n",
            "23/23 - 0s - 5ms/step - loss: 88.0769 - val_loss: 83.4044\n",
            "Epoch 29/100\n",
            "23/23 - 0s - 7ms/step - loss: 84.0926 - val_loss: 83.1329\n",
            "Epoch 30/100\n",
            "23/23 - 0s - 5ms/step - loss: 81.8473 - val_loss: 82.1880\n",
            "Epoch 31/100\n",
            "23/23 - 0s - 5ms/step - loss: 80.6632 - val_loss: 84.0008\n",
            "Epoch 32/100\n",
            "23/23 - 0s - 5ms/step - loss: 81.1488 - val_loss: 80.4920\n",
            "Epoch 33/100\n",
            "23/23 - 0s - 6ms/step - loss: 78.6529 - val_loss: 78.1376\n",
            "Epoch 34/100\n",
            "23/23 - 0s - 5ms/step - loss: 78.1876 - val_loss: 77.8729\n",
            "Epoch 35/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.7892 - val_loss: 77.6715\n",
            "Epoch 36/100\n",
            "23/23 - 0s - 6ms/step - loss: 77.0294 - val_loss: 76.8513\n",
            "Epoch 37/100\n",
            "23/23 - 0s - 5ms/step - loss: 75.6657 - val_loss: 76.4143\n",
            "Epoch 38/100\n",
            "23/23 - 0s - 4ms/step - loss: 76.2535 - val_loss: 82.7831\n",
            "Epoch 39/100\n",
            "23/23 - 0s - 5ms/step - loss: 75.7452 - val_loss: 73.5167\n",
            "Epoch 40/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.0817 - val_loss: 72.4737\n",
            "Epoch 41/100\n",
            "23/23 - 0s - 6ms/step - loss: 75.4706 - val_loss: 77.1594\n",
            "Epoch 42/100\n",
            "23/23 - 0s - 5ms/step - loss: 74.8204 - val_loss: 82.4612\n",
            "Epoch 43/100\n",
            "23/23 - 0s - 6ms/step - loss: 71.2517 - val_loss: 68.8745\n",
            "Epoch 44/100\n",
            "23/23 - 0s - 6ms/step - loss: 68.6078 - val_loss: 68.9864\n",
            "Epoch 45/100\n",
            "23/23 - 0s - 7ms/step - loss: 67.4878 - val_loss: 71.4745\n",
            "Epoch 46/100\n",
            "23/23 - 0s - 5ms/step - loss: 67.5896 - val_loss: 68.8052\n",
            "Epoch 47/100\n",
            "23/23 - 0s - 7ms/step - loss: 67.2724 - val_loss: 69.1293\n",
            "Epoch 48/100\n",
            "23/23 - 0s - 6ms/step - loss: 67.0628 - val_loss: 64.0055\n",
            "Epoch 49/100\n",
            "23/23 - 0s - 5ms/step - loss: 64.3875 - val_loss: 63.5680\n",
            "Epoch 50/100\n",
            "23/23 - 0s - 6ms/step - loss: 63.2408 - val_loss: 63.5378\n",
            "Epoch 51/100\n",
            "23/23 - 0s - 5ms/step - loss: 63.0804 - val_loss: 65.3366\n",
            "Epoch 52/100\n",
            "23/23 - 0s - 6ms/step - loss: 63.4715 - val_loss: 65.5971\n",
            "Epoch 53/100\n",
            "23/23 - 0s - 6ms/step - loss: 64.8995 - val_loss: 62.2809\n",
            "Epoch 54/100\n",
            "23/23 - 0s - 5ms/step - loss: 64.5922 - val_loss: 62.3150\n",
            "Epoch 55/100\n",
            "23/23 - 0s - 5ms/step - loss: 62.8958 - val_loss: 64.4707\n",
            "Epoch 56/100\n",
            "23/23 - 0s - 6ms/step - loss: 64.4559 - val_loss: 66.5190\n",
            "Epoch 57/100\n",
            "23/23 - 0s - 5ms/step - loss: 63.8371 - val_loss: 66.6005\n",
            "Epoch 58/100\n",
            "23/23 - 0s - 7ms/step - loss: 64.3228 - val_loss: 62.1161\n",
            "Epoch 59/100\n",
            "23/23 - 0s - 5ms/step - loss: 60.2656 - val_loss: 66.4899\n",
            "Epoch 60/100\n",
            "23/23 - 0s - 6ms/step - loss: 65.5683 - val_loss: 65.3571\n",
            "Epoch 61/100\n",
            "23/23 - 0s - 6ms/step - loss: 60.0094 - val_loss: 63.1511\n",
            "Epoch 62/100\n",
            "23/23 - 0s - 7ms/step - loss: 63.1497 - val_loss: 65.8659\n",
            "Epoch 63/100\n",
            "23/23 - 0s - 12ms/step - loss: 59.2958 - val_loss: 61.5596\n",
            "Epoch 64/100\n",
            "23/23 - 0s - 7ms/step - loss: 59.2090 - val_loss: 61.9191\n",
            "Epoch 65/100\n",
            "23/23 - 0s - 13ms/step - loss: 62.1382 - val_loss: 73.4316\n",
            "Epoch 66/100\n",
            "23/23 - 0s - 7ms/step - loss: 60.5087 - val_loss: 68.1006\n",
            "Epoch 67/100\n",
            "23/23 - 0s - 13ms/step - loss: 57.9717 - val_loss: 62.9038\n",
            "Epoch 68/100\n",
            "23/23 - 0s - 7ms/step - loss: 56.9403 - val_loss: 59.6483\n",
            "Epoch 69/100\n",
            "23/23 - 0s - 13ms/step - loss: 59.4021 - val_loss: 67.0630\n",
            "Epoch 70/100\n",
            "23/23 - 0s - 13ms/step - loss: 60.0355 - val_loss: 59.6361\n",
            "Epoch 71/100\n",
            "23/23 - 0s - 13ms/step - loss: 56.8851 - val_loss: 60.6429\n",
            "Epoch 72/100\n",
            "23/23 - 0s - 8ms/step - loss: 55.7796 - val_loss: 59.9432\n",
            "Epoch 73/100\n",
            "23/23 - 0s - 11ms/step - loss: 55.8034 - val_loss: 59.2839\n",
            "Epoch 74/100\n",
            "23/23 - 0s - 5ms/step - loss: 55.6115 - val_loss: 59.8876\n",
            "Epoch 75/100\n",
            "23/23 - 0s - 5ms/step - loss: 55.9518 - val_loss: 63.2027\n",
            "Epoch 76/100\n",
            "23/23 - 0s - 5ms/step - loss: 54.5850 - val_loss: 60.3861\n",
            "Epoch 77/100\n",
            "23/23 - 0s - 6ms/step - loss: 56.7046 - val_loss: 61.5742\n",
            "Epoch 78/100\n",
            "23/23 - 0s - 6ms/step - loss: 54.2707 - val_loss: 60.7582\n",
            "Epoch 79/100\n",
            "23/23 - 0s - 6ms/step - loss: 55.3880 - val_loss: 63.6143\n",
            "Epoch 80/100\n",
            "23/23 - 0s - 6ms/step - loss: 55.7879 - val_loss: 59.2415\n",
            "Epoch 81/100\n",
            "23/23 - 0s - 6ms/step - loss: 55.3799 - val_loss: 62.4248\n",
            "Epoch 82/100\n",
            "23/23 - 0s - 6ms/step - loss: 55.8004 - val_loss: 58.5624\n",
            "Epoch 83/100\n",
            "23/23 - 0s - 6ms/step - loss: 53.8846 - val_loss: 59.0790\n",
            "Epoch 84/100\n",
            "23/23 - 0s - 6ms/step - loss: 52.5833 - val_loss: 58.3646\n",
            "Epoch 85/100\n",
            "23/23 - 0s - 5ms/step - loss: 53.7925 - val_loss: 59.3944\n",
            "Epoch 86/100\n",
            "23/23 - 0s - 6ms/step - loss: 54.2218 - val_loss: 60.6470\n",
            "Epoch 87/100\n",
            "23/23 - 0s - 5ms/step - loss: 53.0671 - val_loss: 59.4126\n",
            "Epoch 88/100\n",
            "23/23 - 0s - 6ms/step - loss: 53.2262 - val_loss: 64.0830\n",
            "Epoch 89/100\n",
            "23/23 - 0s - 5ms/step - loss: 59.8729 - val_loss: 63.0101\n",
            "Epoch 90/100\n",
            "23/23 - 0s - 5ms/step - loss: 55.7761 - val_loss: 65.8885\n",
            "Epoch 91/100\n",
            "23/23 - 0s - 7ms/step - loss: 53.9243 - val_loss: 59.9415\n",
            "Epoch 92/100\n",
            "23/23 - 0s - 5ms/step - loss: 51.4737 - val_loss: 59.3314\n",
            "Epoch 93/100\n",
            "23/23 - 0s - 6ms/step - loss: 54.0037 - val_loss: 60.9976\n",
            "Epoch 94/100\n",
            "23/23 - 0s - 4ms/step - loss: 51.4281 - val_loss: 62.7285\n",
            "Epoch 95/100\n",
            "23/23 - 0s - 5ms/step - loss: 51.0080 - val_loss: 58.1610\n",
            "Epoch 96/100\n",
            "23/23 - 0s - 6ms/step - loss: 49.7813 - val_loss: 58.9352\n",
            "Epoch 97/100\n",
            "23/23 - 0s - 4ms/step - loss: 50.7562 - val_loss: 58.5908\n",
            "Epoch 98/100\n",
            "23/23 - 0s - 7ms/step - loss: 52.6500 - val_loss: 70.1907\n",
            "Epoch 99/100\n",
            "23/23 - 0s - 4ms/step - loss: 53.9616 - val_loss: 60.5372\n",
            "Epoch 100/100\n",
            "23/23 - 0s - 6ms/step - loss: 49.9124 - val_loss: 60.9473\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_mse = np.mean(mse_list)\n",
        "mean_mse"
      ],
      "metadata": {
        "id": "T8UbqjFjZH6F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae644cd1-f273-4da7-f484-e24260da5c16"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "121.78255285683088"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "std_mse = np.std(mse_list)\n",
        "std_mse"
      ],
      "metadata": {
        "id": "EYnknV4IZe2J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24dc60b6-f724-4b05-91a9-566f358eee45"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "204.76195630650818"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}